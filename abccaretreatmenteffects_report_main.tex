%Input preamble
\input{preamble}

\externaldocument{abccaretreatmenteffects_report_main_appendix}

\begin{document}
\title{\Large \textbf{Analyzing the Short- and Long-term Effects of Early Childhood Education on Multiple Dimensions of Human Development}\thanks{This research was supported in part by the American Bar Foundation; the Pritzker Children's Initiative, the
Buffett Early Childhood Fund, NIH grants NICHD R37HD065072, NICHD R01HD54702, and NIA R24AG048081, an
anonymous funder, Successful Pathways from School to Work, an initiative of the University of Chicago's Committee
on Education funded by the Hymen Milgrom Supporting Organization, and the Human Capital and Economic
Opportunity Global Working Group, an initiative of the Center for the Economics of Human Development, affiliated with
the Becker Friedman Institute for Research in Economics, and funded by the Institute for New Economic Thinking. The
views expressed in this paper are solely those of the authors and do not necessarily represent those of the funders or
the official views of the National Institutes of Health. For helpful comments, we thank St\'{e}phane Bonhomme, Steven Durlauf, and Azeem Shaikh. For information on the implementation of the Carolina Abecedarian Project and assistance in data acquisition, we thank Peg Burchinal, Carrie Bynum, Frances Campbell, and Elizabeth Gunn. For information on childcare in North Carolina, we thank Richard Clifford and Sue Russell. For exceptional research assistance, we thank Thomas Choi. Lastly, we thank Sylvi Kuperman for sharing detailed and careful descriptions of the Carolina Abecedarian Project.}}

\author{
Jorge Luis Garc\'{i}a\\
The University of Chicago \and
James J. Heckman \\
American Bar Foundation \\
The University of Chicago \and
Andr\'{e}s Hojman\\
The University of Chicago \and
Yu Kyung Koh \\ 
The University of Chicago \and
Joshua Shea \\
The University of Chicago \and
Anna Ziff \\ 
The University of Chicago}
\date{First Draft: January 5, 2016\\ This Draft: \today}
\maketitle

\singlespacing
%\pagebreak
\tableofcontents
\listoffigures
\listoftables
\pagebreak

\section{Introduction}

\noindent One of President Barack Obama's policy goals throughout his tenure has been the promotion of early childhood education as a means of reducing socio-economic inequality \citep{Bajaj_Labaton_2009_ObamaRiskAssets,White_House_2014_Econ_of_EC_Investments,White_House_2014_Fact_Sheet_Press}. Candidates across the political spectrum to succeed President Obama also consider early childhood education an important component of their agendas.\footnote{Candidates from both parties consider access to education a right Americans should have; all make particular emphasis on early childhood education \citep{Hillary-for-Am_2016_Universal-Preschool,On-the-Issues_2016_Sanders-on-Families,On-the-Issues_2016_Cruz-on-Education}.}\\ 

\noindent Public funding of early childhood education has been on the rise in recent years with the intention of reducing socio-economic inequality. The Education Commission of the States reports that 32 states increased spending on early childcare for the 2015-2016 year, with an overall state-spending increase of 12 percent. Similarly, the federal budget proposal for 2017 included an approximately \$300 million increase in spending on early childhood education.\\

\noindent Despite the importance of early childhood education both in the public debate and in the allocation of the government's budget, comprehensive and methodologically rigorous evidence on its efficiency and effectiveness  is still scarce. Many recent studies suffer from one or more of the following pitfalls: (i) they focus on a limited set of outcomes that fail to account for the complete set of program impacts;\footnote{An extreme example is the evaluation of preschool programs using an age-eligibility cutoff. A battery of studies compare children who were just eligible to children who were just ineligible given their birth dates and assess the gain of an additional year of preschool. This does not represent a comprehensive evaluation approach. Instead, it is an evaluation comparing an specific set of children, in a very narrow set of tests and within a time horizon of a single year. Examples of these studies include: \citet{Gormley_Gayer_2005_JHR,Gormley_Gayer_etal_2005_DP,Weiland_2013_CD_Impacts-of-Pre-K}.} (ii) they do not take into account that, even when based on randomized controlled trials, non-compliance to treatment and treatment substitution by the control families make standard evaluation parameters loose policy relevance;\footnote{A relevant example is the evaluation of Head Start through its randomized controlled trial, the Head Start Impact Study \citep{Puma_Bell_etal_2010_HeadStartImpact}. Comparing the children in the treatment and the control groups usually yields relative low gains. This attenuation happens because a substantial proportion of children randomized out of the program were enrolled into preschool alternatives, some of them to other Head Start centers. Thus, a raw comparison between the treatment and the control groups children does not inform on either the efficiency or the effectiveness of Head Start. Studies providing a methodology to account for treatment substitution find that Head Start has substantial effects, although they focus on a single, short-term outcome \citep{Kline-Walters_2015_NBER-Evaluating,Feller_Grindal_etal_2016_ComparedtoWhat}.} or (iii) they evaluate randomized controlled trials with flawed designs.\footnote{An evaluation Tennessee Voluntary Prekindergarten is an emblematic example of this \citep{Lipsey_et_al_2013_Tennessee_Kindergrtn_PRI,Lipsey_et_al_2015_Randomized_Control_Trial_PRI}. The researchers designed a randomized controlled trial to evaluate the program. Unfortunately, they asked permission to assess the children after the randomization protocol. Thus, they have information available for children whose parents agreed for them to be evaluated \textit{post} randomization, inducing a potential imbalance between the children randomized into and out of the program. The evaluation does not account for that. Further, the results this evaluation presents are on a narrow and short-term set of outcomes.}\\ 

\noindent  The case for the effectiveness and the economic efficiency of early childhood education in the U.S. is largely based on evidence from the Perry Preschool Program (referred to simply as Perry). Analyses of Perry suggest that (i) early childhood education has significant positive effects on multiple short- and long-term socio-economic outcomes, even when accounting for compromised randomization, small-sample-size inference, and multiple hypotheses testing \citep{Heckman_Moon_etal_2010_QE}; and (ii) early childhood education could have an annual internal rate of return that ranges between 7 and 10 percent.\footnote{If one dollar were to be invested at age 4, and then reinvested annually and compounded over a lifetime, the return would accrue to 60 to 300 dollars by age 65. This accounts for all the programs' cost and the social burden a government would cause by raising taxes to pay for it \citep{Heckman_Moon_etal_2010_RateofReturn}}\\

\noindent A frequent criticism of the evidence favoring the economic case for early childhood education is the lack of an ampler evidence base. In response, this this paper presents a rigorous evaluation of two related randomized controlled trials: the Carolina Abecedarian Project (ABC) and the Carolina Approach to Responsive Education (CARE).\\ 

\noindent This paper has two novel components. First, it is based on data containing extensive information on the participant children that starts at birth, continues throughout childhood, and ends at adulthood. It includes a battery of standard cognition assessments. But more importantly, it enables us to observe socio-emotional skills, education and labor market outcomes, \textit{administrative} criminal records, and a full medical examination when the treatment and control groups were in their mid 30s. Second, we develop a methodology to assess the effectiveness of the programs accounting for two issues that are common to social experiments: (i) attrition of treatment and control participants throughout the treatment and the data follow-ups; and (ii) treatment substitution by the families of the control-group children. These two components allow for a short- and long-term policy relevant evaluation of the effects early-childhood education has on multiple dimensions of human development.\footnote{A usual critique to programs like ABC and CARE we do not assess here is their small sample size. Asymptotic inference methods, however, are well suited to analyze samples of the size of these programs \citep{Hanushek_Lindseth_2009_BOOKSchoolhousesCourthouses}. \citet{Campbell_Conti_etal_2014_EarlyChildhoodInvestments} evaluate the effectiveness of ABC at boosting health outcomes both using small sample size inference and an asymptotic procedure, and find little sensitivity.}\\

\noindent ABC and CARE were programs implemented in the 1970s and early 1980s. Therefore, we observe long-term outcomes for their participants. The programs were separated into two phases. In the first phase, both programs assigned high-quality center-based childcare to children from ages 0 to 5. In addition, the children who were assigned center-based childcare in CARE also received home visits that aimed to foster the relationship between participating children and their parents. Furthermore, CARE incorporated a second treatment group that received home visits without center-based childcare. The second phase of treatment, from ages 5 to 8, consisted of home visits that aimed to continue promoting childhood development. In ABC, the second-phase treatment was randomly assigned independently of the first-phase randomization. In CARE, the second-phase was not randomized; children initially randomized to treatment continued being treatment. The design of these programs allows us to tests hypotheses to evaluate the effectiveness of different types of programs, as well as the effectiveness of intervening at different stages of childhood.\\

\noindent For each data collection stage, we document non-compliance to treatment and attrition. We propose a methodology to account for these cases, which are a common critique to ABC \citep{Spitz_1992_ABC-Retardation,Hu_2014_ABC-Study}.\\

\noindent We also present a thorough documentation of control-group treatment substitution. In both programs, the parents of around 70\% of the children randomized out of center-based childcare enrolled their children in relatively high-quality preschool alternatives.\footnote{Treatment substitution was not an issue in Perry. Informal conversations with Perry's staff indicate that there were no alternative preschools in the area in which subjects were treated during that time---Ypsilanti, Michigan during the 1960s. This issue is important when evaluating more recent programs. Examples include both ABC and Head Start---see \citep{Puma_Bell_etal_2010_HeadStartImpact} for a documentation of treatment substitution in ABC.} We develop a methodology to account for treatment substitution and explain that there are two policy questions that we are able to ask using data from ABC and CARE. First, we can evaluate the effect of ABC and CARE given the supply of preschool alternatives available when they were implemented. Second, we can evaluate the effect of ABC and CARE relative to a fixed alternative: no preschool at all or attending alternative preschools. The second question can better characterize the effectiveness of each program because it compares it to a set alternative.\\

\noindent We summarize the effectiveness of a program when information on multiple outcomes throughout the life-cycle is available. There are two current alternatives in the literature. One is to to calculate statistics that characterize the efficiency of a social program, such as the internal rate of return or the benefit-to-cost ratio \citep{Heckman_Moon_etal_2010_RateofReturn}. The other is to group outcomes into categories---e.g., socio-emotional skills, criminal activity, health---and adjust the inference on each of the outcomes to account for multiple hypotheses testing and to avoid ``cherry picking'' significant results \citep{Lehman_Romano_2005_AnnStat,Lehmann_Romano_2005_testing,Heckman_Moon_etal_2010_QE}. In this paper, we calculate and formalize an inference procedure for (i) the count of outcomes for which the program causes a positive treatment effect; and (ii) the count of outcomes for which the program causes a \emph{significant} and positive treatment effect, considering different levels of significance.\footnote{This alternative is an application of conducting inference on a statistic that summarizes information across multiple sources---i.e., a combining function \citep{Pesarin_Salmaso_2010_PermutationTests}.}\\

\noindent \textbf{[JLG: next three paragraphs, description of results, pending.]}\\

\noindent We also test diverse hypotheses to assess the effectiveness of the second phase of randomization. The effectiveness of the first phase of treatment is much weaker if compared to that of the second. We conclude that ABC and CARE were much more effective when intervening before age 5, rather than between ages 5 to 8.\\

\noindent This paper extends the work of \citet{Campbell_Conti_etal_2014_EarlyChildhoodInvestments}, who analyze the effectiveness of ABC at improving long-term health outcomes. It presents the methodology for the calculation of the treatment effect estimates that underpin our companion paper, \citet{Elango_et_al_2015_ABC_unpublished}. In it, we use the treatment effects in this paper and forecast the life-cycle gains of ABC on multiple dimensions of human development, from birth and until death, to calculate its internal rate of return and its benefit-to-cost ratio.\footnote{\cite{Campbell_Pungello_etal_2012_DP} estimate treatment effects on adulthood outcomes in ABC. Unlike our approach, this report does not assess outcomes such as health status, criminal behavior, and non-cognitive skills. \cite{Campbell_Conti_etal_2014_EarlyChildhoodInvestments} is the only other paper to assess health outcomes, but they do not address control contamination. In addition to providing a comprehensive analysis of ABC's effects, our paper is a valuable contribution since it is the first to correct for control contamination, to correct for non-random attrition, and to adjust for the cherry-picking of significant treatment effects by using count statistics. Furthermore, we broaden the analysis by analyzing ABC together with CARE, which was close in implementation objectives and design.}\\

\noindent The rest of the paper proceeds as follows. Section~\ref{section:background} describes the background of each program. It includes an overview, a description of the eligibility criteria and the populations served, a characterization of the randomization protocol and of treatment substitution, and a comprehensive summary of the treatment.  Section~\ref{section:methodology} formalizes our methodology by discussing how we correct for compromised randomization, treatment substitution, and multiple hypotheses testing. Section~\ref{section:results} presents our main results and Section~\ref{section:conclusion} offers some final comments. An extensive appendix presents a much more thorough description of the program and data relative to what we present in the main text. It also discusses various alternative methodologies to evaluate the programs accounting for treatment substitution, and documents the results we present to a further extent.

\section{Background} \label{section:background}
\subsection{Overview}

\noindent The Carolina Abecedarian Project (ABC) and the Carolina Approach to Responsive Education (CARE) programs were designed and implemented by researchers at the Frank Porter Graham Center (FPGC) of the University of North Carolina in Chapel Hill. The programs targeted disadvantaged children from the semi-rural communities in the surrounding area.\\

\noindent The design and implementation of CARE and ABC were very similar and both studies had a small sample size. ABC recruited 122 children over four cohorts,\footnote{\citet{Ramey_Collier_etal_1976_CarolinaAbecedarianProject}.} while CARE recruited 67 children over two cohorts.\\  

\noindent ABC had two phases, the first of which lasted from birth until the age of 5. In this phase, children were randomly assigned to either treatment or control groups. The treatment group received: (i) center-based childcare; (ii) breakfast, lunch, an afternoon snack, iron-fortified formula for the first 15 months of life, and a monthly supply of diapers; and (iii) medical care from licensed nurses who were supervised by a pediatrician, frequent health check-ups, and hospital referrals when serious medical treatment was needed. The control group only received formula and diapers. In the second phase of treatment, at the age of 5, the 95 children still in the study were randomly assigned again to treatment or control groups, independently of their status in the prior randomization. This treatment consisted of home visits targeting both children and parents and lasted until age 8.\\ 

\noindent  CARE also had two treatment stages, though children were randomized only once. While the two programs had essentially identical second stages, the first phase of CARE differed significantly from the first phase of ABC by including a family education component. This component was designed to study the effects of improving the home environment on child development.\footnote{\citet{Wasik_Ramey_etal_1990_CD}.} The first treatment phase of CARE lasted from birth until the age of 5. Children were randomly assigned to one of three experimental groups: control (23 children), family education (25 children), and both family education and center-based childcare (17 children). As in ABC, the control group received diapers and complementary nutrition from birth to 15 months. The family education group received home visits that aimed to help parents solve common problems related to childrearing. Both treatment groups received the second phase of treatment from ages 5 to 8.\\

\noindent The available data describing each program is rich and similar. In both programs, from birth until the age of 8, data was collected annually on cognitive and socio-emotional skills, home environment, family structure, and family economic characteristics. After age 8, the collection of data was less frequent. Information on cognitive and socio-emotional skills, education, and family economic characteristics was collected at ages 12, 15, 21, and 30.\footnote{At age 30, information on cognitive skills is unavailable for both ABC and CARE.} In addition, we have two sources of data that are novel to the literature evaluating early childhood education programs: administrative criminal records and a full medical panel at age 34. These rich sources of data allow us to study the long-term effects of the programs on multiple aspects of human development.

\subsection{Eligibility Criteria and Populations Served} \label{section:eligibility}

\noindent ABC recruited four cohorts of children born between 1972 and 1977. CARE recruited two cohorts of children, one born in 1978 and one in 1979. The recruitment processes were identical. Potential families were referred to researchers by local social service agencies and hospitals at the beginning of the mother's last trimester of pregnancy. Eligibility was determined by a score of 11 or above in a High-risk Index (HRI).\footnote{The HRI was a linear combination based on 13 variables, which are listed here with their weights in parentheses: (i) maternal education level measured by years of education---6 (8), 7 (7), 8 (6), 9 (3), 10 (2), 11 (1), 12 (0); (ii) paternal education level with weights identical to those for maternal education; (iii) family income measured in current dollars---\$1,000 (8), \$1,001 - \$2,000 (7), \$2,001 - \$3,000 (6), \$3,001 - \$4,000 (5), \$4,001 - \$5,000 (4), \$5,001 (0); (iv) father's absence from the household for reasons other than health or death (3); (v) absence of maternal relatives in the area (3); (vi) siblings of school age one or more grades behind age-appropriate level, or with equivalently low scores on school-administered achievement tests (3); (vii) received payments from welfare agencies within past 3 years (3); (viii) record of father's work indicates instability or unskilled and semi-skilled labor (3); (ix) record of maternal or paternal IQ score of 90 or below (3); (x) record of sibling IQ score of 90 or below (3); (xi) relevant social agencies in the community indicate the family is in need of assistance (3); (xii) one or more family members has sought counseling or professional help in the past 3 years (1); and (xiii) special circumstances not included in any of the above that are likely contributors to cultural or social disadvantage (1).} Table~\ref{tab:baseline} compares the children in ABC and CARE. Overall, the children in CARE were relatively less disadvantaged; their mothers were older, more educated, and had higher IQ.

\input{output/baseline_balance_abccare}

\noindent Neither ABC nor CARE used race as an eligibility factor. However, $98\%$ and $90\%$ of their participants were African-American, respectively. The average maternal age in ABC when the target child was born was 19.9, whereas in CARE mothers were on average 21 years old. In both treatments, approximately half of all mothers were 19 or younger.\footnote{Maternal age at target child's birth ranges from 13 to 43 years of age. One-third were 17 or younger.} Further, the average IQ for all mothers was 84 in ABC and 87 in CARE---approximately one standard deviation below the national mean. Only $25\%$ of the ABC children lived with both biological parents, and more than $50\%$ lived with extended families in multi-generational households ($61\%$ of treated children and $56\%$ of control children).\\

\begin{figure}[H]
\caption{Family Environment Baseline Characteristics, ABC and CARE}  \label{figure:baselineabccare}
    \centering
\begin{subfigure}{.5\textwidth}
  \centering
  \subcaption{Average Maternal Age}
  \includegraphics[height=2.3in]{output/abccarepsid_m_age0pool.eps}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \subcaption{Average Maternal Years of Education} 
  \includegraphics[height=2.3in]{output/abccarepsid_m_edu0pool.eps}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
  \centering
  \subcaption{Proportion of Households with Father at Home}
  \includegraphics[height=2.3in]{output/abccarepsid_f_home0pool.eps}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \subcaption{Median Parental Income in 1,000s of 2014 USD}
  \includegraphics[height=2.3in]{output/abccarepsid_p_inc0pool.eps}
\end{subfigure}
\floatfoot{
\footnotesize
\noindent  Note: These panels plot mother's age, mother's education, an indicator of father at home, and parental income (in thousands of 2014 USD). In each panel, the first bar shows the national-level for a cohort born in the same years as the ABC and CARE individuals (1972-1979), obtained from the Panel Study of Income Dynamics (PSID). The second bar uses this same information restricted to black individuals. The third and fourth bars plot the same variables for ABC and CARE, pooling the treatment and control groups.
}
\end{figure}

\noindent To better characterize the socio-economic status of the families participating in ABC, we construct two comparison groups using the Panel Study of Income Dynamics (PSID), a nationally representative cohort of children born in the same years as the ABC and CARE participants (1973-1979), and a similar cohort restricted to black children. We show a comparison in Figure~\ref{figure:baselineabccare}. Compared to both nationally representative groups, ABC children were, on average, significantly more disadvantaged; they were born in households with extremely low total parental income and to younger, less educated mothers, most of whom were raising their children without the support of a father. The CARE participants were similarly disadvantaged compared to nationally representative groups with respect to these basic household socio-demographic characteristics.\\

\subsection{Randomization Protocol and Compromises} \label{section:randomization}

\subsubsection{ABC}

\noindent The first phase of randomization was conducted at the family level, so pairs of siblings and twins were jointly randomized to either treatment or control groups.\footnote{Sibling pairs occurred when the two siblings were close enough in age such that both of them were eligible for the program.} Although we know that the pairing was based on HRI, maternal characteristics, number of siblings, and gender, we do not know the original pairs. The study collected an initial sample of 120 families. Twenty-two children did not complete the first-phase of treatment as initially assigned by the randomization or control (see Table~\ref{table:abccompromises}). We document each case and explain how we classify it to assess it with the methodology in Section~\ref{section:methodology}.\\

\noindent First, there were four children assigned to treatment status who left the study before any data on them was collected. The program staff did not assign them an identifier, and we classify them as Cases A, B, C, and D. In our main methodology, we assume that they are missing at random. Sensitivity exercises assuming that these children had outcomes identical to the child with the lowest outcome in the treatment group suggest that, even in this worst case scenario, treatment-group children do much better if compared to control-group children (see Appendix~\ref{appendix:assessingcc}).\\

\noindent Second, four children died before age 5---two of them initially assigned to treatment and two of them initially assigned to control (these are children were assigned the identifiers ``.x'', 914, 74, and 99). For all of them, we observe baseline characteristics and any other data collected before their dead. For methodological purposes, we include them in any estimations before age 5; they represent cases of program attrition thereafter.\\

\noindent Third, one child moved out from the programs location after age 15 and no data was collected on him after (identifier 82). We consider him part of the control-group sample before at age 15 and before; after, we consider him a case of program attrition.\\

\noindent Fourth, three children in the treatment group did not comply to treatment status (identifiers 900, 912, 922). They are different from Cases A to D because we observe any data collection for them from birth and up to age 8---afterwards, the program staff decided not to follow them anymore for no evident reason. As we explain later in Section~\ref{section:methodology}, our main parameters  of interest are different version of the intent-to-treat. Thus, these children remain as part of the treatment sample in our estimations at age 8 or before. After, they represent cases of program attrition, given that we do not observe them anymore. In Appendix~\ref{appendix:assessingcc} we find little sensitivity to adjusting for non-compliance of these children in the results we show for age 8 or before.\\

\input{output/abc_compromises}

\noindent Fifth, one child initially assigned to control status was enrolled into treatment (identifier 78). Her mother wanted to work and the program staff decided to admit her child into treatment.\footnote{Correspondence with the program officers stating this is available under request from the authors of the present document.} Both in terms of data collection and in terms of methodological purposes, this child is analogous to the children in the third case.\footnote{The sensitivity analysis finding little evidence when adjusting for non-compliance includes this case.}\\

\noindent Sixth, four children treatment-group did not complete treatment in its entirety (identifiers 85, 103, 108, and 123). They were treated for 3, 10, 6, and 9 months, respectively. Except for the childhood follow-ups, in which our main results are not based on, we observe most of the data for these children. We avoid taking a stand on how beneficial was the program at each age, because we do not have a way to document this. Thus, we assume that they were treated as other child in the treatment group.\footnote{If anything, this biases downwards the effects of the program we estimate.} \\

\noindent Seventh, the family of one child in the control group moved at age 54 months (identifier 906). We observe any data collection before the family moved, so we consider the child as part of the control group in any estimation before this event. Afterwards, we do not observe any data on the child, so we consider her a case of program attrition.\\

\noindent Eight, two children initially assigned to treatment status were diagnosed as developmentally delayed after six and thirty-six months of treatment (identifiers 95 and 124, respectively). No data for them is available after the diagnosis. We drop them from the sample because they were not eligible to be part of the program, to begin with, as we explain in Section~\ref{section:eligibility}.\\

\noindent Finally, two children initially assigned to the control group were admitted into treatment (identifiers 82 and 119). Local authorities requested this because the children were considered highly disadvantaged. Data on them is available from birth and up to age 8. We drop these children from the sample, because, most likely, they were not eligible to the program.\\

\noindent The analysis of each of these cases leads to the following conclusions. (i) For four children, we do not have data to methodologically assess them as cases of program attrition, though sensitivity analysis suggest that the treatment effects of the program persist after assigning them the same outcome as the children who did worst in the treatment group. (ii) For the four children who did not comply to treatment (three treatment-group children and one control-group child), adjusting our estimates for non-compliance when data is available makes little difference. (iii) The rest 14 children who did not complete treatment as initially assigned represent different cases of program attrition, for which we propose a methodology in Section~\ref{section:methodology}.\\

\noindent In an effort to increase the number of children in the sample, the program officers recruited additional children before who were added to the program before children were six months old. Although we are not able to know who the replacements are in the sample, the observed characteristics of all the children in the sample indicate that they were eligible to the program---all children in the sample have an HRI of 11 or above (see Figure~\ref{section:eligibility}). Our calculations indicate that there were eight replacements.\footnote{Three replacements are documented in \citet{Ramey_Campbell_1979_SR}. One is documented in correspondence with the program officers, which is available from the authors of the present document upon request. The other four replacements are implied by the number of children who participated of the randomization protocol in each cohort.} Thus, the initial sample consisted of 111 children: 53 treatment children and 58 control children.\\

\noindent Prior to the second phase of randomization, 3 children in the control group of the first phase and 3 children in the treatment group of the first phase stopped being followed because it was impossible to find them. One child in the control group and 8 children in the treatment group of the first phase did not participate in the second phase but later agreed to participate in the data collections during adulthood. This yielded a sample of 96 children in the second phase: 49 in treatment and 47 in control. After randomization, three children in the treatment group chose not to participate in the program, while all children in the control group adhered to their randomization status. Figure~\ref{fig:abc-flow} in Appendix~\ref{appendix:background} illustrates ABC's randomization protocol and the flow of participants throughout the data follow-ups.\\

\subsubsection{CARE}

\noindent The randomization protocol in CARE was analogous to the first-phase of randomization in ABC. Notably, it had no major compromises.\footnote{\citet{Bryant_et_al_1987_Carolina_Approach_TIECSE,Wasik_Ramey_etal_1990_CD,Burchinal_Campbell_etal_1997_CD}.} Of the 65 initial families, 23 were randomized to control, 25 to the family education treatment group, and 17 to the family education and center-based childcare treatment group. Two families in the family education treatment group had twins who were jointly randomized, as in ABC. We document four cases of program attrition (see Table~\ref{table:care_compromises}). For methodological purposes, we consider these children analogous to their corresponding cases in ABC. We do not present exercises to evaluate the sensitivity to non-compliance because there was none in CARE. Figure~\ref{fig:care-flow} in Appendix~\ref{appendix:background} illustrates CARE's randomization protocol and the flow of participants throughout the data follow-ups.\\

\input{output/care_compromises}

\subsection{Program Description and Content}

\noindent The ABC and CARE programs shared many objectives and program characteristics, as summarized in Table~\ref{tab:programcomparison}.\\

\input{output/abccare_programcomparison.tex}

\noindent ABC and CARE shared a main objective: to prevent ``mental retardation" and to develop school readiness for disadvantaged children, starting at birth.\footnote{Note that the clinical understanding of mental retardation was once associated with disadvantages that hindered early-life development \citep{Mental-Retardation_America_2004_BOOK_NYU}.} The different curricula implemented across programs and cohorts had the following common goals: (i) to support language and cognitive development; and (ii) to develop socio-emotional competencies that were considered to enable school readiness---e.g. task orientation, emotional self-expression, independence, sharing, and cooperation.\footnote{\citet{Sparling_1974_Synth_Edu_Infant_SPEECH,Ramey_Collier_etal_1976_CarolinaAbecedarianProject,Ramey-etal_2012-ABC}.} The curricula evolved each year according to recommendations made in studies that used the children's data.\footnote{\citet{Ramey-etal_1975_AJoMD,Finkelstein_1982_Day_Care_YC,Haskins_1985_CD}.}$^{,}$\footnote{The curricula implemented in the first phases of ABC and CARE, including Tools of Mind, shared an emphasis on self regulation---e.g., goal setting and self-reflection---and opportunities for language development. Language development, including phonics and reading skills, is also an important element in other widely implemented curricula such as Opening the World of Learning.}$^{,}$\footnote{Two other renowned early childhood education programs are worth comparing to ABC and CARE. The Infant Health and Development Project (IHDP) was based on the first phase of CARE. IHDP had a single treatment group, which was very similar to the center-based childcare and family education treatment group of CARE. The curricula implemented both at home and at center-based childcare were very similar. The main difference is that the first phase of CARE lasted 5 years, while IHDP lasted 3 years and did not have a second phase. Both ABC and CARE were notably different from the Nurse Family Partnership (NFP) program. NFP had fewer visits and began in the pre-natal period. Mothers received monthly visits during pregnancy and one visit every two months from when the child was born until the age of 2. The visitors were nurses and they tried to help women build relationships with friends and family to create a support network for their children. A common element of the three programs is that the visitors helped parents use community resources when solving their everyday problems.}\\

\noindent Both treatment groups in CARE incorporated home visits, which aimed to help parents resolve everyday problems that could adversely affect relationships with their children, as well as to improve the general skills associated with parenting. Generally, the home visits were weekly and one hour long. Between birth and the age of 3, participants in the family education and center-based childcare and family education groups received, on average, 2.5 and 2.7 visits a month, respectively. At ages 4 and 5, the average frequency decreased to 1.4 and 1.1 visits per month.\\ 

\noindent The first phases of ABC and CARE were conducted in conjunction with a longitudinal medical research study on infectious respiratory diseases in group environments.\footnote{\citet{Henderson-et-al_1982_NEJoM}.} This study allowed the children to have comprehensive medical care in the same center in which they received center-based childcare. The children who attended the center received daily screenings to detect any signs of illness. This included all the children in the treatment group of ABC and all the children in the center-based childcare and family education group of CARE. The first cohort of the control group of ABC also received frequent medical check-ups during the first year of the first-phase of the program.\\

\noindent The children assigned to treatment in the first phase of ABC also received primary pediatric care by a family nurse practitioner and a licensed practical nurse, who were supervised by a pediatrician who was on continuous duty at the childcare center. This care consisted of wellness check-ups, immunizations, parental counseling, and initial assessments of illnesses. Like the other treatment components, pediatric care was free of charge. Unfortunately, there is no documentation or corresponding evidence for whether this aspect of treatment was available to the treatment groups of CARE.\\

\noindent For both ABC and CARE, children in the programs' center-based childcare were provided breakfast, lunch, and an afternoon snack, planned by a nutritionist. Children in the control groups of both programs received diapers from birth until the age of 3, and an unlimited supply of bottled formula from birth until 15 months. Neither of the control groups in both programs nor CARE's family education treatment group received any program medical care, with the exception of the first cohort of control children in ABC, as explained above.\\

\noindent The second phase of both ABC and CARE, also referred to as school-age treatment, lasted for the first three years of elementary school and incorporated home visits by a teacher. The visits aimed to increase the child's exposure to reading and mathematics and to promote parental involvement in the learning process. These visits occurred every two weeks in the presence of the parents. At the visits, the teachers discussed the children's programs and helped parents with issues related to literacy, housing, and medical care.\\

\subsection{Treatment Substitution}

\noindent The interpretation of treatment and control group comparisons depends on how the control group substituted treatment, posing a methodological challenge when answering policy-oriented questions. In both programs, many children without access to center-based childcare through random assignment nevertheless attended alternative preschools. In this section, we characterize the types of care received by the treatment group. We propose a methodology to answer relevant policy-questions in Section~\ref{section:methodology}.\\

\begin{figure}[H]
		\caption{Treatment Substitution, ABC} \label{fig:treatsubabc}
		\includegraphics[width=.9\columnwidth]{output/abc_controlcontamination_months.eps}
\floatfoot{
\footnotesize
\noindent Note: This figure displays the cumulative density function of enrollment in an alternative preschool for the control group in ABC.}
\end{figure}

\noindent In ABC, $65\%$ of control-group children was enrolled in one of 11 local center-based childcare centers (see Figure~\ref{fig:treatsubabc}). Each of these centers received federal subsidies and were therefore regulated by the Federal Interagency of Daycare Requirements. Therefore, their staff members were required to be trained in early childhood education and the centers were required to implement approved curricula designed to enhance cognitive, social, and linguistic competence in disadvantaged children.\footnote{\citet{Burchinal_etal_1989_CD_Daycare-Pre-K-Dev}.} In CARE, slightly more than $70\%$ of the control group and $60\%$ of the family education group were enrolled in alternative preschools by their parents (see Figure~\ref{fig:treatsubcare}). The parents of the children in both of these groups had as options the same set of local center-based childcare centers as the ABC children in the control group.

\begin{figure}[H]
		\caption{Treatment Substitution, CARE} \label{fig:treatsubcare}
		\includegraphics[width=.9\columnwidth]{output/care_controlcontamination_months.eps}
\floatfoot{
\footnotesize
\noindent Note: This figure displays the cumulative density function of enrollment in an alternative preschool for the control and family education treatment groups in CARE.}
\end{figure}
 

\subsection{Data} \label{section:data}

\noindent Table~\ref{tab:datasumm_1} and Table~\ref{tab:datasumm_2} summarize our data availability. The collection process was analogous in both programs. The treatment and control groups were followed into adulthood with relatively low attrition. For ABC, children were followed annually through elementary school and at ages 12, 15, 21, and 30. Health and administrative crime data were collected when the children reached their mid-30s. For CARE, the exact same follow-ups are available with the exception of the age 15 follow-up.\\

\input{output/abccare_data}

\noindent Information on developmental progress, schooling, home environment, and parental characteristics was recorded through early childcare, elementary school, and at age 21. The data include measures of the child's IQ, achievement test scores, health status, risky behavior, schooling, social interactions, socio-emotional status, and non-cognitive skills. The data also include family and household variables, such as parents' labor market participation, household income, parental IQ, parental schooling, and parental attitudes toward child-rearing. For ages 21 and 30, information on labor market outcomes, income, educational attainment, relationship histories, health statuses, household statuses, risky behavior, and criminal activity is available.\\

\noindent For ABC, information is available on 100 children in the age 30 follow-up, which we call the adult follow-up. In addition, 80 participants---40 from the control group and 40 from the treatment group---consented to the release of their criminal records. Further, 70 participants consented to the release of information regarding a full-range biomedical panel---31 from the control group and 39 from the treatment group. Examples of measures in the health data include incidence of diabetes and high blood pressure, waist-to-hip ratio, height and weight, and cholesterol levels. For CARE, the available data is similar. In Appendix~\ref{appendix:randomization}, we document balance in observed, baseline characteristics across the treatment and control groups, once we drop the individuals for whom we have crime or health information. Further, the methodology we propose addresses missing information in either of these two data categories.

\section{Methodology} \label{section:methodology}

\subsection{Parameters of Interest and Policy Questions} \label{section:methodsquestions}

\noindent Random assignment to treatment does not guarantee that simple estimators commonly used in the literature are able to answer policy-relevant questions. For estimators to properly inform policy-making, they must relate to policy-relevant parameters. These parameters make a clear statement of the program being evaluated and the counterfactual scenario with respect to which the program is being compared.\\

\noindent In this section, we outline our methodology for estimating policy-relevant parameters of interest. We start by comparing children who \textit{take up} treatment to children who did not. Thus, for the moment, we think of estimating the effect of ABC's first phase of treatment. We clarify how to incorporate the second phase of treatment and multiple, simultaneous treatments afterwards.\\

\noindent Let $D$ be an indicator of treatment take-up: $D = 1$ if the child took-up treatment and $D=0$ if she did not. Let $Y$ be an outcome of interest. We write

\begin{equation}
Y = D Y_{1} + \left( 1 - D \right) Y_{0}, 
\end{equation}

\noindent where $Y_{1}$  is the outcome when she is fixed to a counterfactual scenario in which she takes up treatment; $Y_{0}$ is her outcome when fixed not to take up treatment.\\

\noindent An alternative to evaluate the treatment a program offers is to compare the expectation of $Y_{1}$ ($\mu_{1}$) to the expectation of $Y_{0}$ ($\mu_{0}$). That is, to test the hypothesis 

\begin{equation}
H_{0}^A: \mu_{0} = \mu_{1}. \label{eq:ho}
\end{equation}\\

\noindent We follow this alternative because it allows us to provide a transparent explanation of the methods with which we account for treatment substitution and program attrition. We can extend these methods to test various other hypothesis---e.g., difference in higher order moments, rank differences, etc.\\

\noindent \begin{assumption} \label{assumption:pc} \normalfont (Perfect Compliance) Let $R$ indicate randomization to treatment and $D$ indicate treatment take-up. Perfect compliance occurs whenever  $R = D$.\end{assumption}

\noindent Under Assumption~\ref{assumption:pc}, it is straightforward to test \eqref{eq:ho}: it is equivalent to test if the intent-to-treat (ITT) estimator is different from zero. This estimator is defined as 

\begin{equation}
\text{ITT} = \mathbb{E} \left[ Y | R = 1 \right] - \mathbb{E} \left[ Y | R = 0 \right]. \label{eq:itt}
\end{equation}\\ 

\noindent Given perfect compliance to randomization status, the ITT tests \eqref{eq:ho} because $\mathbb{E} \left[ Y | R = 1 \right]$ and $\mathbb{E} \left[ Y | R = 0 \right]$ identify the expectations of outcome $Y$ when the individual is fixed to treatment and control, respectively. The ITT is simply the difference between the expectations of the distributions of $Y_{0}$ and $Y_{1}$. It is related to the following policy question: what is the effect of fixing an individual to treatment status, relative to fixing her to control status?\\

\noindent In ABC, however, there were randomization compromises we need to assess in order for the ITT to represent an adequate estimator to test the hypothesis in \eqref{eq:ho}. After age 8, all the compromises consist of cases of program attrition. That is, we stop observing data from the children in the subsequent data collections. Before age eight there were cases of non-compliance into the initial assignment to treatment. We propose a methodology to address the latter and not the former for three reasons: (i) most of our analysis focuses on outcomes after age 8; and (ii) for outcomes after age 8, non-compliance becomes program attrition because we do not observe data on children who did not comply after age 8; and (iii) when studying the sensitivity of the results before age 8 to non-compliance, we find little sensitivity (see Appendix~\ref{appendix:assessingcc}).\\

\noindent To account for program attrition, we propose a correction to the elements that compose the ITT. Let $A$ denote denote program attrition: $Y_{d} \left(\text{fix } A = a \right)$ represents the counterfactual outcome $Y$ when $A$ is fixed to no program attrition ($A = 0$) or program attrition ($A = 1$). It is not necessarily the case that 

\begin{equation}
\mathbb{E} \left[ Y_{d} | \text{fix } A = 0 \right]  = \mathbb{E} \left[ Y_{d} | \text{fix } A = 0  \right].
\end{equation}\\

\begin{assumption} \normalfont \label{assumption:balance} (Conditional Independence in Program Attrition) The expectation of the counterfactual outcome $Y_{d} \left(\text{fix } A = a \right)$ is independent of the value on which $A$ is fixed, after conditioning on observed characteristics, $X$: 

\begin{equation}
\mathbb{E} \left[ Y_{d} | \text{fix } A = a, X \right] = \mathbb{E} \left[ Y_{d} | X \right].
\end{equation}

\end{assumption}

\noindent Under Assumption~\ref{assumption:balance}, we are able to correct our estimates of $\mathbb{E} \left[ Y | R = 1 \right]$ and $\mathbb{E} \left[ Y | R = 0 \right]$ for program attrition by using an inverse-probability weighting (IPW) scheme. In other words, we can weight the data to achieve balance in the observed characteristics of children for who we have program attrition and children for who we do not. Assumption~\ref{assumption:balance} states that once $X$ is balanced, program attrition does not affect the counterfactual distributions of interest, so we are able to identify them. Once we account for program attrition, the ITT represents the average treatment effect of ABC as implemented, rather than relative to a specific alternative preschool. For clarity, we omit the argument $A$ henceforth, although in our empirical application we show estimates correcting for program attrition.\\

\noindent The standard ITT does not account for the fact that almost $70 \%$ of control-group children enrolled in different preschool alternatives across both programs. Therefore, this estimator only captures the effects of the program relative to the available supply of alternatives when the programs was implemented.\footnote{If the preschool alternatives were beneficial for the children in the control group, the ITT is attenuated. This is common in early childhood education programs in which alternatives are close in quality to the program itself. Perhaps the most iconic example is the randomized evaluation of Head Start, the Head Start Impact Study, in which $15\%$ of children in the control group had access to alternative Head Start centers. ITT estimates reported by \cite{Puma_Bell_etal_2010_HeadStartImpact} are close to zero. However, this does not mean that the efficacy of Head Start is low, but rather that Head Start treatment is being compared to close substitutes when computing the ITT.} \\

\noindent To measure the effect of ABC as a program \emph{per se}, it is more meaningful to estimate the effect of treatment relative to a counterfactual in which all children are fixed to the same alternative---e.g. staying at home, attending a low-quality preschool. Answering this question requires  to account for treatment substitution in the control group. By fixing the children who did not take up treatment into a homogeneous alternative, we can more meaningfully compare children in the treatment and control groups. \\

\noindent Let $P$ indicate whether a child attended a substitute preschool. The value of $P$ could either be fixed to indicate no take-up of a preschool alternative ($P = 0$) or take-up of a preschool alternative $(P = 1)$. We are interested in the following hypotheses: 

\begin{eqnarray}
H_{0}^B &:& \mathbb{E} \left[ Y_{0} | \text{fix } P = 0 \right] =  \mathbb{E} \left[ Y_{1} | \text{fix } P = 0 \right] \label{eq:hoB} \\
H_{0}^C &:&  \mathbb{E} \left[ Y_{0} | \text{fix } P = 1 \right] =  \mathbb{E} \left[ Y_{1} | \text{fix } P = 1 \right] \label{eq:hoC}. 
\end{eqnarray}\\

\noindent That is, we want to compare the counterfactual treatment distributions when fixing children to no alternative preschool ($H_{0}^B$) and when fixing children to alternative preschool ($H_{0}^C$).\footnote{This treats alternative preschool as a binary decision, although it is continuous as we show in Figure~\ref{fig:treatsubabc}. We take this approach because we are limited by our sample size when predicting preschool take-up as we show in Appendix~\ref{appendix:methodology}.}\\

\noindent To contrast these hypotheses, consider the following estimators: 

\begin{eqnarray}
\text{ITT} \left( \text{fix } P = 0 \right) &=& \mathbb{E} \left[ Y | R = 1, \text{fix } P = 0 \right] - \mathbb{E} \left[ Y | R = 0, \text{fix } P = 0 \right] \label{eq:ittp0} \\
\text{ITT} \left( \text{fix } P = 1 \right) &=& \mathbb{E} \left[ Y | R = 1, \text{fix } P = 1 \right] - \mathbb{E} \left[ Y | R = 0, \text{fix } P = 1 \right]. \label{eq:ittp1}  
\end{eqnarray}\\

\noindent Estimating the expectations in \eqref{eq:ittp0} and \eqref{eq:ittp1} is not as straightforward as computing the expectations in \eqref{eq:itt} because families select whether or not to enroll their children into preschool alternatives.\\

\begin{assumption} \normalfont \label{assumption:matching} (Conditional Independence in Preschool Alternatives Enrollment) The expectation of the counterfactual outcome $Y_{d} \left( \text{fix } P=p \right)$ follows the same distribution regardless of the value to which $P$ is fixed, after conditioning on $X$ (observed characteristics): 
\begin{equation}
\mathbb{E} \left [ Y_{d} | \text{fix } P=p, X  \right] = \mathbb{E} \left [ Y_{d} | X  \right].
\end{equation}
 \end{assumption}

\noindent Assumption~\ref{assumption:matching} states that the observed characteristics in $X$ account for the parental decision of whether or not to enroll the child in preschool alternatives.\\

\noindent The estimates for $\text{ITT} \left( \text{fix } P = 0 \right) $ and $\text{ITT} \left( \text{fix } P = 1 \right)$ relate to the second policy question, which evaluates the efficacy of ABC as a program \emph{per se}. Once program attrition is accounted for, the ITT estimates represent the average treatment effect of ABC relative to receiving no treatment at all and relative to receiving a \textit{fixed} preschool alternative.\\

\noindent To illustrate, suppose we want to estimate $\text{ITT} \left( \text{fix } P = 0 \right)$ using a linear and separable parameterization. We estimate the following model: 

\begin{equation}
Y = \Delta \left( \text{fix } P = 0 \right) R + X \beta + \varepsilon, 
\end{equation}

\noindent which provides a consistent estimate for $\Delta \left( \text{fix } P = 0 \right)$ under Assumption~\ref{assumption:matching}. $\Delta \left( \text{fix } P = 0 \right)$ is the average treatment effect of ABC with respect to a well-defined alternative: no center-based childcare. To account for program attrition in this framework, we could weight the linear regression with individual-level estimates of the probability of program attrition.\\

\noindent We present estimates of $\Delta \left( \text{fix } P = 0 \right)$ and $\Delta \left( \text{fix } P = 1 \right)$ using this parameterization and using other alternatives to more flexibly  condition on $X$---e.g., nearest-neighbor matching, propensity-score matching, and kernel-based weighting.

\subsection{Multiple Treatment Groups}

\noindent We can readily apply the methodology in Section~\ref{section:methodsquestions} to test the hypotheses specified in \eqref{eq:ho}, \eqref{eq:hoB}, or \eqref{eq:hoC} for ABC.\\

\noindent In CARE, however, there were two treatment groups. A simple extension of the framework in Section~\ref{section:methodsquestions} allows us to test various hypotheses that measure the effectiveness of the program.\\

\noindent As before, let $Y_{d}$ denote a counterfactual outcome. $Y_{0}$ corresponds to fixing the child to no treatment take-up;  $Y_{1}$ to take-up of family education treatment; $Y_{2}$ to center-based childcare and family education treatment.\footnote{To adjust for program attrition, we can apply a weighting method as in Section~\ref{section:methodsquestions}.} To evaluate the program, we consider the following hypotheses: 

\begin{eqnarray}
H_{0}^D: \mathbb{E} \left[ Y_{0} \right] &=&  \mathbb{E} \left[ Y_{1} \right] \\ 
H_{0}^E: \mathbb{E} \left[ Y_{0} \right] &=&  \mathbb{E} \left[ Y_{2} \right] \\
H_{0}^F: \mathbb{E} \left[ Y_{1} \right] &=&  \mathbb{E} \left[ Y_{2} \right]. 
\end{eqnarray}\\

\noindent The first null hypothesis implies that family education has no average treatment effect, while the second null hypothesis implies that the center-based childcare and family education have no average treatment effect. The third hypothesis implies that the two treatments have the same average effect, which could be no average effect at all. The three hypotheses help to evaluate the program as implemented. That is, without correcting for alternative preschool enrollment of the children in either the family education treatment or the control groups. We can test these hypotheses constructing ITT estimators analogous to \eqref{eq:itt}.\\ 

\noindent Alternatively, we can measure the average treatment effect of CARE by fixing the counterfactual scenarios to a given setting of preschool alternative. Fixing a preschool alternative is as relevant to CARE as it is to ABC since substantial numbers of children in the control groups for both programs were enrolled in alternative preschools (see Figure~\ref{fig:treatsubcare}). Under Assumption~\ref{assumption:matching}, we are able to construct ITT estimators fixing $P$ at either no preschool alternative or preschool alternative, as in \eqref{eq:ittp0} and \eqref{eq:ittp1}. We present estimates that account for $X$ using different parameterizations.\\

\subsection{Combining ABC and CARE}

\noindent An alternative method for evaluating the first phases of ABC and CARE is to combine the data from both programs and to test effects for the common elements of their designs. The ABC treatment group and the CARE center-based childcare and family education treatment group were subject to the same center-based childcare treatment component, with the CARE children receiving an additional family education component. If there is no evidence for the treatment effect of family education in CARE, then any effect of center-based childcare and family education treatment in CARE can be attributed to the center-based childcare component, which was shared with ABC. We outline a methodology to combine the data and to exploit this fact.\\

\noindent Suppose that we fail to reject $H_{0}^D$. That is, we fail to reject that the distribution of the outcome of interest differs in the family education group, relative to the control group. Suppose further that we reject $H_{0}^F$, so that the counterfactual distributions of family education and center-based childcare and family education treatments differ. Together, this evidence favors assuming that center-based childcare was the main component generating treatment effects in CARE, if there were any. If this claim holds, we can pool the children fixed to control in ABC and CARE and pool the children fixed to treatment in ABC and to center-based childcare and family education treatment in CARE to test \eqref{eq:ho}, the effect of center-based childcare. Moreover, we can fix the children in the treatment groups to either no alternative preschool or to alternative preschool. We can then proceed as in Section~\ref{section:methodsquestions} to construct the estimates and correct for non-compliance.\footnote{This reasoning implicitly imposes that there is no interaction reinforcing the two treatments CARE offered. Our evidence supports this implicit assumption: when evaluating the effect of center-based childcare either by (i) comparing the treatment and control groups of ABC; or (ii) pooling the treatment group of ABC and the treatment group of of CARE receiving center-based childcare and family education and comparing it to a group pooling the control groups of both programs and the family education treatment group we find very similar results.}\\

\noindent We report results in Section~\ref{section:results} for these two methods of combining information in ABC and CARE.

\subsection{Second-phase Treatment}

\noindent ABC and CARE had by design comparable second phases of treatment. In ABC, children were randomized to the second phase, which enables the testing of a series of hypotheses measuring the efficacy of the treatment. In order to do this, we consider an additional dimension in the sub-index of the counterfactual outcome notation. Let $S$ indicate random assignment to the second phase of treatment and $Y_{d,s}$ be a counterfactual outcome defined by treatment take-up of the two phases of the program. That is, a counterfactual outcome allowing to fix two dimensions of treatment take-up.\\

\begin{sidewaystable}[H] 
\begin{threeparttable}
\caption{First-phase and Second-phase Hypotheses}
\label{table:hypotheses}
\centering 
\begin{tabular}{ccc} \toprule
 & Fixing First-phase Treatment & Fixing Second-phase Treatment \\ \\ \midrule
Fixed to control       & $H_{0}^G: \mathbb{E} \left[ Y \text{ fix } D = 0, S = 0 \right]  = \mathbb{E} \left[ Y \text{ fix } D = 0, S = 1 \right]$ & $H_{0}^H: \mathbb{E} \left[ Y \text{ fix } D = 0, S = 0 \right] = \mathbb{E} \left[ Y \text{ fix } D = 1, S = 0 \right]$ \\
Fixed to treatment  & $H_{0}^I: \mathbb{E} \left[ Y \text{ fix } D = 1, S = 0 \right] = \mathbb{E} \left[ Y \text{ fix } D = 1, S = 1 \right]$ & $H_{0}^J: \mathbb{E} \left[ Y \text{ fix } D = 0, S = 1 \right] = \mathbb{E} \left[ Y \text{ fix } D = 1, S = 1 \right]$ \\ \\ \midrule
Not fixed                 & $H_{0}^K: \mathbb{E} \left[ Y \text{ fix } D = d, S = 0 \right] = \mathbb{E} \left[ Y \text{ fix } D = d, S = 1 \right]$ & $H_{0}^A: \mathbb{E} \left[ Y \text{ fix } D = 0, S = s \right] = \mathbb{E} \left[ Y \text{ fix } D = 1, S = s \right]$ \\  \toprule
\end{tabular}
\begin{tablenotes}
\footnotesize
\item Note: This table displays the hypotheses we test for the counterfactual distributions of an outcome $Y$, when fixing first-stage treatment status to treatment ($R = 1$) or control ($R = 0$) and/or second-stage treatment status to treatment ($S = 1$) or control ($S = 0$).
\end{tablenotes}
\end{threeparttable}
\end{sidewaystable}

\noindent Table~\ref{table:hypotheses} outlines the different hypotheses we are able to test. To illustrate how we construct the tests, consider the following hypothesis: 

\begin{equation}
H_{0}^G: \mathbb{E} \left[ Y \text{ fix } D = d, S = 0 \right]  = \mathbb{E} \left[ Y \text{ fix } D = d, S = 1 \right]  \label{eq:h0fixfirst}
\end{equation}

\noindent In words, we test the effect of second-phase treatment, fixing first-phase treatment to control status. Following the methodology in Section~\ref{section:methodsquestions}, we can construct an ITT to test this hypothesis: 

\begin{eqnarray}
\text{ITT} = \mathbb{E} \left[ Y | R = 0, S = 1 \right] - \mathbb{E} \left[ Y | R = 0, S = 0 \right]. 
\end{eqnarray}

\noindent Perfect compliance to treatment allows us to identify the expectation of the outcome when fixing first-phase treatment to control status and the second-phase treatment to treatment status---$\mathbb{E} \left[ Y_{0,1} \right]$---by using its empirical counterpart: $\mathbb{E} \left[ Y | R = 0, S = 1 \right]$. Similarly, we are able to identify $\mathbb{E} \left[ Y_{0,0} \right]$ using $\mathbb{E} \left[ Y | R = 0, S = 0 \right]$. With imperfect compliance, we can use the weighting method in Section~\ref{section:methodsquestions} to identify and estimate these expectations. The tests in which the first phase of treatment is fixed proceed similarly.\\

\noindent Alternatively, it is also meaningful to test if the second phase of treatment had an effect independent of assignment in the first phase. That is, we test 

\begin{equation}
H_{0}^K: \mathbb{E} \left[ Y \text{ fix } D = 0, S = s \right] = \mathbb{E} \left[ Y \text{ fix } D = 1, S = s \right] \label{eq:h02}
\end{equation}

\noindent where $d \in \{0,1\}$. The hypothesis in \eqref{eq:h02} is the second-phase counterpart to the hypotheses in \eqref{eq:ho} and addresses the effectiveness of the second phase of ABC. Importantly, the test does \emph{not} consider dynamics between the first and second phases of treatment, while hypotheses that fix the first phase of treatment do consider these dynamics.\\

\noindent We report results for tests of the presented hypotheses, while also fixing the first-phase alternative for preschool, as we explain in Section~\ref{section:methodsquestions}.

\subsection{Treatment Effects on Multiple Outcomes}

\noindent While our discussion thus far addresses how to test the effectiveness of the interventions at improving a single life-cycle outcome, human development is ultimately multidimensional. Therefore, we want to exploit the numerous measures of human development throughout the participants' lifetimes in both ABC and CARE to test the effect of the program in numerous dimensions. \\

\noindent In our companion paper, \citet{Elango_et_al_2015_ABC_unpublished}, we offer one method for measuring the effectiveness of a program using two statistics: the benefit-to-cost ratio and the internal rate of return. To do this, we account for the life-cycle gains of the program in several dimensions such as employment, income, government transfers, health, and crime. A simpler but informative alternative is to count the number of socially-positive outcomes that the program influences an inference methodology for this procedure.\\

\noindent This latter method requires classifying each outcome as socially positive or negative, which is inherently biased. In the interest of objectivity, we present the counts on 141 outcomes, all of which we think are either unambiguously socially positive or unambiguously socially negative. We offer some relevant examples in Section~\ref{section:data}.\\

\noindent The different counts we propose are forms of combining functions \citep{Pesarin_Salmaso_2010_PermutationTests}.\footnote{This reference offers a comprehensive treatment of combining functions.} These functions combine information on several outcomes for testing patterns in a scientific or social phenomenon---in our case, an early childhood education program. For instance, suppose we want to test the hypothesis: 

\begin{equation}
H_{0}^A: \mathbb{E} \left[ Y_{0} \right] =  \mathbb{E} \left[ Y_{1} \right] \label{eq:hoagain}
\end{equation}

\noindent for multiple outcomes $Y$, and that, for each outcome individually, we already have an inference procedure readily available---i.e., we know the hypothesis, the statistics we use to test it, and the $p$-value associated with the test. For instance, we want to test \eqref{eq:hoagain} using the ITT and a bootstrapped, non-parametric $p$-value.\\

\noindent We consider three counts. First, a count of the socially positive treatment effects. We can calculate this count over the complete set of outcomes or certain categories of outcomes (e.g. employment, health, crime), without consideration of their significance when \eqref{eq:hoagain} is individually tested. Next, we count the outcomes that are significantly socially positive at the $10\%$ level, when hypothesis \eqref{eq:hoagain} is individually tested. Finally, we use the same sum but at a $5\%$ significance level.\\

\noindent Consider constructing a combining function---in our case, a count---for a group or block of outcomes $\mathcal{O}^g$ with $g \in \mathcal{G}$, where $\mathcal{G}$ is the index set for the groups of outcomes.\footnote{It is not necessarily the case that the groups in $\mathcal{G}$ are exclusive. It could be of interest to study groups which have overlapping outcomes. The test does not require the groups to be exclusive.} Alternatively, we can construct the count for $\mathcal{O} : =  \bigcup \limits _{g \in \mathcal{G}} \mathcal{O}^g$. Each group includes the number of outcomes $\# \mathcal{O}^g$ and an associated sequence of treatment effects $\{ \widehat{\Delta}_{j}^{g} \}_{j = 1}^{\# \mathcal{O}^g}$. The test statistic for group $g$ is the count. For example, if we count the number of socially positive outcomes, the test statistic for group $g$ is 

\begin{equation}
T_{g} = \sum _{j=1}^{\# \mathcal{O}^g} \mathbf{1} \left[ \widehat{\Delta}_{j}^{g} > 0\right]. 
\end{equation} 

\noindent For inference purposes, we bootstrap this procedure and construct a null distribution. The $p$-value for the number of socially positive treatment effects in group $g$ is $1 - \widehat{F}_{g} \left( T_{g} \right)$, where $ \widehat{F}_{g}$ is the empirical bootstrap distribution of group $g$. The procedure is analogous when constructing statistics for the second and third combining functions.\\

\noindent In Section~\ref{section:results}, we present tests for the three combining functions for different groups of outcomes and for the unions of all of these group of outcomes, $\mathcal{O}$.

\section{Results} \label{section:results}

\section{Final Comments} \label{section:conclusion}

%References
\clearpage
\singlespace
\bibliographystyle{chicago}
\bibliography{heckman}

\end{document} 