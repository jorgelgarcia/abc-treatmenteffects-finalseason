%Input preamble
\input{preamble}

\externaldocument{abccaretreatmenteffects_report_main_appendix}

\begin{document}
\title{\Large \textbf{Analyzing the Short- and Long-term Effects of Early Childhood Education on Multiple Dimensions of Human Development}\thanks{This research was supported in part by the American Bar Foundation; the Pritzker Children's Initiative, the
Buffett Early Childhood Fund, NIH grants NICHD R37HD065072, NICHD R01HD54702, and NIA R24AG048081, an
anonymous funder, Successful Pathways from School to Work, an initiative of the University of Chicago's Committee
on Education funded by the Hymen Milgrom Supporting Organization, and the Human Capital and Economic
Opportunity Global Working Group, an initiative of the Center for the Economics of Human Development, affiliated with
the Becker Friedman Institute for Research in Economics, and funded by the Institute for New Economic Thinking. The
views expressed in this paper are solely those of the authors and do not necessarily represent those of the funders or
the official views of the National Institutes of Health. For helpful comments, we thank St\'{e}phane Bonhomme, Steven Durlauf, and Azeem Shaikh. For information on the implementation of the Carolina Abecedarian Project and assistance in data acquisition, we thank Peg Burchinal, Carrie Bynum, Frances Campbell, and Elizabeth Gunn. For information on childcare in North Carolina, we thank Richard Clifford and Sue Russell. For exceptional research assistance, we thank Thomas Choi. Lastly, we thank Sylvi Kuperman for sharing detailed and careful descriptions of the Carolina Abecedarian Project.}}

\author{
Jorge Luis Garc\'{i}a\\
The University of Chicago \and
James J. Heckman \\
American Bar Foundation \\
The University of Chicago \and
Andr\'{e}s Hojman\\
The University of Chicago \and
Yu Kyung Koh \\ 
The University of Chicago \and
Joshua Shea \\
The University of Chicago \and
Anna Ziff \\ 
The University of Chicago}
\date{First Draft: January 5, 2016\\ This Draft: \today}
\maketitle

\singlespacing
%\pagebreak
\tableofcontents
\listoffigures
\listoftables
%\pagebreak


\textbf{[MT: Put this somewhere, footnote or else, in results section:]}

MAKE TABLE Appendix~\ref{appendix:data}

We employ a two-step procedure in selecting our control variables. In the first step, we estimate a series of linear probability models for enrollment into alternative preschool for subjects randomized out of treatment. In each model we condition on an indicator for sex, and three additional variables chosen from a list of 18 variables that we believe to potentially impact either outcomes or the decision to enroll in alternative preschool. These variables are listed below in Table~\ref{tab:pselectvars}.  We fit each of the $18 \choose 3$ models to the data, and select the set of covariates generating the lowest BIC to be the first subset of the controls we use in our main estimations.

In the second step, we perform a similar procedure for every outcome of interest. Namely, we estimate a linear model for every outcome, regressing the outcome variable on treatment, an indicator variable for sex, and three additional covariates. The three covariates are chosen from a list of 15 variables, a subset of the 18 variables after removing those we believe to only impact the decision to enroll in alternative preschool and not the outcomes of interest. For each outcome, we rank each of the $15 \choose 3$ models by the \textbf{[MT: BIC MAKE EXPLICIT BAYESIAN INFO CRIT]} value. We then sum the ranks over all the outcomes to determine which model best fits the data. The three covariates we permute over from this model are then pooled with those from the first step of the model selection procedure to form the set of controls we use in our main estimations.




\section{Introduction}

\noindent One of President Barack Obama's policy goals throughout his tenure has been the promotion of early childhood education as a means of reducing socio-economic inequality \citep{Bajaj_Labaton_2009_ObamaRiskAssets,White_House_2014_Econ_of_EC_Investments,White_House_2014_Fact_Sheet_Press}. Candidates across the political spectrum to succeed President Obama also consider early childhood education an important component of their agendas.\footnote{Candidates from both parties consider access to education a right Americans should have; all make particular emphasis on early childhood education \citep{Hillary-for-Am_2016_Universal-Preschool,On-the-Issues_2016_Sanders-on-Families,On-the-Issues_2016_Cruz-on-Education}.}\\ 

\noindent Public funding of early childhood education has been on the rise in recent years with the intention of reducing socio-economic inequality \textbf{[MT: If you don't have a cite for this ``intention'' then remove.]}. The Education Commission of the States reports that 32 states increased spending on early childcare for the 2015-2016 year, with an overall state-spending increase of 12 percent. Similarly, the federal budget proposal for 2017 included an approximately \$300 million increase in spending on early childhood education.\\

\noindent Despite the importance of early childhood education both in the public debate and in the allocation of the government's budget, comprehensive and methodologically rigorous evidence on its efficiency and effectiveness  is still scarce. Many recent studies suffer from one or more of the following pitfalls: (i) they focus on a limited set of outcomes that fail to account for the complete set of program impacts;\footnote{An extreme example is the evaluation of preschool programs using an age-eligibility cutoff. A battery of studies compare children who were just eligible to preschool to children who were just ineligible to preschool given their birth dates and assess the gain of an additional year of preschool. This does not represent a comprehensive evaluation approach. Instead, it is an evaluation comparing an specific set of children, in a very narrow set of tests and within a time horizon of a single year. Examples of these studies include: \citet{Gormley_Gayer_2005_JHR,Gormley_Gayer_etal_2005_DP,Weiland_2013_CD_Impacts-of-Pre-K}.} (ii) they do not take into account that, even when based on randomized controlled trials, non-compliance to treatment and treatment substitution by the control families make standard evaluation parameters loose policy relevance;\footnote{A relevant example is the evaluation of Head Start through its randomized controlled trial, the Head Start Impact Study \citep{Puma_Bell_etal_2010_HeadStartImpact}. Comparing the children in the treatment and the control groups usually yields relatively low gains. This attenuation happens because a substantial proportion of children randomized out of the program were enrolled into preschool alternatives, some of them to other Head Start centers. Thus, a raw comparison between the treatment- and the control-group children does not inform on either the efficiency or the effectiveness of Head Start. Studies providing a methodology to account for treatment substitution find that Head Start has substantial effects, although they focus on a single, short-term outcome \citep{Kline-Walters_2015_NBER-Evaluating,Feller_Grindal_etal_2016_ComparedtoWhat}.} or (iii) they evaluate randomized controlled trials with flawed designs.\footnote{An evaluation of the Tennessee Voluntary Prekindergarten is an emblematic example of this \citep{Lipsey_et_al_2013_Tennessee_Kindergrtn_PRI,Lipsey_et_al_2015_Randomized_Control_Trial_PRI}. The researchers designed a randomized controlled trial to evaluate the program. Unfortunately, they asked permission to assess the children after the randomization protocol. Thus, their main evaluation is based on information for children whose parents agreed for them to be evaluated \textit{post} randomization, inducing a potential imbalance between the children randomized into and out of the program. The evaluation does not account for that. Further, the results this evaluation presents are on a narrow and short-term set of outcomes.}\\ 

\noindent  The case for the effectiveness and the economic efficiency of early childhood education in the U.S. is largely based on evidence from the Perry Preschool Program (referred to simply as Perry). Analyses of Perry suggest that (i) early childhood education has significant positive effects on multiple short- and long-term socio-economic outcomes, even when accounting for compromised randomization, small-sample-size inference, and multiple hypotheses testing \citep{Heckman_Moon_etal_2010_QE}; and (ii) early childhood education could have an annual internal rate of return that ranges between 7 and 10 percent.\footnote{If one dollar were to be invested at age 4, and then reinvested annually and compounded over a lifetime, the return would accrue to 60 to 300 dollars by age 65. This accounts for the program's cost and the social burden a government would cause by raising taxes to pay for it \citep{Heckman_Moon_etal_2010_RateofReturn}.}\\

\noindent A frequent criticism of the evidence favoring the economic case for early childhood education is the lack of an ampler evidence base. In response, we present a rigorous evaluation of two related randomized controlled trials: the Carolina Abecedarian Project (ABC) and the Carolina Approach to Responsive Education (CARE).\\ 

\noindent ABC and CARE were programs implemented in the 1970s and early 1980s. Therefore, we observe long-term outcomes for their participants. The programs were separated into two phases. In the first phase, both programs assigned high-quality center-based childcare to children from ages 0 to 5. In addition, the children who were assigned center-based childcare in CARE also received home visits that aimed to foster the relationship between participating children and their parents. Furthermore, CARE incorporated a second treatment group that received home visits without center-based childcare. The second phase of treatment, from ages 5 to 8, consisted of home visits that aimed to continue promoting childhood development. In ABC, the second-phase treatment was randomly assigned independently of the first-phase randomization. In CARE, the second-phase was not randomized; children initially randomized to either of the treatment groups continued being treated.\\

\noindent The data availability is very similar in both programs. It is extensive and starts at birth, continues throughout childhood, and ends at adulthood. It includes a battery of standard cognition assessments. But more importantly, it comprises socio-emotional skills, education and labor market outcomes, \textit{administrative} criminal records, and a full medical examination when the treatment and control groups were in their mid 30s. This allows us to study the effect early-childhood education has on multiple dimensions of human development.\\

\noindent To illustrate the suitability of our data when assessing the effectiveness of early childhood education, consider the following exercise. We construct 141 measures of human development across the life-cycle (e.g. cognition at age 5, high school graduation and labor income at age 30, hypertension at age 34). Then, we count the number of measures for which the program had a socially beneficial effect. For both ABC and CARE, we do so by focusing on the first phase of treatment to compare the children who received center-based childcare to the children who did not---noting that assignment was random.\footnote{In ABC, this implies comparing the children who were randomly assigned to the treatment group to the children who were randomly assigned to the control group, in the first phase. In CARE, this implies comparing the children who were randomly assigned to receive center-based childcare and home visits to the children who were randomly assigned either to the group receiving home visits only or to the control group, in the first phase as well.} Figure~\ref{fig:ppositive} displays the results from this exercise: ABC and CARE positively impact a noticeable majority of this variety of outcomes. In fact, throughout the paper, we formalize the count in this exercise as an statistic to summarize the effectiveness of ABC and CARE, while accounting for methodological challenges inherent to the evaluation of social programs.

\begin{figure}[H]
		\caption{Positively Impacted Outcomes, ABC and CARE} \label{fig:ppositive}
		\includegraphics[width=.9\columnwidth]{output/abccare_positiveeffects.eps}
\floatfoot{
\footnotesize
\noindent Note: The first two bars (ABC) compare the treatment and control groups in ABC. The third and four bars (CARE) compare the children who received center-based childcare and family education to the children who receive either family education or no treatment at all. The last two bars (ABC and CARE) pool the two previous sets of comparisons.}
\end{figure}


\noindent We develop a methodology to assess the effectiveness of the programs accounting for two issues that are common to social experiments: (i) attrition of treatment and control participants throughout the treatment and the data follow-ups; and (ii) treatment substitution by the families of the control-group children.\footnote{A usual critique to programs like ABC and CARE we do not assess here is their small sample size \citep{Hanushek_Lindseth_2009_BOOKSchoolhousesCourthouses}. Asymptotic inference methods, however, are well suited to analyze samples of the size of these programs. \citet{Campbell_Conti_etal_2014_EarlyChildhoodInvestments} evaluate the effectiveness of ABC at boosting health outcomes both using small-sample-size inference and asymptotic inference, and find little sensitivity.}\\

\noindent For each data collection stage, we document non-compliance to treatment and attrition. We propose a methodology to account for these cases, which are a common critique to ABC \citep{Spitz_1992_ABC-Retardation,Hu_2014_ABC-Study}.\\

\noindent We also present a thorough documentation of control-group treatment substitution. In both programs, the parents of around 70\% of the children randomized out of center-based childcare enrolled their children in relatively high-quality preschool alternatives.\footnote{Treatment substitution was not an issue in Perry. Informal conversations with Perry's staff indicate that there were no alternative preschools in the area in which subjects were treated during that time---Ypsilanti, Michigan during the 1960s. This issue is important when evaluating more recent programs. Examples include both ABC and Head Start---see \citep{Puma_Bell_etal_2010_HeadStartImpact} for a documentation of treatment substitution in the Head Start Impact Study.} We develop a methodology to account for treatment substitution and explain that there are two policy questions that we are able to ask using data from ABC and CARE. First, we can evaluate the effect of ABC and CARE given the supply of preschool alternatives available when they were implemented. Second, we can evaluate the effect of ABC and CARE relative to a fixed alternative: no preschool at all or attending alternative preschools. The second question can better characterize the effectiveness of each program because it compares it to a set alternative.\\

\noindent We summarize the effectiveness of a program when information on multiple outcomes throughout the life-cycle is available. There are two current alternatives in the literature. One is to to calculate statistics that characterize the efficiency of a social program, such as the internal rate of return or the benefit-to-cost ratio \citep{Heckman_Moon_etal_2010_RateofReturn}. The other is to group outcomes into categories---e.g., socio-emotional skills, criminal activity, health---and adjust the inference on each of the outcomes to account for multiple hypotheses testing and to avoid ``cherry picking'' significant results \citep{Lehman_Romano_2005_AnnStat,Lehmann_Romano_2005_testing,Heckman_Moon_etal_2010_QE}. In this paper, we calculate and formalize an inference procedure for (i) the count of outcomes for which the program causes a positive treatment effect; and (ii) the count of outcomes for which the program causes a \emph{significant} and positive treatment effect, considering different levels of significance.\footnote{This alternative is an application of conducting inference on a statistic that summarizes information across multiple sources---i.e., a combining function \citep{Pesarin_Salmaso_2010_PermutationTests}.}\\

\noindent We also test diverse hypotheses to assess the effectiveness of the second phase of randomization. The effectiveness of the first phase of treatment is much weaker if compared to that of the second. We conclude that ABC and CARE were much more effective when intervening before age 5, rather than between ages 5 to 8.\\

\noindent This paper extends the work of \citet{Campbell_Conti_etal_2014_EarlyChildhoodInvestments}, who analyze the effectiveness of ABC at improving long-term health outcomes. It presents the methodology for the calculation of the treatment effect estimates that underpin our companion paper, \citet{Elango_et_al_2015_ABC_unpublished}. In it, we use the treatment effects in this paper and forecast the life-cycle gains of ABC on multiple dimensions of human development, from birth and until death, to calculate its internal rate of return and its benefit-to-cost ratio.\footnote{A brief survey of previous, related work to this paper is the following. \cite{Campbell_Pungello_etal_2012_DP} estimate treatment effects on adulthood outcomes in ABC. Unlike our approach, this report does not assess outcomes such as health status, criminal behavior, and non-cognitive skills. \cite{Campbell_Conti_etal_2014_EarlyChildhoodInvestments} is the only other paper to assess health outcomes, but they do not address control contamination. In addition to providing a comprehensive analysis of ABC's effects, our paper is a valuable contribution since it is the first to correct for treatment substitution, to correct for program attrition, and to adjust for the cherry-picking of significant treatment effects by using count statistics. Furthermore, we broaden the analysis by analyzing ABC together with CARE, which was close in implementation objectives and design.}\\

\noindent The rest of the paper proceeds as follows. Section~\ref{section:background} describes the background of each program. It includes an overview, a description of the eligibility criteria and the populations served, a characterization of the randomization protocol and of treatment substitution, and a comprehensive summary of the treatment.  Section~\ref{section:methodology} formalizes our methodology by discussing how we correct for compromised randomization, treatment substitution, and multiple hypotheses testing. Section~\ref{section:results} presents our main results and Section~\ref{section:conclusion} offers some final comments. An extensive appendix presents a much more thorough description of the program and data relative to what we present in the main text. It also discusses various alternative methodologies to evaluate the programs accounting for treatment substitution, and documents the results we present to a further extent.

\section{Background} \label{section:background}
\subsection{Overview}

\noindent The Carolina Abecedarian Project (ABC) and the Carolina Approach to Responsive Education (CARE) programs were designed and implemented by researchers at the Frank Porter Graham Center (FPGC) of the University of North Carolina in Chapel Hill. The programs targeted disadvantaged children from the semi-rural communities in the surrounding area.\\

\noindent The design and implementation of CARE and ABC were very similar and both studies had a small sample size. ABC recruited 122 children over four cohorts, while CARE recruited 67 children over two cohorts.\\  

\noindent ABC had two phases, the first of which lasted from birth until the age of 5. In this phase, children were randomly assigned to either treatment or control groups. The treatment group received: (i) center-based childcare; (ii) breakfast, lunch, an afternoon snack, iron-fortified formula for the first 15 months of life, and a monthly supply of diapers; and (iii) medical care from licensed nurses who were supervised by a pediatrician, frequent health check-ups, and hospital referrals when serious medical treatment was needed. The control group only received formula and diapers. In the second phase of treatment, at the age of 5, the 95 children still in the study were randomly assigned again to treatment or control groups, independently of their status in the prior randomization. This treatment consisted of home visits targeting both children and parents and lasted until age 8.\\ 

\noindent  CARE also had two treatment stages, though children were randomized only once. While the two programs had essentially identical second stages, the first phase of CARE differed significantly from the first phase of ABC by including a family education component. This component was designed to study the effects of improving the home environment on child development.\footnote{\citet{Wasik_Ramey_etal_1990_CD}.} The first treatment phase of CARE lasted from birth until the age of 5. Children were randomly assigned to one of three experimental groups: control (23 children), family education (25 children), and both family education and center-based childcare (17 children). As in ABC, the control group received diapers and complementary nutrition from birth to 15 months. The family education group received home visits that aimed to help parents solve common problems related to childrearing. Both treatment groups received the second phase of treatment from ages 5 to 8.\\

\noindent The available data describing each program is rich and similar. In both programs, from birth until the age of 8, data was collected annually on cognitive and socio-emotional skills, home environment, family structure, and family economic characteristics. After age 8, the collection of data was less frequent. Information on cognitive and socio-emotional skills, education, and family economic characteristics was collected at ages 12, 15, 21, and 30.\footnote{At age 30, information on cognitive skills is unavailable for both ABC and CARE.} In addition, we have two sources of data that are novel to the literature evaluating early childhood education programs: administrative criminal records and a full medical panel at age 34. These rich sources of data allow us to study the long-term effects of the programs on multiple aspects of human development.

\subsection{Eligibility Criteria and Populations Served} \label{section:eligibility}

\noindent ABC recruited four cohorts of children born between 1972 and 1977. CARE recruited two cohorts of children, one born in 1978 and one in 1979. The recruitment processes were identical. Potential families were referred to researchers by local social service agencies and hospitals at the beginning of the mother's last trimester of pregnancy. Eligibility was determined by a score of 11 or above in a High-risk Index (HRI).\footnote{The HRI was a linear combination based on 13 variables, which are listed here with their weights in parentheses: (i) maternal education level measured by years of education---6 (8), 7 (7), 8 (6), 9 (3), 10 (2), 11 (1), 12 (0); (ii) paternal education level with weights identical to those for maternal education; (iii) family income measured in current dollars---\$1,000 (8), \$1,001 - \$2,000 (7), \$2,001 - \$3,000 (6), \$3,001 - \$4,000 (5), \$4,001 - \$5,000 (4), \$5,001 (0); (iv) father's absence from the household for reasons other than health or death (3); (v) absence of maternal relatives in the area (3); (vi) siblings of school age one or more grades behind age-appropriate level, or with equivalently low scores on school-administered achievement tests (3); (vii) received payments from welfare agencies within past 3 years (3); (viii) record of father's work indicates instability or unskilled and semi-skilled labor (3); (ix) record of maternal or paternal IQ score of 90 or below (3); (x) record of sibling IQ score of 90 or below (3); (xi) relevant social agencies in the community indicate the family is in need of assistance (3); (xii) one or more family members has sought counseling or professional help in the past 3 years (1); and (xiii) special circumstances not included in any of the above that are likely contributors to cultural or social disadvantage (1).} Table~\ref{tab:baseline} compares the children in ABC and CARE. Overall, the children in CARE were relatively less disadvantaged; their mothers were older, more educated, and had higher IQ.

\input{output/baseline_balance_abccare}

\noindent Neither ABC nor CARE used race as an eligibility factor. However, $98\%$ and $90\%$ of their participants were African-American, respectively. The average maternal age in ABC when the target child was born was 19.9, whereas in CARE mothers were on average 21 years old. In both treatments, approximately half of all mothers were 19 or younger.\footnote{Maternal age at target child's birth ranges from 13 to 43 years of age. One-third were 17 or younger.} Further, the average IQ for all mothers was 84 in ABC and 87 in CARE---approximately one standard deviation below the national mean. Only $25\%$ of the ABC children lived with both biological parents, and more than $50\%$ lived with extended families in multi-generational households ($61\%$ of treated children and $56\%$ of control children).\\

\begin{figure}[H]
\caption{Family Environment Baseline Characteristics, ABC and CARE}  \label{figure:baselineabccare}
    \centering
\begin{subfigure}{.5\textwidth}
  \centering
  \subcaption{Average Maternal Age}
  \includegraphics[height=2.3in]{output/abccarepsid_m_age0pool.eps}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \subcaption{Average Maternal Years of Education} 
  \includegraphics[height=2.3in]{output/abccarepsid_m_edu0pool.eps}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
  \centering
  \subcaption{Proportion of Households with Father at Home}
  \includegraphics[height=2.3in]{output/abccarepsid_f_home0pool.eps}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \subcaption{Median Parental Income in 1,000s of 2014 USD}
  \includegraphics[height=2.3in]{output/abccarepsid_p_inc0pool.eps}
\end{subfigure}
\floatfoot{
\footnotesize
\noindent  Note: These panels plot mother's age, mother's education, an indicator of father at home, and parental income (in thousands of 2014 USD). In each panel, the first bar shows the national-level for a cohort born in the same years as the ABC and CARE individuals (1972-1979), obtained from the Panel Study of Income Dynamics (PSID). The second bar uses this same information restricted to black individuals. The third and fourth bars plot the same variables for ABC and CARE, pooling the treatment and control groups.
}
\end{figure}

\noindent To better characterize the socio-economic status of the families participating in ABC, we construct two comparison groups using the Panel Study of Income Dynamics (PSID), a nationally representative cohort of children born in the same years as the ABC and CARE participants (1973-1979), and a similar cohort restricted to black children. We show a comparison in Figure~\ref{figure:baselineabccare}. Compared to both nationally representative groups, ABC children were, on average, significantly more disadvantaged; they were born in households with extremely low total parental income and to younger, less educated mothers, most of whom were raising their children without the support of a father. The CARE participants were similarly disadvantaged compared to nationally representative groups with respect to these basic household socio-demographic characteristics.\\

\subsection{Randomization Protocol and Compromises} \label{section:randomization}

\subsubsection{ABC}

\noindent The first phase of randomization was conducted at the family level, so pairs of siblings and twins were jointly randomized to either treatment or control groups.\footnote{Sibling pairs occurred when the two siblings were close enough in age such that both of them were eligible for the program.} Although we know that the pairing was based on HRI, maternal characteristics, number of siblings, and gender, we do not know the original pairs. The study collected an initial sample of 120 families. Twenty-two children did not complete the first-phase of treatment as initially assigned by the randomization or control (see Table~\ref{table:abccompromises}). We document each case and explain how we classify it to assess it with the methodology in Section~\ref{section:methodology}.\\

\noindent First, there were four children assigned to treatment status who left the study before any data on them was collected. The program staff did not assign them an identifier, and we classify them as Cases A, B, C, and D. In our main methodology, we assume that they are missing at random. Sensitivity exercises assuming that these children had outcomes identical to the child with the lowest outcome in the treatment group suggest that, even in this worst case scenario, treatment-group children do much better if compared to control-group children (see Appendix~\ref{appendix:assessingcc}).\\

\noindent Second, four children died before age 5---two of them initially assigned to treatment and two of them initially assigned to control (these are children were assigned the identifiers ``.x'', 914, 74, and 99). For all of them, we observe baseline characteristics and any other data collected before their dead. For methodological purposes, we include them in any estimations before age 5; they represent cases of program attrition thereafter.\\

\noindent Third, one child moved out from the programs location after age 15 and no data was collected on him after (identifier 82). We consider him part of the control-group sample before at age 15 and before; after, we consider him a case of program attrition.\\

\noindent Fourth, three children in the treatment group did not comply to treatment status (identifiers 900, 912, 922). They are different from Cases A to D because we observe any data collection for them from birth and up to age 8---afterwards, the program staff decided not to follow them anymore for no evident reason. As we explain later in Section~\ref{section:methodology}, our main parameters  of interest are different version of the intent-to-treat. Thus, these children remain as part of the treatment sample in our estimations at age 8 or before. After, they represent cases of program attrition, given that we do not observe them anymore. In Appendix~\ref{appendix:assessingcc} we find little sensitivity to adjusting for non-compliance of these children in the results we show for age 8 or before.\\

\input{output/abc_compromises}

\noindent Fifth, one child initially assigned to control status was enrolled into treatment (identifier 78). Her mother wanted to work and the program staff decided to admit her child into treatment.\footnote{Correspondence with the program officers stating this is available under request from the authors of the present document.} Both in terms of data collection and in terms of methodological purposes, this child is analogous to the children in the third case.\footnote{The sensitivity analysis finding little evidence when adjusting for non-compliance includes this case.}\\

\noindent Sixth, four children treatment-group did not complete treatment in its entirety (identifiers 85, 103, 108, and 123). They were treated for 3, 10, 6, and 9 months, respectively. Except for the childhood follow-ups, in which our main results are not based on, we observe most of the data for these children. We avoid taking a stand on how beneficial was the program at each age, because we do not have a way to document this. Thus, we assume that they were treated as other child in the treatment group.\footnote{If anything, this biases downwards the effects of the program we estimate.} \\

\noindent Seventh, the family of one child in the control group moved at age 54 months (identifier 906). We observe any data collection before the family moved, so we consider the child as part of the control group in any estimation before this event. Afterwards, we do not observe any data on the child, so we consider her a case of program attrition.\\

\noindent Eight, two children initially assigned to treatment status were diagnosed as developmentally delayed after six and thirty-six months of treatment (identifiers 95 and 124, respectively). No data for them is available after the diagnosis. We drop them from the sample because they were not eligible to be part of the program, to begin with, as we explain in Section~\ref{section:eligibility}.\\

\noindent Finally, two children initially assigned to the control group were admitted into treatment (identifiers 82 and 119). Local authorities requested this because the children were considered highly disadvantaged. Data on them is available from birth and up to age 8. We drop these children from the sample, because, most likely, they were not eligible to the program.\\

\noindent The analysis of each of these cases leads to the following conclusions. (i) For four children, we do not have data to methodologically assess them as cases of program attrition, though sensitivity analysis suggest that the treatment effects of the program persist after assigning them the same outcome as the children who did worst in the treatment group. (ii) For the four children who did not comply to treatment (three treatment-group children and one control-group child), adjusting our estimates for non-compliance when data is available makes little difference. (iii) The rest 14 children who did not complete treatment as initially assigned represent different cases of program attrition, for which we propose a methodology in Section~\ref{section:methodology}.\\

\noindent In an effort to increase the number of children in the sample, the program officers recruited additional children before who were added to the program before children were six months old. Although we are not able to know who the replacements are in the sample, the observed characteristics of all the children in the sample indicate that they were eligible to the program---all children in the sample have an HRI of 11 or above (see Figure~\ref{section:eligibility}). Our calculations indicate that there were eight replacements.\footnote{Three replacements are documented in \citet{Ramey_Campbell_1979_SR}. One is documented in correspondence with the program officers, which is available from the authors of the present document upon request. The other four replacements are implied by the number of children who participated of the randomization protocol in each cohort.} Thus, the initial sample consisted of 111 children: 53 treatment children and 58 control children.\\

\noindent Prior to the second phase of randomization, 3 children in the control group of the first phase and 3 children in the treatment group of the first phase stopped being followed because it was impossible to find them. One child in the control group and 8 children in the treatment group of the first phase did not participate in the second phase but later agreed to participate in the data collections during adulthood. This yielded a sample of 96 children in the second phase: 49 in treatment and 47 in control. After randomization, three children in the treatment group chose not to participate in the program, while all children in the control group adhered to their randomization status. Figure~\ref{fig:abc-flow} in Appendix~\ref{appendix:background} illustrates ABC's randomization protocol and the flow of participants throughout the data follow-ups.\\

\subsubsection{CARE}

\noindent The randomization protocol in CARE was analogous to the first-phase of randomization in ABC. Notably, it had no major compromises.\footnote{\citet{Bryant1987TIECSE,Wasik_Ramey_etal_1990_CD,Burchinal_Campbell_etal_1997_CD}.} Of the 65 initial families, 23 were randomized to control, 25 to the family education treatment group, and 17 to the family education and center-based childcare treatment group. Two families in the family education treatment group had twins who were jointly randomized, as in ABC. We document four cases of program attrition (see Table~\ref{table:care_compromises}). For methodological purposes, we consider these children analogous to their corresponding cases in ABC. We do not present exercises to evaluate the sensitivity to non-compliance because there was none in CARE. Figure~\ref{fig:care-flow} in Appendix~\ref{appendix:background} illustrates CARE's randomization protocol and the flow of participants throughout the data follow-ups.\\

\input{output/care_compromises}

\subsection{Program Description and Content}

\noindent The ABC and CARE programs shared many objectives and program characteristics, as summarized in Table~\ref{tab:programcomparison}.\\

\input{output/abccare_programcomparison.tex}

\noindent ABC and CARE shared a main objective: to prevent ``mental retardation" and to develop school readiness for disadvantaged children, starting at birth.\footnote{Note that the clinical understanding of mental retardation was once associated with disadvantages that hindered early-life development \citep{Mental-Retardation_America_2004_BOOK_NYU}.} The different curricula implemented across programs and cohorts had the following common goals: (i) to support language and cognitive development; and (ii) to develop socio-emotional competencies that were considered to enable school readiness---e.g. task orientation, emotional self-expression, independence, sharing, and cooperation.\footnote{\citet{Sparling_1974_Synth_Edu_Infant_SPEECH,Ramey_Collier_etal_1976_CarolinaAbecedarianProject,Ramey-etal_2012-ABC}.} The curricula evolved each year according to recommendations made in studies that used the children's data.\footnote{\citet{Ramey-etal_1975_AJoMD,Finkelstein_1982_Day_Care_YC,Haskins_1985_CD}.}$^{,}$\footnote{The curricula implemented in the first phases of ABC and CARE, including Tools of Mind, shared an emphasis on self regulation---e.g., goal setting and self-reflection---and opportunities for language development. Language development, including phonics and reading skills, is also an important element in other widely implemented curricula such as Opening the World of Learning.}$^{,}$\footnote{Two other renowned early childhood education programs are worth comparing to ABC and CARE. The Infant Health and Development Project (IHDP) was based on the first phase of CARE. IHDP had a single treatment group, which was very similar to the center-based childcare and family education treatment group of CARE. The curricula implemented both at home and at center-based childcare were very similar. The main difference is that the first phase of CARE lasted 5 years, while IHDP lasted 3 years and did not have a second phase. Both ABC and CARE were notably different from the Nurse Family Partnership (NFP) program. NFP had fewer visits and began in the pre-natal period. Mothers received monthly visits during pregnancy and one visit every two months from when the child was born until the age of 2. The visitors were nurses and they tried to help women build relationships with friends and family to create a support network for their children. A common element of the three programs is that the visitors helped parents use community resources when solving their everyday problems.}\\

\noindent Both treatment groups in CARE incorporated home visits, which aimed to help parents resolve everyday problems that could adversely affect relationships with their children, as well as to improve the general skills associated with parenting. Generally, the home visits were weekly and one hour long. Between birth and the age of 3, participants in the family education and center-based childcare and family education groups received, on average, 2.5 and 2.7 visits a month, respectively. At ages 4 and 5, the average frequency decreased to 1.4 and 1.1 visits per month.\\ 

\noindent The first phases of ABC and CARE were conducted in conjunction with a longitudinal medical research study on infectious respiratory diseases in group environments.\footnote{\citet{Henderson-et-al_1982_NEJoM}.} This study allowed the children to have comprehensive medical care in the same center in which they received center-based childcare. The children who attended the center received daily screenings to detect any signs of illness. This included all the children in the treatment group of ABC and all the children in the center-based childcare and family education group of CARE. The first cohort of the control group of ABC also received frequent medical check-ups during the first year of the first-phase of the program.\\

\noindent The children assigned to treatment in the first phase of ABC also received primary pediatric care by a family nurse practitioner and a licensed practical nurse, who were supervised by a pediatrician who was on continuous duty at the childcare center. This care consisted of wellness check-ups, immunizations, parental counseling, and initial assessments of illnesses. Like the other treatment components, pediatric care was free of charge. Unfortunately, there is no documentation or corresponding evidence for whether this aspect of treatment was available to the treatment groups of CARE.\\

\noindent For both ABC and CARE, children in the programs' center-based childcare were provided breakfast, lunch, and an afternoon snack, planned by a nutritionist. Children in the control groups of both programs received diapers from birth until the age of 3, and an unlimited supply of bottled formula from birth until 15 months. Neither of the control groups in both programs nor CARE's family education treatment group received any program medical care, with the exception of the first cohort of control children in ABC, as explained above.\\

\noindent The second phase of both ABC and CARE, also referred to as school-age treatment, lasted for the first three years of elementary school and incorporated home visits by a teacher. The visits aimed to increase the child's exposure to reading and mathematics and to promote parental involvement in the learning process. These visits occurred every two weeks in the presence of the parents. At the visits, the teachers discussed the children's programs and helped parents with issues related to literacy, housing, and medical care.\\

\subsection{Treatment Substitution}

\noindent The interpretation of treatment and control group comparisons depends on how the control group substituted treatment, posing a methodological challenge when answering policy-oriented questions. In both programs, many children without access to center-based childcare through random assignment nevertheless attended alternative preschools. In this section, we characterize the types of care received by the treatment group. We propose a methodology to answer relevant policy-questions in Section~\ref{section:methodology}.\\

\begin{figure}[H]
		\caption{Treatment Substitution, ABC} \label{fig:treatsubabc}
		\includegraphics[width=.9\columnwidth]{output/abc_controlcontamination_months.eps}
\floatfoot{
\footnotesize
\noindent Note: This figure displays the cumulative density function of enrollment in an alternative preschool for the control group in ABC.}
\end{figure}

\noindent In ABC, $65\%$ of control-group children was enrolled in one of 11 local center-based childcare centers (see Figure~\ref{fig:treatsubabc}). Each of these centers received federal subsidies and were therefore regulated by the Federal Interagency of Daycare Requirements. Therefore, their staff members were required to be trained in early childhood education and the centers were required to implement approved curricula designed to enhance cognitive, social, and linguistic competence in disadvantaged children.\footnote{\citet{Burchinal_etal_1989_CD_Daycare-Pre-K-Dev}.} In CARE, slightly more than $70\%$ of the control group and $60\%$ of the family education group were enrolled in alternative preschools by their parents (see Figure~\ref{fig:treatsubcare}). The parents of the children in both of these groups had as options the same set of local center-based childcare centers as the ABC children in the control group.

\begin{figure}[H]
		\caption{Treatment Substitution, CARE} \label{fig:treatsubcare}
		\includegraphics[width=.9\columnwidth]{output/care_controlcontamination_months.eps}
\floatfoot{
\footnotesize
\noindent Note: This figure displays the cumulative density function of enrollment in an alternative preschool for the control and family education treatment groups in CARE.}
\end{figure}
 

\subsection{Data} \label{section:data}

\noindent Table~\ref{tab:datasumm_1} and Table~\ref{tab:datasumm_2} summarize our data availability. The collection process was analogous in both programs. The treatment and control groups were followed into adulthood with relatively low attrition. For ABC, children were followed annually through elementary school and at ages 12, 15, 21, and 30. Health and administrative crime data were collected when the children reached their mid-30s. For CARE, the exact same follow-ups are available with the exception of the age 15 follow-up.\\

\input{output/abccare_data}

\noindent Information on developmental progress, schooling, home environment, and parental characteristics was recorded through early childcare, elementary school, and at age 21. The data include measures of the child's IQ, achievement test scores, health status, risky behavior, schooling, social interactions, socio-emotional status, and non-cognitive skills. The data also include family and household variables, such as parents' labor market participation, household income, parental IQ, parental schooling, and parental attitudes toward child-rearing. For ages 21 and 30, information on labor market outcomes, income, educational attainment, relationship histories, health statuses, household statuses, risky behavior, and criminal activity is available.\\

\noindent For ABC, information is available on 100 children in the age 30 follow-up, which we call the adult follow-up. In addition, 80 participants---40 from the control group and 40 from the treatment group---consented to the release of their criminal records. Further, 70 participants consented to the release of information regarding a full-range biomedical panel---31 from the control group and 39 from the treatment group. Examples of measures in the health data include incidence of diabetes and high blood pressure, waist-to-hip ratio, height and weight, and cholesterol levels. For CARE, the available data is similar. In Appendix~\ref{appendix:randomization}, we document balance in observed, baseline characteristics across the treatment and control groups, once we drop the individuals for whom we have crime or health information. Further, the methodology we propose addresses missing information in either of these two data categories.

\section{Methodology} \label{section:methodology}

\subsection{Parameters of Interest and Policy Questions} \label{section:methodsquestions}

\noindent Random assignment does not guarantee that conventional treatment effect estimates used in the literature are able to answer policy-relevant questions. For an estimator to be useful in policy design, it should relate to a relevant parameter in the presence of selection and should clearly state the counterfactual scenario to what the program is being compared.\\

\noindent In this section, we outline our methodology for estimating policy-relevant parameters. We start by comparing children who \textit{take up} treatment to children who do not. For the moment, we focus our exposition on estimating the effect of ABC's first phase of treatment. We then clarify how to incorporate the second phase of treatment into our estimates---as well as multiple, simultaneous treatments afterwards \textbf{[MT: Vague. What are these multiple, simultaneous treatments?]}.\\

\noindent Let $D = 1$ if the child takes up treatment, and $D=0$ if the child does not. Let $Y$ be an outcome of interest. We write

\begin{equation}
Y = D Y_{1} + \left( 1 - D \right) Y_{0} \label{eq:outcome}
\end{equation}

\noindent where $Y_{1}$ is the outcome when the child is ``fixed'' to a scenario in which she takes up treatment, $Y_{0}$ is the outcome when the child is ``fixed'' to a scenario in which she does not, and $Y$ is her realized outcome. \textbf{[MT: A ``counterfactual'' scenario refers to the outcomes when we flip (0 to 1) or (1 to 0)---not just her potential outcomes. This is your/Heckman's call, but I still think that the ``fixed'' language is kind of awkward. You could just say ``$Y_{1}$ is the child's potential outcome if she takes up treatment, and $Y_{0}$ is the child's potential outcome if she does not.'' Also consider this formulation:} \begin{equation}
Y = Y_{0} + D \left (Y_{1} - Y_{0} \right ). \nonumber 
\end{equation}

\textbf{It's obviously the same, but I think it better represents that there's some sort of ``mechanical switch'' happening by ``fixing'' D/it clearly states what the treatment effect/coefficient is ($Y_{1} - Y_{0}$) and why we usually test it against 0.]}

\noindent The conventional method of evaluating a program's treatment effect is to compare the expectation of $Y_{1}$ to the expectation of $Y_{0}$. Let $\mathbb{E} \left[ Y_{1} \right] = \mu_{1}$ and $\mathbb{E} \left[ Y_{0} \right] = \mu_{0}$. We test the hypothesis:

\begin{equation}
H_{0}^A: \mu_{0} = \mu_{1}. \label{eq:ho}
\end{equation}

\noindent We can extend this method to testing various other hypotheses, such as differences in higher order moments and rank. Testing~\eqref{eq:ho} is straightforward under perfect compliance, defined below. \\

\textbf{[MT: Assumption~\ref{assumption:pc} is a definition, not an assumption, especially since this is directly observable in the data. ]}

\noindent \begin{assumption} \label{assumption:pc} \normalfont (Perfect Compliance) Let $R$ indicate randomization to treatment and $D$ indicate treatment take-up. Perfect compliance occurs whenever  $R = D$.\end{assumption}

\noindent Under perfect compliance, testing~\eqref{eq:ho} is equivalent to testing if the intent-to-treat (ITT) estimator is different from zero. This estimator is defined as 

\begin{equation}
\text{ITT} = \mathbb{E} \left[ Y | R = 1 \right] - \mathbb{E} \left[ Y | R = 0 \right]. \label{eq:itt}
\end{equation} 

\noindent Given perfect compliance, the ITT can be used to test~\eqref{eq:ho} because $\mathbb{E} \left[ Y | R = 1 \right]$ and $\mathbb{E} \left[ Y | R = 0 \right]$ identify the expectations of outcome $Y$ when the individual is fixed to treatment and control, respectively. To see this, \textbf{[MT: I added a bit of exposition to why ITT=ATE under perfect compliance. Feel free to throw it out if it is overkill.]}


\begin{align}
\text{ITT} &= \mathbb{E} \left[ Y | R = 1 \right] - \mathbb{E} \left[ Y | R = 0 \right] \nonumber \\
	       &= \mathbb{E} \left[ Y_{1} | R = 1 \right] - \mathbb{E} \left[ Y_{0} | R = 0 \right] \nonumber \\
	       &= \mathbb{E} \left[ Y_{1} \right] - \mathbb{E} \left[ Y_{0} \right].
\end{align} 

\noindent where the second equality follows from Assumption~\ref{assumption:pc}. As a policy parameter, the ITT answers the following question: What is the expected effect of fixing a randomly selected individual to treatment status, relative to fixing her to control status? \textbf{[MT: The previous question didn't invoke averages or random selection (we're not conditioning on her attributes).]} \\

\noindent In practice, ABC suffered from imperfect compliance. Therefore, the ITT does not recover $ \mathbb{E} \left[ Y_{1} \right] - \mathbb{E} \left[ Y_{0} \right] $ and therefore does not test the hypothesis specified in \eqref{eq:ho} without further adjustment. In the study, children who did not comply with their assignment were not followed beyond age 8, at which point program treatment had ended \textbf{[MT: Confirm this]}. Since we focus mostly on outcomes after this age, we will propose a methodology to correct for program attrition and not for imperfect compliance. Additionally, we find that outcomes before age 8 are insensitive to issues of non-compliance \textbf{[MT: Confirm this]} (see Appendix~\ref{appendix:assessingcc}).\\

\noindent To account for program attrition in our estimation, we develop a correction to the ITT formula. Let $A \in \left \{ 0,1 \right \}$ indicate a case of program attrition and $Y_{d} $ represent a potential outcome, where $d$ indexes program take-up. It is not necessarily the case that 

\begin{equation}
\mathbb{E} \left[ Y_{d} |  A = 1 \right]  = \mathbb{E} \left[ Y_{d} | A = 0  \right],
\end{equation}

\noindent which motivates the following assumption. 

\begin{assumption} \normalfont \label{assumption:balance} (Conditional Independence in Program Attrition) The expectation of potential outcome $Y_{d}$ is independent of $A$ after conditioning on observed characteristics, $X$ \textbf{[MT: Is this true only for the first moment? Why not $ Y_{d} | X \perp A = a $ and then use this to derive the moment condition]}: 

\begin{equation}
\mathbb{E} \left[ Y_{d} | A = a, X \right] = \mathbb{E} \left[ Y_{d} | X \right].
\end{equation}

\end{assumption}

\noindent Under Assumption~\ref{assumption:balance}, we can correct for program attrition in our estimation of the ITT by using inverse probability weighting (IPW). In other words, we can weight observations in the data to achieve balance in observed characteristics between children for whom data was collected and not collected. Assumption~\ref{assumption:balance} states that once $X$ is balanced, conditioning on program attrition has no bearing on the potential distributions of interest. Therefore, these distributions are identifiable. Once we account for program attrition, the ITT represents the average treatment effect of ABC with respect to the control group. For clarity, we omit $A$ henceforth, although in our empirical application we present estimates corrected for attrition.\\

\noindent Importantly, the standard ITT does not account for the fact that almost $70 \%$ of the control group were enrolled in different preschool alternatives across both programs. Therefore, this estimator only captures the effects of the programs \emph{relative to} the mix of alternatives used in the control group, such as home care or preschools of different quality.\footnote{If the preschool alternatives were beneficial for the children in the control group, the ITT is attenuated. This is common in early childhood education programs in which alternatives are close in quality to the program itself. Perhaps the most iconic example is the randomized evaluation of Head Start, the Head Start Impact Study, in which $15\%$ of children in the control group had access to alternative Head Start centers. ITT estimates reported by \cite{Puma_Bell_etal_2010_HeadStartImpact} are close to zero. However, this does not mean that the efficacy of Head Start is low, but rather that Head Start treatment is being compared to close substitutes when computing the ITT.} We refer to the take-up of alternative forms of child care in the control group as treatment substitution. Therefore, to more precisely characterize the effects of the program \emph{per se}, our method must correct for this penomenon by fixing the alternative form of care among untreated children. \\

\noindent Let $P$ indicate whether a child takes up a given treatment substitute. The value of $P$ can be fixed to either $0$ or 1, indicating no take-up or take-up of an alternate, respectively. We are interested in the following hypotheses: \textbf{[MT: I still find this fixing notation strange/unintuitive. It doesn't make sense to incorporate the fixing using conditional notation; this directly violates probability theory (i.e., partitioning the probability space). Instead, by fixing you're just directly changing what $Y_{0}$ measures --- which doesn't happen through the conditioning. This is why you are inclined to use parenthetical notation for fixing outside of an expectations context. I am always still a proponent for using notation similar to this: $ Y_{0} = Y_{0}^{0} + P \cdot (Y_{0}^{1} - Y_{0}^{0}) $. With this formulation, it's clear what ``fixing'' is doing. It's just selecting a specified potential/counterfactual outcome. In this case, $ Y_{0}(\text{fix }P=0) $ is, directly, just $  Y_{0}^{0} $, which explains itself through the above formula. In any case, to make these hypotheses clearer, I removed the fixing ``condition'' for the RHS since $Y_{1}$ is independent of how we fix the treatment substitute.]}
\begin{eqnarray}
H_{0}^B &:& \mathbb{E} \left[ Y_{0} | \text{fix } P = 0 \right] =  \mathbb{E} \left[ Y_{1}  \right] \label{eq:hoB} \\
H_{0}^C &:&  \mathbb{E} \left[ Y_{0} | \text{fix } P = 1 \right] =  \mathbb{E} \left[ Y_{1}  \right] \label{eq:hoC}. 
\end{eqnarray}

\noindent That is, we want to compare the treatment distribution against a counterfactual distribution where children are fixed to no alternative preschool ($H_{0}^B$) and where children are fixed to an alternative preschool ($H_{0}^C$).\footnote{This treats alternative preschool as a binary decision on the extensive margin, which ignores the continuous decisions made on the intensive margin, as we show in Figure~\ref{fig:treatsubabc}. We take this approach because we are limited by our sample size when predicting preschool take-up, as we show in Appendix~\ref{appendix:methodology}.}\\

\noindent To contrast these hypothesis with \eqref{eq:itt}, consider the following estimators: 

\begin{eqnarray}
\text{ITT} \left( \text{fix } P = 0 \right) &=& \mathbb{E} \left[ Y | R = 1, \text{fix } P = 0 \right] - \mathbb{E} \left[ Y | R = 0, \text{fix } P = 0 \right] \label{eq:ittp0} \\
\text{ITT} \left( \text{fix } P = 1 \right) &=& \mathbb{E} \left[ Y | R = 1, \text{fix } P = 1 \right] - \mathbb{E} \left[ Y | R = 0, \text{fix } P = 1 \right]. \label{eq:ittp1}  
\end{eqnarray}

\noindent Estimating the expectations in \eqref{eq:ittp0} and \eqref{eq:ittp1} is not as straightforward as computing the expectations in \eqref{eq:itt} since families select whether or not to enroll their children into preschool alternatives. To estimate \eqref{eq:ittp0} and \eqref{eq:ittp1}, we introduce the following assumption. \\

\begin{assumption} \normalfont \label{assumption:matching} (Conditional Independence in Preschool Alternative Enrollment) The expectation of the counterfactual outcome $Y_{d} \left( \text{fix } P=p \right)$ follows the same distribution regardless of the value to which $P$ is fixed \textbf{[MT: You only present this for the first moment]} after conditioning on observed characteristics, $X$: \textbf{[MT: Again, why not $ Y_{d} | X \perp P=p \implies \mathbb{E} \left [ Y_{d} | \text{fix } P=p, X  \right] = \mathbb{E} \left [ Y_{d} | X  \right] $]}

\begin{equation}
\mathbb{E} \left [ Y_{d} | \text{fix } P=p, X  \right] = \mathbb{E} \left [ Y_{d} | X  \right].
\end{equation}
 \end{assumption}

\noindent Assumption~\ref{assumption:matching} states that observed characteristics, $X$, explain the parental decision for whether or not to enroll a child in a preschool alternative.\\

\noindent The estimates for $\text{ITT} \left( \text{fix } P = 0 \right) $ and $\text{ITT} \left( \text{fix } P = 1 \right)$ correspond to the second policy question related to the effects of ABC as a program \emph{per se}. Once program attrition is accounted for, the ITT estimates represent the average treatment effect of ABC relative to receiving no treatment at all and relative to receiving a \textit{fixed} preschool alternative.\\

\noindent To illustrate, suppose we want to estimate $\text{ITT} \left( \text{fix } P = 0 \right)$ using a linear and separable parameterization. We estimate the following model using OLS \textbf{[MT: you use OLS right?]}: 

\begin{equation}
Y = \Delta \left( \text{fix } P = 0 \right) R + X \beta + \varepsilon, \label{eq:ittmodel}
\end{equation}
\textbf{[MT: $\Delta$ is still a confusing way to denote a coefficient (vs. a differencing operator on $R$). Maybe change how you denote this coefficient]}

\noindent which provides a consistent estimate for $\Delta \left( \text{fix } P = 0 \right)$ under Assumption~\ref{assumption:matching}. $\Delta \left( \text{fix } P = 0 \right)$ represents the average treatment effect of ABC with respect to a well-defined alternative: no center-based childcare. To account for program attrition in this framework, we could weight the linear regression with individual-level estimates of the probability of program attrition \textbf{[MT: So the model doesn't directly provide a consistent estimate for $\Delta$ as it is shown in \eqref{eq:ittmodel} as said above]}.\\

\noindent We present estimates of $\Delta \left( \text{fix } P = 0 \right)$ and $\Delta \left( \text{fix } P = 1 \right)$ using this parameterization and using alternative specifications to more flexibly condition on $X$---e.g., nearest-neighbor matching, propensity-score matching, and kernel-based weighting.

\textbf{[MT: I still think that it is unclear exactly how you estimate a coefficient that is fixed on an alternative.  I would add a paragraph before this last one where you make explicit your empirical methodology. How does one estimate a coefficient in a regression that represents an effect whose counterfactual is ``fixed''? This should be pretty simply --- e.g., ``we restrict the control sample to children who satisfy $P=p$.'']} \\

\textbf{[MT: As an aside, I think the ``counterfactual'' language should be used more specifically. As a reader, ``counterfactual'' represents to me the potential outcome that we do not observe (it's counter the fact); that is, it's not used for any potential outcome.]} \\

\subsection{Multiple Treatment Groups}

\noindent We can readily apply the methodology in Section~\ref{section:methodsquestions} to test the hypotheses specified in \eqref{eq:ho}, \eqref{eq:hoB}, or \eqref{eq:hoC} for ABC. For CARE, a simple extension of the framework in Section~\ref{section:methodsquestions} allows us to test various hypotheses that measure the effectiveness of the program given that there were two treatment groups of different levels.\\

\noindent As before, let $Y_{d}$ denote a potential outcome. In this case, however, $Y_{0}$ corresponds to fixing the child to no treatment take-up,  $Y_{1}$ to take-up of family education treatment, and $Y_{2}$ to center-based childcare and family education treatment.\footnote{To adjust for program attrition, we can apply a weighting method as in Section~\ref{section:methodsquestions}.} To evaluate the program, we consider the following hypotheses: 

\begin{eqnarray}
H_{0}^D: \mathbb{E} \left[ Y_{0} \right] &=&  \mathbb{E} \left[ Y_{1} \right] \\ 
H_{0}^E: \mathbb{E} \left[ Y_{0} \right] &=&  \mathbb{E} \left[ Y_{2} \right] \\
H_{0}^F: \mathbb{E} \left[ Y_{1} \right] &=&  \mathbb{E} \left[ Y_{2} \right]. 
\end{eqnarray}\\

\noindent The first null hypothesis is that family education has no average treatment effect, while the second null hypothesis is that the center-based childcare and family education have no average treatment effect. The third hypothesis implies that the two treatments have the same average effect, which could be no average effect at all. The three hypotheses help us evaluate the program as implemented. That is, without correcting for alternative preschool enrollment of the children in either the family education treatment or the control groups. We can test these hypotheses constructing ITT estimators analogous to \eqref{eq:itt}.\\ 

\noindent Alternatively, we can measure the average treatment effect of CARE by fixing the counterfactual scenarios to a given preschool alternative. Fixing a preschool alternative is as relevant to CARE as it is to ABC since substantial numbers of children in the control groups for both programs were enrolled in alternative preschools (see Figure~\ref{fig:treatsubcare}). Under Assumption~\ref{assumption:matching}, we are able to construct ITT estimators fixing $P$ at either no preschool alternative or preschool alternative, as in \eqref{eq:ittp0} and \eqref{eq:ittp1}. We present estimates that account for $X$ using different parameterizations.\\

\subsection{Combining ABC and CARE} \label{section:combine}

\noindent Another method for evaluating the first phases of ABC and CARE is to combine the data from both programs and to test effects for the common elements of their designs. The ABC treatment group and the CARE center-based childcare and family education treatment group were subject to the same center-based childcare treatment component, with the CARE children receiving an additional family education component. If there is no evidence for the treatment effect of family education in CARE, then any effect of center-based childcare and family education treatment in CARE can be attributed to the center-based childcare component, which was shared with ABC. We outline a methodology to combine the data and to exploit this fact.\\

\noindent Suppose that we fail to reject $H_{0}^D$. That is, we fail to reject that the distribution of the outcome \textbf{[MT: $H_{0}^D$ just tests the first moment, not the ``distribution of outcomes''. Do you also test higher moments?]} of interest differs in the family education group, relative to the control group. Suppose further that we reject $H_{0}^F$, so that the counterfactual distributions \textbf{[MT: Against, testing means not entire distributions.]} of family education and center-based childcare and family education treatments differ. Together, this evidence favors assuming that center-based childcare was the main component generating treatment effects in CARE, if there were any. If this claim holds, we can pool the children fixed to control in ABC and CARE and pool the children fixed to treatment in ABC and to center-based childcare and family education treatment in CARE to test \eqref{eq:ho}, the effect of center-based childcare. Moreover, we can fix the children in the treatment groups to either no alternative preschool or to alternative preschool. We can then proceed as in Section~\ref{section:methodsquestions} to construct the estimates and correct for non-compliance.\footnote{This reasoning implicitly imposes that there is no interaction reinforcing the two treatments CARE offered. Our evidence supports this implicit assumption. We find quantitatively similar results when evaluating the effect of center-based childcare by (i) comparing the treatment and control groups of ABC and (ii) pooling the treatment group of ABC and the highest treatment group of CARE and comparing it to a pooled group of both control groups and CARE's family education treatment group.}\\

\noindent We report results in Section~\ref{section:results} for these two methods of combining information in ABC and CARE.

\subsection{Second-phase Treatment}

\noindent By design, ABC and CARE had comparable second phases of treatment. In ABC, children were randomized to the second phase, which enables us to test a series of hypotheses measuring its efficacy. To do this, let $S$ indicate random assignment to the second phase of treatment, and let $Y_{d,s}$ be a potential outcome corresponding to treatment status in the two phases of the program. This notation allows us to consider two dimensions of treatment take-up.\\

\textbf{[MT: Table~\ref{table:hypotheses} has fix notation inconsistent with the rest of the paper (not sure which notation you prefer). I also re-formatted so it weren't super wide!]}

\begin{table}[H] 
\begin{threeparttable}
\caption{First-phase and Second-phase Hypotheses}
\label{table:hypotheses}
\centering 
\begin{tabular}{ccc} \toprule
 & Fixing First-phase Treatment & Fixing Second-phase Treatment \\ \\ \midrule
Fixed to Control       & $ \begin{aligned} H_{0}^G: & \enspace \mathbb{E} \left[ Y \text{ fix } D = 0, S = 0 \right]  \\ &= \mathbb{E} \left[ Y \text{ fix } D = 0, S = 1 \right] \end{aligned} $ & $  \begin{aligned} H_{0}^H: & \enspace \mathbb{E} \left[ Y \text{ fix } D = 0, S = 0 \right] \\ & = \mathbb{E} \left[ Y \text{ fix } D = 1, S = 0 \right] \end{aligned} $ \\
Fixed to Treatment  & $ \begin{aligned}  H_{0}^I: & \enspace \mathbb{E} \left[ Y \text{ fix } D = 1, S = 0 \right]  \\  & = \mathbb{E} \left[ Y \text{ fix } D = 1, S = 1 \right] \end{aligned} $ & $ \begin{aligned}  H_{0}^J: & \enspace \mathbb{E} \left[ Y \text{ fix } D = 0, S = 1 \right] \\ & = \mathbb{E} \left[ Y \text{ fix } D = 1, S = 1 \right] \end{aligned} $ \\ \\ \midrule
Not Fixed                 & $ \begin{aligned}  H_{0}^K: & \enspace \mathbb{E} \left[ Y \text{ fix } D = d, S = 0 \right] \\ & = \mathbb{E} \left[ Y \text{ fix } D = d, S = 1 \right] \end{aligned} $ & $ \begin{aligned}  H_{0}^A: & \enspace \mathbb{E} \left[ Y \text{ fix } D = 0, S = s \right] \\ &= \mathbb{E} \left[ Y \text{ fix } D = 1, S = s \right] \end{aligned} $ \\  \toprule
\end{tabular}
\begin{tablenotes}
\footnotesize
\item Note: This table displays the hypotheses we test for the counterfactual distributions of an outcome $Y$, when fixing first-stage treatment status to treatment ($R = 1$) or control ($R = 0$) and/or second-stage treatment status to treatment ($S = 1$) or control ($S = 0$).
\end{tablenotes}
\end{threeparttable}
\end{table}

\noindent Table~\ref{table:hypotheses} outlines the different hypotheses we are able to test. To illustrate how we construct the tests, consider the following hypothesis: 

\begin{equation}
H_{0}: \mathbb{E} \left[ Y \text{ fix } D = d, S = 0 \right]  = \mathbb{E} \left[ Y \text{ fix } D = d, S = 1 \right]  \label{eq:h0fixfirst}
\end{equation}

\noindent In words, we test the effect of second-phase treatment, fixing first-phase treatment to control status. Following the methodology in Section~\ref{section:methodsquestions}, we can construct an ITT to test this hypothesis: 

\begin{eqnarray}
\text{ITT} = \mathbb{E} \left[ Y | R = 0, S = 1 \right] - \mathbb{E} \left[ Y | R = 0, S = 0 \right]. 
\end{eqnarray}

\noindent Perfect compliance allows us to identify the expectation of the outcome when fixing first-phase treatment to control status and the second-phase treatment to treatment status---that is, $\mathbb{E} \left[ Y_{0,1} \right]$---by using its empirical counterpart: $\mathbb{E} \left[ Y | R = 0, S = 1 \right]$. Similarly, we are able to identify $\mathbb{E} \left[ Y_{0,0} \right]$ using $\mathbb{E} \left[ Y | R = 0, S = 0 \right]$. With imperfect compliance, we can use the weighting method in Section~\ref{section:methodsquestions} to identify and estimate these expectations. The tests in which the first phase of treatment is fixed proceed similarly.\\

\noindent Alternatively, it is also meaningful to test if the second phase of treatment had an effect independent of assignment in the first phase \textbf{[MT: I don't think this is what you are doing in \eqref{eq:h02}. It looks like you are testing some sort of dynamics?]}. That is, we test

\begin{equation}
H_{0}^K: \mathbb{E} \left[ Y \text{ fix } D = 0, S = s \right] = \mathbb{E} \left[ Y \text{ fix } D = 1, S = s \right] \label{eq:h02}
\end{equation}

\noindent The hypothesis in \eqref{eq:h02} is the second-phase counterpart to the hypotheses in \eqref{eq:ho} and addresses the effectiveness of the second phase of ABC. Importantly, the test does \emph{not} consider dynamics between the first and second phases of treatment, while hypotheses that fix the first phase of treatment do consider these dynamics.\\

\noindent We report results for tests of the presented hypotheses, while also fixing the first-phase alternative for preschool, as we explain in Section~\ref{section:methodsquestions}.

\subsection{Treatment Effects on Multiple Outcomes} \label{section:counts}

\noindent While our discussion thus far addresses how to test the effectiveness of the programs at improving a single outcome, human development is obviously multidimensional. In our companion paper, \citet{Elango_et_al_2015_ABC_unpublished}, we offer one method for measuring the effectiveness of a program using two statistics: the benefit-to-cost ratio and the internal rate of return. To do this, we account for the life-cycle gains of the program in dimensions such as employment, income, government transfers, health, and crime. A simpler but informative alternative is to count the number of socially positive outcomes that the program influences. We will present an inference methodology for this procedure.\\

\noindent This latter method requires classifying each outcome as socially positive or negative, which is an inherently subjective procedure. In the interest of objectivity, we present the counts on 141 outcomes, all of which we think are either unambiguously socially positive or unambiguously socially negative. We offer some relevant examples in Section~\ref{section:data} \textbf{[MT: Include all?]}.\\

\noindent The different counts we propose are examples of combining functions \citep[see][]{Pesarin_Salmaso_2010_PermutationTests}. These functions combine information on several outcomes for testing patterns in a scientific or social phenomenon---in our case, an early childhood education program. For instance, suppose we want to test the hypothesis: 

\begin{equation}
H_{0}^A: \mathbb{E} \left[ Y_{0} \right] =  \mathbb{E} \left[ Y_{1} \right] \label{eq:hoagain}
\end{equation}

\noindent for multiple outcomes $Y$, and that, for each outcome individually, we already have an inference procedure readily available. That is, we know the hypothesis, the statistics we use to test it, and the $p$-value associated with the test. For instance, we may want to test \eqref{eq:hoagain} using the ITT and a bootstrapped, non-parametric $p$-value. \textbf{[MT: Why are these needed?]}\\

\noindent Consider constructing a combining function---in our case, a count---for a group or block of outcomes $\mathcal{O}^g$ with $g \in \mathcal{G}$, where $\mathcal{G}$ is the index set for the groups of outcomes.\footnote{It is not necessarily the case that the groups in $\mathcal{G}$ are exclusive. It could be of interest to study groups which have overlapping outcomes. The test does not require the groups to be exclusive.} \textbf{[MT: It'd be interesting to provide a sentence-long explanation for why we do not need the groups to be mutually exclusive when taking the count over $ \bigcup \limits _{g \in \mathcal{G}} \mathcal{O}^g $]} Alternatively, we can construct the count for $\mathcal{O} : =  \bigcup \limits _{g \in \mathcal{G}} \mathcal{O}^g$. Each group includes the number of outcomes $\# \mathcal{O}^g$ and an associated sequence of treatment effects $\{ \widehat{\Delta}_{j}^{g} \}_{j = 1}^{\# \mathcal{O}^g}$. The test statistic for group $g$ is the count. For example, if we count the number of socially positive outcomes, the test statistic for group $g$ is 

\begin{equation}
T_{g} = \sum _{j=1}^{\# \mathcal{O}^g} \mathbf{1} \left[ \widehat{\Delta}_{j}^{g} > 0\right]. \label{eq:count}
\end{equation} 

\noindent For inference purposes, we bootstrap this procedure and construct a null distribution. The $p$-value for the number of socially positive treatment effects in group $g$ is $1 - \widehat{F}_{g} \left( T_{g} \right)$, where $ \widehat{F}_{g}$ is the empirical bootstrap distribution of group $g$. \\

\noindent We consider three counts. First, a count of the socially positive treatment effects, which is directly presented in~\eqref{eq:count}. We can construct this count over the complete set of outcomes or over subsets---e.g. employment, health, crime---without consideration of their significance when \eqref{eq:hoagain} is individually tested. Next, we count the outcomes that are  socially positive at a $10\%$ significance level when hypothesis \eqref{eq:hoagain} is individually tested. Finally, we use the same count but at a $5\%$ significance level.\\

\noindent In Section~\ref{section:results}, we present tests for the three combining functions for different groups of outcomes and for the unions of all of these group of outcomes, $\mathcal{O}$.

\section{Results} \label{section:results}

\noindent In this section, we discuss our main results. Appendix~\ref{appendix:results} displays further results. In our main results, we combine the data of ABC and CARE to test the hypothesis in \eqref{eq:ho}. To do so, we compare children who were randomly assigned to treatment in ABC and to the highest level of care in CARE with children who were not assigned center-based childcare.\footnote{In Appendix~\ref{appendix:results} we show that (i) the family education treatment had no substantial effect, if compared to the control group; (ii) comparing the groups receiving center-based childcare to the control groups of ABC and CARE independently provide results very similar to those we discuss here.} We decide to pool the sample to test our hypothesis of interest because we want to evaluate center-based childcare as a policy, rather than as an implementation of a specific program.\\

\textbf{[MT: You should include observations in the table.]}
\textbf{[MT: Confusing: it seems at first that you only present results for females. Maybe give an outline of the results section at the beginning to give readers a roadmap.]} \\

\noindent In Tables~\ref{tab:ate_female_main1} and \ref{tab:ate_female_main2}, we present results for a set of economically relevant outcomes for females. Each outcomes generates eight estimates. To illustrate how we interpret them, consider one outcome: high school graduation at age 30. Column~(1) displays the mean difference in graduation between children assigned and not assigned to receive center-based childcare. This difference amounts to 20 percentage points. In column~(2) we present this difference controlling for a set of variables and accounting for program attrition.\footnote{See Appendix~\ref{appendix:controls} for our procedure for selecting controls.} In this case, the estimate remains practically unchanged. This is generally the case for all the estimates we consider, so we will restrict our discussion to estimates in which we include controls and account for program attrition.\\

\noindent The estimates in column (2) correspond to our first policy question: What is the effect of center-based childcare relative to the mix of alternatives at implementation? That is, we do not fix the alternative preschools to which almost 70\% of the control children had access. \textbf{[MT: You should provide a discussion of what the estimates suggest instead of pointing to just the column.]} \\

\noindent Columns (4) and (5) provide estimates where the treatment substitute is fixed. Specifically, they assess the more policy-relevant question: What is the effect of center-based childcare relative to a counterfactual where the child receives no treatment at all \textbf{[MT: Be more specified: no center-based treatment (?). Children will always receive some sort of early care ``treatment''.]}? In column (4), we compare the adjusted mean of children assigned and not assigned to center-based childcare. For children not assigned to center-based childcare, we restrict the sample to those who did not enroll in any alternative preschools. Compared to that of column (1), the effect almost doubles. To take into account possible selection into preschool alternatives, we consider a matching strategy.\footnote{We parameterize the matching using an Epanechnikov kernel-weight approach. Results are not sensitive to matching using nearest neighbor or propensity score matching.} If selection into preschool is based on observed characteristics, column (5) provides a selection-corrected estimate, relative to the estimate in column (4). The difference between (4) and (5) is economically sizable, as it amounts to a 6 percentage point decrease in high school graduation. This difference suggests that parents select on potential gains when enrolling their children into preschool alternatives. However, both estimates in columns (4) and (5) suggest that fixing children to no alternative preschools imply a sizable increase in the estimated treatment effect of center-based childcare. 

\noindent Columns (7) and (8) present estimates that inform another policy question: What is the effect of center-based childcare relative to a counterfactual where the child receives care from a fixed preschool alternative? The alternative we fixed is a non-program preschool, which was presumably lower quality than ABC or CARE and started treatment later, from ages 3 to 5 (see Appendix~\ref{appendix:background}). Therefore, this experiment consists of evaluating high-quality center-based childcare to an alternative of lower quality and intensity. As expected, the estimates decrease compared to the estimates in which children receive no center-based treatment. As before, the comparison between the estimates in columns (7) and column (8) suggest that parents select on potential gains.\\

\noindent The remainder of the results in Table~\ref{tab:ate_female_main1} and Table~\ref{tab:ate_female_main2} show that the strategies point to economically and statistically sizable and socially positive effects on cognition, education, welfare dependency, employment, and criminal activity. For females, the program does not have many statistically precise effects on health outcomes. However, these effects help verify the pattern we describe for high-school graduation, which almost all outcomes satisfy: (i) a socially positive effect of the programs, although not statistically significant for every outcome; (ii) controlling for background characteristics and correcting for program attrition has little effect on our estimates \textbf{[MT: Do you have an interpretation for this? Include in above paragraphs.]}; (iii) when fixing the counterfactual to (no) alternative preschool, the effect of center-based childcare with respect to the counterfactual (strengthens) weakens; (iv) the estimates in which we correct for potential selection shrink in absolute value, but the pattern in (iv) persists. \textbf{[MT: You should keep this paragraph, but integrate some of the discussion of results in the above paragraphs. You are leaving a lot of the work for the readers to interpret the table themselves, although this paragraph helps; I don't think readers will wait for this discussion before trying to grasp the tables.]}\\

\noindent To conclude our discussion of results for female outcomes, we summarize the total number of socially positive effects that the program has on the multiple outcomes we consider in Table~\ref{tab:counts_female}.\footnote{By ``socially positive'' we mean that we reverse the effects for outcomes such as crime or obesity when counting the effects of the program.} These outcomes represent multiple measures of human development from birth to adulthood and go beyond what we present in Table~\ref{tab:ate_female_main1} and Table~\ref{tab:ate_female_main2}---see Section~\ref{section:data} and Appendix~\ref{appendix:data} for a thorough discussion on all the outcomes.\\ 

\noindent The results in Table~\ref{tab:counts_female} are compelling. First, more than 70\% of all treatment effect estimates we present are positive. We contrast three hypotheses using this count. We test the null-hypothesis of at most 25\%, 50\%, and 75\% of outcomes having a positive treatment effect. We easily reject the first two hypothesis for any of the estimates we consider. Second, at least 20\% of the effects are significant at a 10\% level. Note that at a 10\% significance level, 10\% of the effects are expected to be significant by chance. Further, when fixing the children who did not receive center-based childcare to no preschool alternative, nearly 50\% of the effects are positive and significant at the 10\% level. For these estimates, we reject the null hypothesis of at most 25\% of the effects being significant at the 10\% level.

\input{output/tables/abccare/rslt_female_main1}
\input{output/tables/abccare/rslt_female_main2}
\input{output/tables/abccare/rslt_female_counts}

\noindent The results for males somewhat differ from the results for females, but they also suggest socially beneficial effects from center-based childcare. We display them in Table~\ref{tab:ate_male_main1} and Table~\ref{tab:ate_male_main2}. There are two main differences between males and females. First, outcomes of greatest policy interest such as employment and labor income exhibit a much stronger effect for males compared to females. In general, males have greater attachment to the labor force. Therefore, the difference in the effects could simply be an artifact of the general conditions of the labor market \textbf{[MT: What exact bearing does this have when taking differences?]}. A perhaps more surprising fact is that there are stronger effects on males' health.\footnote{This was already noted in \citet{Campbell_Conti_etal_2014_EarlyChildhoodInvestments}.} Second, as we will discuss, the pattern in which the the effects we present from columns (1) to (8) is not as clear as in the case of females.\\

\noindent For males, correcting for self-selection in the estimates that fix a counterfactual does not strongly indicate that parents enrolled children based on potential gains. Instead, for some outcomes this correction points toward the opposite effect. To illustrate this, consider years of education. When fixing children to no alternative preschool, the treatment effect increases by more than 0.4 years with respect to the effect where alternative preschool is not fixed. This pattern is the same in the case for females. However, when correcting for potential self-selection in the preschool enrollment decision, the estimate further increases from 1.224 to 1.696 years of preschool. While this estimate suggest that children with the most potential (or with the best home environment) stay at home, the analogous estimate for females indicates the opposite---that female children with the least potential (or with the worst home environment) stay at home. \textbf{[MT: Give an interpretation/story?]}\\

\noindent As in the case for females, we present the counts of positive effects, with a comprable inference exercise, in Table~\ref{tab:counts_male}. We fail to reject that at most 50\% of the outcomes are socially beneficial for any of the estimates we consider. The effects are weaker than for the case of females. \textbf{[MT: Is this evidence interesting in light of the effects themselves seeming to be stronger for males? How to interpret this discrepancy?]}

\input{output/tables/abccare/rslt_male_main1}
\input{output/tables/abccare/rslt_male_main2}
\input{output/tables/abccare/rslt_male_counts}

\noindent To finalize the discussion of our results, we evaluate the effect of the second-phase of treatment in Appendix~\ref{appendix:results}. When comparing children randomized into second-phase treatment to children randomized into second-phase control, we find very small effects. A further step would be to test the set of hypotheses we present in Table~\ref{table:hypotheses} for this phase. Unfortunately, doing so requires partitioning the ABC sample, which in this case would incur a loss of power that inhibits us from finding any statistical treatment effects \textbf{[MT: Do a power analysis (?)]}. It remains a research question of interest to understand (i) if multiple phases of treatment provide more enduring effects, relative to a single phase \textbf{[MT: Say what this means in policy terms. What is ``multiple phases of treatment'' for an education policymaker]}; and (ii) at what stage of childhood is providing early-life education most effective.

\section{Final Comments} \label{section:conclusion}

\noindent \textbf{[JLG: let's finish the paper before this.]}

%References
\clearpage
\singlespace
\bibliographystyle{chicago}
\bibliography{heckman}

\end{document} 