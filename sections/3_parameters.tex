\textbf{[JJH: This needs to be rewritten.][This section has been rewritten.]}

Random assignment to treatment does not guarantee that conventional treatment effect estimators answer policy-relevant questions. We define and estimate three parameters that address different policy questions.

Let $W=1$ indicate that the parents referred to the program participate in the randomization protocol. $W=0$ indicates otherwise. $R$ indicates randomization into the treatment group ($R = 1$) or to the control group ($R = 0$). $D$ indicates attending the program, i.e., $D = R$ implies compliance with the initial randomization protocol.

Individuals are eligible to participate in the program if baseline background variables $\bm{B}\in\mathcal{B}_0$. $\mathcal{B}_0$ is the set of scores on the risk index that determines program eligibility. Because all of the eligible people given the option to participate choose to do so $(W=1\text{ and } D=R)$, \textbf{[AZ: Just highlighting this here based on the comment in the data section. Should this be altered?]} we can safely interpret the treatment effects generated by the experiment as average treatment effects for the population for which $\bm{B}\in\mathcal{B}_0$ and not just treatment effects for the treated.

Let $Y^1_{j}$ be the outcome $j$ for the treated, and $Y^0_{j}$ be the control counterfactual. $Y^0_{j}$ depends on the exposure to various alternative preschools while ABC/CARE was active (i.e.,\ it depends on the degree of control substitution). The index set for the outcomes is $\mathcal{J}$, which we can partition by age (\ $\mathcal{J}_a$ with $\mathcal{J} = \bigcup \limits _{a \in \mathcal{A}} \mathcal{J}_a$ and $\mathcal{A}$ indexes age) or by outcome category (\ $\mathcal{J}_\ell$ with $\mathcal{J} = \bigcup \limits _{\ell \in \mathcal{L}} \mathcal{J}_\ell$ and $\mathcal{L}$ indexes categories). 

 All treatment-group children had the same exposure to the ABC/CARE treatment and no exposure to alternative center-based care. It would be desirable to identify and estimate parameters evaluating ABC/CARE against all possible levels of exposure to alternative childcare, but our samples are too small to credibly do so. We simplify the analysis of the counterfactual to ABC/CARE by creating two categories. ``$H$'' indicates that the control-group child is in home care throughout the entire length of the program. ``$C$'' indicates that a control-group child is in alternative center childcare for any amount of time.\footnote{This categorization is consistent with Figure~\ref{fig:proportion-alt-pre}. Once parents decided to enroll their children in alternative childcare arrangements, the children tended to stay enrolled up to age 5.} We test the sensitivity of our estimates to the choice of different categorizations in our empirical analysis in Appendix~\ref{appendix:vsensitivity-controlsub}.

We thus compress a complex reality into two counterfactual outcome states for each outcome $j$:
\begin{align*}
Y_{j,H}^0 \quad &: \quad \textbf{ Subject received home care exclusively} \\
Y_{j,C}^0 \quad &: \quad \textbf{ Subject received some alternative childcare}.
\end{align*}


One parameter of interest addresses the question: What is the effect of the program as implemented? This is the effect of the program compared to the next best alternative as perceived by the parents (or the relevant decision maker) and is defined by
\begin{equation}\label{eq:effect}
\Delta_j := \mathbb{E} \left[ Y_{j}^1 -  Y_{j}^0 | W =1 \right] = \mathbb{E} \left[Y_{j}^1 -  Y_{j}^0 | \bm{B} \in \mathcal{B}_0 \right],
\end{equation}
where the second equality follows because everyone who was eligible elected to participate in the program. For the sample of eligible people, this parameter addresses the effectiveness of the program relative to the quality of all available alternatives when the program was implemented, including staying at home. It is the parameter intended to be estimated by Local Average Treatment Effects (LATE).\footnote{\citet{Imbens_Angrist_1994_Econometrica}.}

We define $V$ as a dummy variable indicating that the control-group child attended an alternative center-based childcare. $V=0$ denotes that the control-group child stayed at home. The outcome when a child is in the control group is
\begin{equation}
Y_{j}^0 : = \left( 1 - V \right) Y_{j,H}^0 + \left( V \right) Y_{j,C}^0. \label{eq:meandiff}
\end{equation}
\noindent It is fruitful to assess the effectiveness of the program with respect to a counterfactual world in which the child stays at home full time. The associated causal parameter for those who would choose to keep the child at home is:
\begin{equation}\label{eq:cont1}
\Delta_j \left(V = 0 \right) : =   \mathbb{E} \left[ Y_{j}^1 -  Y_{j}^0 | V = 0, W = 1 \right] := \mathbb{E} \left[Y_{j}^1 -  Y_{j}^0 | V = 0, \bm{B} \in \mathcal{B}_0 \right].
\end{equation}
It is also useful to assess the average effectiveness of a program relative to attending an alternative childcare center for those who would choose an alternative:
\begin{equation}\label{eq:cont2}
\Delta_j \left( V =1 \right) : =   \mathbb{E} \left[ Y_{j}^1 -  Y_{j}^0 | V = 1, W = 1 \right] := \mathbb{E} \left[ Y_{j}^1 -  Y_{j}^0 | V = 1, \bm{B} \in \mathcal{B}_0 \right].
\end{equation}

Random assignment to treatment does not directly identify the parameters in Equations~\eqref{eq:cont1} or~\eqref{eq:cont2}. Econometric methods are required to identify these parameters. We primarily rely on matching to control for selection into home or alternative childcare by the control group. Our procedure assumes that the observed characteristics are sufficient to describe the selection into alternative center-based arrangements. Table~\ref{tab:testing-matched-samples} in Appendix~\ref{app:matching-is-fun} shows the balance across the groups in the matched samples, further justifying this approach.

We report results from alternative strategies, including instrumental variables and control functions, in Appendix~\ref{appendix:amethodology}. The results from these alternative strategies are consistent with our main results but lack precision. We characterize the determinants of choices and our strategy for controlling for selection into home care and alternative center-based care when we discuss the empirical results in Section~\ref{sec:treatment-effects}.\footnote{Appendix~\ref{appendix:vsensitivity-controlsub} displays results with alternative definitions of $V$ (i.e., different thresholds define if a child attended alternative childcare). The results are robust to the various definitions. What matters is whether any center-based child care is being used ($V>0$), and not the specific value of $V$.}

\subsection{Summarizing Multiple Treatment Effects}\label{sec:combining-functions}

The extensive data collection in ABC/CARE described in Section~\ref{sec:data} provides us with many outcomes that we could use to evaluate the program. Summarizing these effects in an intuitive, interpretable way is challenging.\footnote{In Appendix~\ref{appendix:results} we present an exhaustive list of treatment effects correcting the $p$-values using the step-down procedure in \citet{Romano_Wolf_2016_pval_SaPL}.} We start by constructing a simple, digestible summary: combining functions that count the proportion of treatment effects that are positive by different categories of outcomes. Similarly, we study the count of the proportion of treatment effects that are positive and significant at the 10\% level. We complement these functions by providing a non-parametric test on the equality of the joint distribution of outcomes within categories across counterfactuals developed in \citep{Rosenbaum_2005_Distribution_JRSS}.

\textbf{Combining Functions.} Consider a block of outcomes $\mathcal{J}_{\ell}$, with cardinality $B_{\ell}$ and an associated treatment effects $\Delta_1, \ldots \Delta_{B_\ell}$. We assume that outcomes can be ordered so that $\Delta_{j} >0$ is beneficial.\footnote{All but 5\% of the outcomes we study can be ranked in this fashion. See Appendix~\ref{appendix:results} for a discussion.} The count of positive treatment effects within block $\mathcal{J}_{\ell}$ is:
\begin{equation}
C_\ell = \sum^{B_\ell}_{j=1} \bm{1} (\Delta_{j} >0), 
\end{equation}

\noindent and the proportion of beneficial outcomes, our combining function, is $C_\ell / B_\ell$. In our empirical application we consider all the outcomes as a block, and then different blocks grouped by age (e.g.,\ childhood, school age, adulthood) or by common categories (e.g.,\ employment, health, crime).

Under the null hypothesis of no treatment effects for the block of outcomes indexed by $\mathcal{J}_\ell$, and assuming the validity of asymptotic approximations, $C_\ell / B_\ell$ is centered at $\frac{1}{2}$. We compute the fraction $C_\ell / B_\ell$ and the corresponding bootstrapped empirical distribution to obtain a $p$-value. The bootstrap procedure accounts for dependence in unobservables across outcomes (within blocks) in a general way. 

The test based on the number of outcomes for which the treatment effect is significant at the $10\%$ level is analogous: Under the null hypothesis, 10\% of all outcomes should be ``significant'' at the 10\% level even if there is no treatment effect of the program.\footnote{In this case, we perform a ``double bootstrap'' procedure to first determine significant treatment effects at $10\%$ level and then calculate the standard error of the count.} We provide evidence against both null hypotheses. The combining functions avoid: (i) arbitrarily picking outcomes that have statistically significant effects---``cherry picking''; or (ii) arbitrarily selecting blocks of outcomes to correct the $p$-values when accounting for multiple hypothesis testing. We present $p$-values for these hypotheses and a number of combining functions by outcome category in Appendix~\ref{appendix:results}. \footnote{In Appendix~\ref{appendix:results}, we present yet another alternative. We calculate a ``latent'' outcome out of the set of outcomes within a block and perform inference on this latent outcome. This analysis also points to beneficial effects of the program.}

\textbf{[JJH: Add discussion of Rosenbaum.][This subsection now describes the Rosenbaum test.]}

\textbf{A Non-Parametric Test.} We provide a brief explanation of the test in \citet{Rosenbaum_2005_Distribution_JRSS} and refer interested readers to the source for more details. Let $\mathcal{N}$ index the individuals in our sample and consider the block of outcomes $\mathcal{J}_\ell$. Let $d_{ii'}$ be the distance between the individuals $i, i' \in \mathcal{N}$, $i \neq i'$, based on the outcomes in $\mathcal{J}_\ell$. In our application, this is the Mahalanobis distance \citep{Mahalanobis_1936_PNISI}. There is an optimal non-bipartite pairing of individuals according to $d_{ii'}$ \citep{Derigs_1988_Solving_AOR}. This is obtained when minimizing the distance across all possible pairings $i, i'$ in the sample. 

Under the null hypothesis of no treatment effects, pairings of treatment-group children with control-group children should be as frequent as pairings of treatment-group children with treatment-group children and control-group children with control-group children. If a relatively large number of pairs are across groups (treatment-group children matching with control-group children), this fails to provide evidence against the null hypothesis that the joint distribution of outcomes in block $\mathcal{J}_\ell$ is the same across the treatment and control groups.

The number of treatment-control pairings in the optimal non-bipartite pairing within the block of outcomes $\mathcal{J}_\ell$, denoted by $A_\ell$, is a summary statistic allowing us to test the null hypothesis of interest. Its exact $p$-value can be calculated. Asymptotically, the studentized value of $A_\ell$ follows a normal standard distribution \citep{Rosenbaum_2005_Distribution_JRSS}. For each block, we present these $p$-values to complement the information provided by the combining functions.
