\input{../../preamble}
%\linespread{2}

\begin{document}


\begin{titlepage}
\newgeometry{top=.8in, bottom=.8in, left=.8in, right=.8in}

\title{\Large \textbf{Responses for Referees \\ Gender Differences in\\ the Benefits of an Influential Early Childhood Program}.}

\author{
Jorge Luis Garc\'{i}a\\
Department of Economics\\
The University of Chicago \and
James J. Heckman \\
American Bar Foundation \\
Center for the Economics of Human Development\\
The University of Chicago \and
Anna L. Ziff \\
Center for the Economics of \\
Human Development \\
The University of Chicago}
\date{First Draft: January 5, 2016\\ This Draft: \today \\}

\maketitle
\thispagestyle{empty}
\restoregeometry
\end{titlepage}

\restoregeometry

% REVIEWER 2

\section*{Reviewer \#2}

This is an interesting paper with potentially important findings regarding the longer-term effects of an innovative early childhood intervention. While based on a relatively small sample, randomized treatment assignment (program entry) permits credible causal inference regarding the program’s effectiveness. While the paper makes a valuable contribution to the literature, the paper has some shortcomings and I see significant scope for further improvements.
\begin{enumerate}
\item The findings in the paper apply to the population of eligible households who signed up to participate in the experiment. Are there systematic differences between eligible households who signed up and did not sign up? It would be useful to give the reader a sense of whether the participating households are representative of the eligible population. \textbf{This is an important point. After consulting older reports of the study, we learned the following: All providers of health care and social services (referral agencies) in the area of the ABC/CARE study were informed of the programs. They referred mothers whom they considered disadvantaged. Eligibility was corroborated before randomization by the researchers. Ramey, Yeates, and Short (1984) indicate that the encouragement from the referral agencies was such that all but one referred mother attended and agreed to participate in the initial randomization. We included this information in-text in the data section to clarify this point. We highlight that none of the eligible families dropped out before randomization.}


\item Strictly speaking, only the pooled control-treatment outcome comparisons exploit the randomized treatment assignment. Assuming no other selection issues related to nonrandom dropout, I consider those estimates to be the most credible. \textbf{We have clarified language throughout distinguishing between the approaches that use random assignment and those that rely on matching, and have added more explanation of the differences in assumptions needed for the evaluation in relation to the counterfactual scenarios. The full discussion of the approach that we take is in the appendix. }

Several other main findings in this study instead rely on strong conditional independence assumptions for identification. They involve a comparison of treatment group outcomes with outcomes for two different control groups: those where the child stayed at home and those where the child entered a lower-quality childcare center. For example, among the major findings is that ``Low-quality childcare arrangements are detrimental for boys'' and ``Home care is beneficial for boys compared to low- quality center childcare''. While not always clearly discussed in the paper, these conclusions are presumably based on taking the difference between columns 6 and 4 in Table 4, representing treatment effects that control for differences in observed characteristics. \textbf{We deleted or qualified statements like the ones you highlighted throughout to remind the reader that those comparisons rest on stronger assumptions than the LATE-like estimates. We no longer present the tables mentioned in this comment.}

An obvious challenge to establishing these causal effects is that the childcare choice among control group members is endogenous. As the authors acknowledge, those who opt for alternative care are less economically disadvantaged at baseline compared to children who stay at home. So the reliability of these findings in the paper depends on the extent to which the adjusted differences in outcomes reflect selection on unobservables. One would imagine, for example, that parent(s) of more difficult or demanding boys may be more inclined to send them to childcare instead of keeping them at home. So boys in childcare may differ systematically from boys staying at home. How confident can we be that the included controls adequately control for selection into childcare? How do mothers and households who keep boys at home compare to those who choose childcare, and how does this compare for girls? There is no discussion in the paper of any potential role of selection on unobservables. \textbf{We have expanded our description of the observed characteristics of the control-group children who selected into different childcare arrangements. We recognize that we may not fully account for potentially endogenous unobservables and now explicitly state that in the paper. We discuss estimates from alternative approaches in the appendix, including an instrumental variable approach and a control function approach. They are broadly consistent with our results for matching. These, in theory, should account for unobservables more completely than our main analysis and yield similar results to what we present in the paper. We have clarified that we try these approaches in-text. We discuss the instrumental variables that we use in more detail in the response to your next comment.}


\item Related to the previous point, it is unclear whether one could attribute a difference in outcomes solely to a child attending a lower-quality childcare center. Presumably the ``treatment'' also involves changes in other inputs as the decision to send a child to childcare involves monetary costs (while ABC/CARE and home care presumably are free), and may coincide with increased maternal employment. So what is estimated here is the effect of using lower-quality childcare center combined with changes in parental income and time inputs into child development, which could be compensatory or complimentary. Are the negative effects for boys due to lower quality childcare, or do they capture income effects?
 \textbf{Yes it is true that ABC/CARE is free for the families. Unfortunately, we do not have the breadth of data and sample to be able to disentangle income effects from direct effects of the program. It is true, as we show in Table A.4, that the mothers of the control-group girls who stay at home do not work whereas 14\% of the control-group boys who stay at home have a mother who works. This is consistent with the fact that more boys than girls have a father present, both in the data and as a documented pattern (e.g., Dahl and Moretti, 2008). This could be one mechanism through which the decision is made and could have implications for quality of home care. We have expanded on this greatly throughout the paper to link family characteristics, selection into alternative care, and the gender differences in the treatment effects. This is especially highlighted in Section 5. In addition, the concept that we have on the quality of the alternative center-based care come from auxiliary historical documents (e.g., state and federal standards), rather than self-report or direct observation. We added this in-text. We now test for quality at baseline in Table 5 and find that there is a significant difference favoring boys.}

 Does the choice perhaps reflect the absence of good alternative informal childcare by the parent(s), grandparents and friends, relative to those who opt for home care?
 \textbf{We attempted to use the presence of relatives as an instrument for selection into alternative center-based care. This is in Appendix E.1. There was an extensive neighborhood survey done when the ABC subjects (not CARE, unfortunately) were entering kindergarten. This included a more expansive enumeration of family in the area and allowed us to isolate which subjects had a grandparent in the area. In addition to this measure, we also used the survey information (available in ABC and CARE) on people who lived in the household to try to capture opportunity for home care. Using different combinations of these weaker instruments and a more plausibly exogenous one (being born in the fall, which would allow for easy enrollment into center-based care if following the academic year). We present various specifications in the appendix. The IV results are pretty comparable to the main results but less precise.}

What exactly counts as ``home care''? Does it include informal childcare arrangements? These issues deserve more discussion in the paper. \textbf{Researchers administered a survey to the control-group parents asking about childcare arrangements made during each month between birth and age 5. If the answer was either staying at home or in the care of a relative, neighbor, or friend, then that is coded as home care. If the answer involved some center-based program, then the respondent also provided the name, which further confirms that the care option was indeed center-based. We have added this clarification to the data section.}

 Do you have access to data on the time mothers spent with their children, and on time spent with other family, friends and siblings? \textbf{Unfortunately, we cannot study the differences in time use due to lack of data. There are no time diaries available. We note this in the text.}

 Perhaps more importantly, is there any evidence on gender differences in what constitutes ``staying at home'' or ``lower-quality childcare''? \textbf{We are not able to compare the quality of the center-based alternatives at the individual level and our knowledge of the quality of the home care is not precisely known. However, we have changed the analysis to focus on the differences between boys and girls at baseline and how these can suggestively result in the observed difference in treatment effects. Girls were more disadvantaged than boys at baseline, which we now document. Section 5 discusses that there is a difference in selection into alternative preschools between genders, with more advantaged boys staying at home. This is consistent with the treatment effects being stronger for boys compared to those who attend alternative care. For girls, those who were more advantaged attended alternative care, although the selection pattern is not as sharply defined as it is for boys. Similarly, the treatment effects are stronger for girls compared to those who stayed at home.}

\item Related to the previous comment, there is little discussion in the paper of the effect of the intervention on parental income. As the estimated effects look very large, they should be discussed in more detail. Does labor income include zero income values for those with non- working parents? \textbf{Yes, parental labor income is 0 for non-working parents. We removed this table.}

Presumably the large effect then captures changes in maternal employment, thus explaining why the parental income effects are so much bigger relative to the alternative of the child staying at home as compared to alternative center childcare. So one of the channels through which ABC/CARE affects child outcomes is through allowing increased maternal employment? How does this relate to estimated effects of maternal employment uncovered in the literature? \textbf{In response to this comment, we added a paragraph to Section 4 explaining the treatment effects on parental income. We amended the category to include maternal employment so that it is capturing the effect of the program on that dimension as well. We also reference the appendix, which has individual treatment effects on maternal employment. Although the effects on parental income still show up when comparing to the group that received alternative care, the effects on maternal employment are only present compared to the group that stayed at home. Although there are a few finding that subsidized child care does not increase maternal labor supply (e.g., Havnes and Mogstad, 2011), there are several that find a positive causal effect of increasing access to child care on maternal labor supply (Bauernschuster and Schlotter, 2015; Bettendorf et al., 2015; Geyer et al., 2015; Brilli et al., 2016). Brilli et al., (2016) is particularly consistent with our results given that they find an increased effect in provinces with less availability of alternative programs. This information is now in a footnote.They do not find that children's gender is significantly associated with mother's working status.}

\item Similar to the treatment of childcare choice among control group members, in your analysis you treat the presence of the father as exogenous, while it seems more like an endogenous outcome to me. \textbf{We previously had a figure showing the presence of the father by experimental group and gender over time. We have replaced this with Table 3  to more formally compare the baseline differences. That table highlights that father's presence is balanced at baseline. Although, as you say, it is definitely possible that randomization into the program can affect father's presence, we always use father's presence at baseline in the analysis. Fathers stay around less if a son (or a daughter) gets randomized into the program. This difference is not statistically significant though, as shown in Table 3.}

\item Nonrandom attrition. On page 9 you discuss that dropout is related to the health of the child and to mobility of families. Both seem highly related to potential outcomes, so this seems to generate a classic case of attrition-induced selection bias. How can we be confident that controlling for observables is sufficient? The estimates in Tables 4 and 5 clearly show that adjusting for covariates has meaningful impacts on treatment effect estimates, but they may still reflect differences in unobservables. Dropping 22 subjects out of a total sample of 121 is obviously not trivial, so it seems to me that the reliability of your approach for controlling for nonrandom attrition deserves more discussion in the main body of the paper. \textbf{This is a crucial point to clarify. We provide details for each of these individuals in Table A3. We argue that most cases of non-compliance were exogenous to the program implementers or to household choices and we elaborate on how we deal with them.}

\textbf{1. Four individuals in the treatment group did not complete the treatment. They left 3, 10, 6, and 9 months after the treatment began. We treat the as though they have had treatment (because they did, at least for a few months). In later life follow ups, we fully observe outcomes for this children and include them in our computations. This would only bias our results downwards, as this children did not complete treatment. In terms of information loss for estimating treatment effects, that is not an issue for these four children.}

\textbf{2. Four individuals died: two of them in the treatment group and two of them in the control group. Given the causes of death (heart disease for two of them, SIDS for one of them, and a pedestrian accident for one of them), we interpret this as missing at random. This would be information lost at random.}

\textbf{3. Four children in the treatment group "disappeared." There is no data on them, and it is difficult to make a methodological decision with respect to them. We have no data on them and have no other choice than to assume that they are missing at random.}

\textbf{4. One child crossed from the control to the treatment group. This crossover was suggested and enforced by the local authorities, and did not occur by household choice or by design. We decide to drop this child from our sample of analysis. This dropping could be interpreted as exogenous because was a consequence of an action of a third party (neither the household nor the program designers were responsible for this). There was a typo before---only one child in the control group crossed over to the treatment group. This individual had health issues.}

\textbf{5. One child in the control group and two children from the treatment group were dropped from the sample, in a standard attrition fashion, which we address as documented in the paper. We observe baseline data and data before age 8 for this children (i.e., they attrited but data collection for them continued).}

\textbf{6. Two children in the treatment group were diagnosed as developmentally delayed 6 and 36 months after the treatment began. This disqualified for treatment: Children were not supposed to be developmentally delayed. This is not a concern per se. The concern would be that analogous control-group children could not be detected (because usually there is less contact of program officers with control-group children). Given the complementary features offered to the control group and the frequent data collection, implementation staff kept a close relationship with the control-group children, which lessens that concern. This evidence comes from conversations with FPG staff.}

\item Most of the analysis in the paper focuses on the direction rather than the magnitude of treatment effects, and all outcomes are treated as equally important. While I understand your motivation for doing so, clearly some outcomes matter more than others. In my view it would be useful to add a brief discussion of weighting, or relative importance of these outcomes in your benefit (rates of return) analysis. \textbf{We added effect sizes (treatment-control mean divided by the control standard deviation), which allow for some sense of magnitude to give context to the other results (Table 4). We have added references to the rate of return analysis in this section) to better connect the results. We have also added more references to the cost-benefit results throughout.}

Furthermore, it appears from Tables 4 and 5 that the magnitudes of several estimated effects are very large (almost unrealistically so?), which at a minimum deserves more discussion in the paper. \textbf{Certain outcomes, especially income outcomes, have large variation. We removed these tables anyway due to a change in the presentation of results.}

\item It was not clear from the paper whether the authors investigated whether treatment effects vary with the presence of a grandparent or sibling, an analysis which could provide additional insights. \textbf{Thin support and incomplete data makes this analysis difficult to accomplish in a credible manner. The family structures of the subjects were complex resulting in household and family data that varies substantially between data collection points. We do use the presence of some relatives as an instrument for selection into preschool, although this is a crude measurement that is only possible to use as an instrument when interacting it with more plausibly exogenous instruments, like being born in the fall.}

\end{enumerate}

\textbf{Additional comments}
\begin{enumerate}
\item Page 1. It would be useful to add a sentence briefly summarizing earlier findings about differential gender benefits of early-life interventions (among studies that report these). \textbf{We moved this discussion a footnote and added a sentence summarizing earlier findings.}
\item Page 2. Please clarify here that what is meant with ``high-quality childcare'' is childcare provided by the ABC/CARE program, and ``low quality childcare'' is any alternative childcare arrangement used by control group members. It seems more appropriate to call these ``lower-quality childcare'' - can one really say these were low-quality? \textbf{We added more explanation in the introduction about the quality of ABC/CARE and the alternative options. We changed ``low-quality'' to ``lower-quality'' throughout the paper to capture that there was heterogeneity in the quality of the alternative preschool. However, the documentation that we provide in the appendix supports that even the alternative centers that had educative components, rather than being essentially child supervision, were of lower quality than what was offered in ABC/CARE. We also added a more detailed discussion on the quality of ABC/CARE and the alternative options.}
\item Page 2. The statement ``staying at home is a better option for them [boys], especially if the family environment is relatively advantaged (e.g. the father is present)'' appears at odds with the findings reported later in the paper. I presume you meant when the father is absent? \textbf{We removed this example because it is an oversimplification and confusing, as you pointed out.}
\item Page 3. How do the findings of the earlier studies listed in footnote 8 compare to those in this paper? \textbf{We edited this footnote to include some sentences on those findings relative to ours. The only papers of those listed that divide by gender is Campbell et al. (2014), which focuses on health results, and Anderson (2008), which does not have the complete data we analyze. Our findings are consistent with the findings in these papers, but uses more extensive data and different techniques.}
\item Page 4. The use of a 10\% significance level is unconventional in empirical economic research. Given the small size of your sample it may be reasonable, and perhaps is a convention in analyses based on combining functions, but in my view deserves a brief explanation. \textbf{We added a footnote clarify this in the paper. We also changed the presentation of the results throughout and now display $p$-values more extensively.}
\item Page 15. Explain what is meant with ``accounts for model pretesting''. Does this include the formation of the outcome ``blocks''? \textbf{We expanded the information on accounting for model pretesting. Accounting for model pretesting involves selecting the model with the most predictive control set. This is detailed in Appendix D.1.}
\item Page 15. Does the test based on the 10\% significance level of treatment effects on outcomes assume independence across outcomes within and across blocks? \textbf{The combining functions do not restrict the within- or between-outcomes correlation structure. To see this, note the following. In order to compute the point estimate, we simply categorize the variables and ask what proportion are either positive or positive and significant (depending of the statistic of interest). For inference, we bootstrap our procedure. For a bootstrap sample b, we sample with replacement our entire sample, re-categorize, and compute the statistics again. The standard error of our statistic is the standard deviation of the resulting empirical bootstrap distribution. Thus, our inference procedure does not restrict the within- or between-outcomes correlation structure.}
\item Page 17. You list a finding of increased college graduation for females, but in table 5 this result is missing and you state that you could not estimate the treatment effect for that outcome for women. \textbf{This was a typo. It should have read that it increased high school graduation. We have removed these tables. }
\item Page 20. ``Male results are stronger than female results''. Here and elsewhere in the paper the use of ``results'' is often confusing – do you mean outcomes or treatment effects? \textbf{We clarified this here and used more precise language throughout related to this concern.}
\item Pages 20-22. The statement on page 20 that benefits from ABC/CARE are largely driven by its effects on males' seem inconsistent with the statement on page 22 that ``females benefit more from the program than do males''. Is this apparent contradiction due to the difference between direction and magnitude of treatment effects? \textbf{This is a confusion between the dominance of females in the treatment effects versus the dominance of males in the cost/benefit analysis. That is, the treatment effects that are higher for males result in a higher monetary return on the investment. However, females have higher treatment effects in more outcomes (including some outcomes that cannot be monetized). We clarified this distinction throughout the paper and discuss it in the conclusion.}
\item Page 22. It appears that the results for the ``proportions equal 10\%'' test based on the pooled control group are missing in the paper? \textbf{We removed these figures from the paper.}
\end{enumerate}

\clearpage

% REVIEWER 3
\section*{Reviewer \#3}

This manuscript considers how a host of treatment outcomes differ between disadvantaged boys and girls who were subjects of two high-quality, random-assignment child care interventions. The manuscript finds that the number of significant socially beneficial treatment effects was higher for girls than boys and that the gender differences principally stem from a smaller number of significant treatment effects for boys when the relevant comparison is home care. The manuscript makes a methodological contribution through its use and statistical analysis of combining functions to count and statistically compare the numbers of significant socially beneficial treatment effects. As a methodological exercise, the manuscript is impressive. However, although the manuscript applies these methods to an important child care experiment, its substantive contribution is less clear.

First, comparisons of the counts of significant effects may not be especially valuable in this context. There is little consideration of the magnitudes of effects.  \textbf{We changed the summary of results in Section 4 in order to highlight the magnitude of the treatment effects rather than the direction/significance. Table 4 now shows standardized treatment effects by gender. These results are consistent with and complement the other analysis that focuses more on direction/significance or relative magnitude (comparing male results to female results). We reference the companion cost-benefit analysis more clearly throughout the paper, which focuses more on the magnitudes given that it weighs them by their associated social cost.}

Also, many of the outcomes are highly-gendered adult behaviors, such as employment and arrests, where we might not have expectations of comparable effects. Even if child care had similar effects on boys' and girls' early cognitive, emotional and behavioral outcomes, these might not translate into comparable adult outcomes. \textbf{This is a very important point. We argue that comparing the standardized treatment effects newly presented in Table 4 addresses this by standardizing across outcome domains.}

Second, the manuscript does not offer theories or explanations of how effects might have occurred in different domains; it focuses instead on the summary measures. \textbf{By adding the average effect sizes, the results are more comparable across different domains. We removed the summary of individual measures from the main paper because it was a selection of outcomes rather than something comprehensive. In the description of results in Sections 4 and 5, we do more to offer suggestions to explain certain effect sizes.}

The main area where it does dig deeper---gender differences in the benefits of the child care intervention relative to either home care or alternative care---doesn't lead to a convincing result, because the manuscript doesn't establish the comparability or representativeness of the comparison groups. The manuscript makes numerous statements about the inferiority of alternative child care for boys, but it hasn't made a strong case. \textbf{We expanded the explanations of the control group, referencing more explicitly Table A.4, which describes the baseline characteristics of the control-group children by selection into alternative care setting. We also explained in more detail the process of recruiting and randomizing the subjects. This helps establish that the sample reflected the children from disadvantaged families in the Chapel Hill area. Finally, the selection into home care or alternative center-based care is not randomized, as you mention. We included more explanation in the paper explicitly saying this and better explaining the assumptions of the methods we use to account for this selection. We aim for this expanded explanation to further support the analysis of results comparing ABC/CARE to alternative care settings by gender.}

\subsection*{Gender Differences}

The manuscript convincingly documents that there are many differences in outcomes from high-quality child care between boys and girls. The text documents treatment effects for many adult outcomes and shows that women have better treatment outcomes for education and employment, while men have better treatment outcomes for drug use, blood pressure, and hypertension. Some of the gender differences in health outcomes had previously been reported by Campbell et al. (2014) and other outcomes have been reported before.

The manuscript glosses over differences in the patterns of results. For example, it summarizes the results in Table 5 by writing, ``The general pattern is that male results are stronger than female results in the control group. The pattern is generally reversed in the treatment group.'' Well, yes, but it's still the case that men's treatment effects were better than women's treatment effects for many outcomes (age 5 IQ, college graduation, labor income, and all four health measures) and indistinguishable for a few others. The manuscript formalizes this approach with its combining functions and statistically confirms that there are more significant positive treatment effects for girls than boys. However, these analyses continue to show that there are many positive treatment effects for boys. \textbf{There are indeed many positive treatment effects for boys. Statements like the one you highlighted have been deleted or modified to be more nuanced (e.g., Section 4). We have also expanded references to the companion cost-benefit analysis, in which the weighted treatment effects reveal that the social returns for males are higher than those for females.}

The manuscript finds differences across many domains. But it's not clear that this is helpful. For example, how do we compare that girls had significantly better home scores at age 1.5 while boys didn't but boys had better labor incomes at 30 while girls didn't. The analysis seems worthwhile within domains of closely related measures but not across domains. More discussion and analysis of Figure 4 (and similar comparisons) would be a better way to go. \textbf{We edited the description of results to focus more on relating treatment effects on closely related outcomes. The effect sizes also help compare across domains.}

One piece of evidence that the counts may not be that valuable come from the reports of benefit-cost ratios that the authors calculated in their companion paper which indicate that the value of the benefits for boys is approximately four times that of girls. \textbf{The counts are valuable as one aggregate measure to understand the treatment effects. Weighing those treatment effects by the social cost is, of course, the most policy-relevant aggregate measure to report. However, presenting the counts with reference to the cost-benefit results highlights an earlier concern of yours that the context of the outcome matters. For example, ABC/CARE reduced females' criminal activity more than that of males'. However, after weighing these avoided crimes by their social cost, the weighted effect is much larger for men than for women. This is due to the nature of the crimes differing, with men committing more violent crimes. We have expanded reference to the companion paper throughout the manuscript.}

\subsection*{Alternative Child Care}

The focus of the manuscript turns to the type of control. The numbers of significantly positive treatment effects for girls are mostly similar regardless of the type of control situation, but, there are more differences in the counts for boys when the control is alternative child care rather than home care. Again, however, there are exceptions in the patterns. The treatment for boys is stronger for the home care comparison group for health but stronger for the alternative care group for cognitive skills, parenting, education/employment/income. There is no substantive discussion about why these different results should occur. \textbf{We changed much of the paper to better analyze why the effects differ by gender and alternative environment. We now present evidence that (1) the control-group girls were more disadvantaged at baseline than the control-group boys, (2) more advantaged control-group boys stay at home, (3) more advantaged control-group girls attend alternative preschools. This selection pattern helps explain the control situation. The exceptions to the patterns in the new presentation of results are discussed in Section 5. We redid this analysis to address this concern that the connection between the selection into alternative preschools and the treatment effects were not developed. Now, these are connected and we find gender differences in the selection process that are consistent with the gender differences in the treatment effects.}

The argument about the inferiority of alternative care seems to stem mainly from the higher count of positive treatment effects for the alternative care control than the home care control. However, these counts are similar to the counts for girls under each of the control situations. So this doesn't seem to provide strong evidence of gender differences in the harms associated with alternative care. Rather it looks like there is something unique about the home care that the boys received. \textbf{This is an insightful point that there could be a substantive difference in the care that boys received outside of ABC/CARE. We rewrote the paper and deemphasized ``vulnerability'' and ``quality'' and made a much stronger argument about the home environments Our new analysis addresses this directly by examining the baseline disadvantage and how that differs by gender. We present evidence to support what you intuited---that there is something different about the strength of home care between boys and girls. We extrapolated this to differences in alternative preschools as well given that control-group girls are in more resource-constrained environments than control-group boys (see Table 5). The full discussion of this is in Section 5. We document three facts: (1) boys' families are more advantaged than those of girls, (2) more advantaged boys stay at home than disadvantaged boys, (3) more advantaged girls attend alternative preschools than disadvantaged girls. This helps explain the gender differences in the estimates by mode of choice of alternative childcare.}

\subsection*{Selection into Home Care and Alternative Care}

Alternative care was selected by the parents and not randomly assigned. The manuscript uses matching to address the selection issues. However, it provides very little information (none in the body of the manuscript) about how much the resulting matched samples look like the treatment sample or each other. The manuscript is drawing conclusions about the impacts of alternative care but it hasn't shown that the matched alternative care sample for boys looks like either the home care or treatment samples. \textbf{This is an important point and we have added Table D.4 to Appendix D to show the balance between the groups after matching. The table is copied here for convenience.}

\singlespacing
\begin{table}[htbp!]
\begin{threeparttable}
\caption{Testing Matched Samples} \label{tab:testing-matched-samples}
\input{../../output/matching-baseline-test-pstest}
\begin{tablenotes}
\item \footnotesize \raggedright Note: This table tests the difference between the matched samples for both sets of matches that are done: treatment to alternative childcare and treatment to staying at home. The \% Bias is the standardized mean difference between the matched samples. The corresponding $t$-scores and $p$-values are also reported.
\end{tablenotes}
\end{threeparttable}
\end{table}
\doublespacing

\subsection*{Generalizability}

The children in this analysis come from extremely disadvantaged backgrounds. The mothers had an average IQ of 84; their average age at baseline was just under 20; and fathers were absent from three-quarters of the homes. Lack of maternal relatives (potential other caregivers) entered into the selection criteria. The initial characteristics of the children should be discussed more in the body of the manuscript for readers (especially those outside the U.S.) who are not familiar with the interventions. \textbf{We added Table 3 with more baseline information on the subjects as suggested. This helps better characterize the disadvantage of the subjects, especially the young age of the mothers. To discuss the representativeness of the sample of the larger US population, we calculate that 19\% of all African American children would be eligible now and that 43\% were eligible during the intervention. We include this in-text. It is true that our findings do not apply to a general population given the high disadvantage of the sample.}

A particular concern is that with such a modest initial sample and with the gender and control condition cuts that were made to the sample, the authors are trying to generalize from some extremely small cells. This is especially true of the home care cells. If Table A.3 is a guide, the boys' home care group is not only very small (9 children) but has a relatively high income, a high proportion of fathers present, older mothers, and more siblings. This again raises concerns that the differences in the treatment effects reflect something unusual in the boys home care sample. \textbf{The cells indeed get small after making the cuts used for our analysis. We no longer present this analysis in the main text.}

 \subsection*{Minor Points}
 \begin{itemize}
\item P. 17, manuscript reports that treatment increases girls' college completion by 13 percentage points, but the corresponding figures are dropped from Table 5. \textbf{This was a typo (it should have said that high school completion increased by 13 percentage points). We have removed those tables.}
\item Table A.5, is ``Mother Works'' a simple dummy variable? I can't determine how you arrived at the percentages listed in the table if it is. \textbf{Yes, it is a dummy variable. Most of the mothers in the sample did not work because they were in school. This is why the percentages in the table (A.4) are so low. We now clarify this.}
 \end{itemize}

 \clearpage

% REVIEWER 4
\section*{Reviewer \#4}

\subsection*{Summary}

This paper estimates the pooled impacts of two ``model'' randomized early childhood interventions---the Carolina Abecedarian Project (ABC) and the Carolina Approach to Responsive Education (CARE)---separately by gender. Because there are so many outcomes---indeed, nearly as many outcomes as participants (126 vs. 156)---inference focuses on the proportion of positive (and separately, proportion of statistically significant) treatment effects within outcome categories (IQ, education, etc.). In addition to the basic treatment-control comparison, which is based on the randomization of access to (and participation in) the intervention, the authors present comparisons of outcomes in the treatment group to those of subsets of the control group defined by exposure to center-based care under age five, adjusting for selection on observables (only) through matching. Thus, they attempt to assess the impacts of the ``high quality'' ABC/CARE intervention relative to two counterfactuals: home care and the ``low quality'' center-based care available to the control group.

\subsection*{Comments}

Impact evaluations of early childhood programs depend on the counterfactual; in turn, the policy relevance of findings from a particular intervention depend on whether that counterfactual still stands. The fraction of children today in formal childcare or early education settings is much higher than it was in the late 1970s and early 1980s, when the ABC and CARE interventions were carried out. I therefore really like the fact that the authors are trying to understand the importance of the counterfactual to their findings. That the importance may vary by gender is also interesting, and I think novel. I also applaud the authors for producing a very readable and generally clear paper; the graphical representations of the impacts are particularly helpful. \textbf{We really appreciate the point that analyzing the alternative childcare environment more closely helps relate these results to the modern context. We added a sentence with this justification to the introduction.}

However, I have three major concerns about the paper as it currently stands. I will elaborate on each of these concerns in the remainder of this report, then offer a few more minor comments.

\begin{description}
\item[Major concern 1]  Participation in center-based care in the control group is not randomized. As the paper is currently written, it seems like the treatment-control/home care and treatment-control/center care inferences are as credible as the treatment-full control group inferences. These inferences are not created equally. The treatment-full control group inference is based on randomization; sample sizes are small, but absent selective attrition, randomization should address both selection on observables and selection on unobservables. By contrast, the treatment-control/home care and treatment-control/center care comparisons only adjust for selection on observables. I think that this needs to be made very clear early on in the paper (well before page 14, where it is first mentioned in the current draft), and appropriate caveats on conclusions drawn from these inferences given throughout the text.  \textbf{We have expanded upon this point in the paper to ensure that the differences in the approaches are explicitly stated. We now first mention this distinction earlier. We also have adjusted the language describing the results (Section 5) so that the assumptions are more clearly stated (Section 3). This provides more qualifications to the results to address this concern.}

\item[Major concern 2] There is too much focus on the sign and statistical significance of effects, and too little on magnitudes. In part, this is an artifact of the statistics (and corresponding inference) that the authors have chosen to highlight:  proportions of positive effects within categories. Given that the interest is in gender differences in treatment effects, shouldn't magnitudes matter as well?  I think that there is an easy solution to this:  instead of focusing on proportions, why not focus on standardized treatment effects within categories, as in the Kling, Liebman, and Katz (2007) evaluation of MTO or the Finkelstein, et al. (2012) evaluation of the Oregon Health Insurance Experiment?  Alternatively, monetization of the effects (e.g., to calculate cost-benefit ratios) would provide an omnibus magnitude, but it looks like you've already done this in another paper. \textbf{We followed this comment by adding average effect sizes (averaged over outcomes within a category). This is in Table 4. We used a similar approach as the cited papers to present standardized treatment effects. We agree that this is clearer than the previous presentation which relied on relative magnitude. It also helps contextualize the other results that still rely on relative magnitude. We have also clarified summarizing the results in this paper in relation to the companion paper on cost-benefit analysis (this clarification is done throughout). The very short summary is that ABC/CARE positively and significantly affected more results for women than for men. However, when weighing the treatment effects by the social cost, ABC/CARE had a higher return for men than for women. This is partially because the types of outcomes that show larger treatment effects for men than women, such as health, are very socially costly. There is another issue that there are many results that are not able to be monetized. Family outcomes such as marriage or number of children are good examples of this. It is possible that ABC/CARE positively affects females in non-market ways that are not well encapsulated in either of these papers. All of this is better explained in-text as a result of the feedback we received.}

\item[Major concern 3:]  There is inadequate reconciliation with existing literature. There is (to me) a glaring lack of reconciliation with several key papers. First, and most importantly, Anderson (2008) estimates the impacts of a number of model early interventions---including ABC---correcting for multiple inference. This paper is not even cited, despite the fact that it is well known in this literature (cited 590 times in Google Scholar at the time this report was written). The authors really must cite this paper, and describe what they do differently from it; if gender differences in ABC have already been explored, what is the contribution? Do the authors arrive at different conclusions?  If so, why? \textbf{We included this citation explaining why we innovate on that paper. One thing that is important to note is that Anderson (2008) was published before the age-30 and -34 data collections were available. These later data collections are really important to capture more complete life cycle outcomes, especially health, crime, and employment. These findings complicate the gender differences reported in Anderson (2008). We also included this paper in Table C.1, which summarizes previous literature in more depth. Finally, we have expanded references to previous literature more generally both in the number of citations and the description given of those findings relative to ours. Gender differences of ABC/CARE have not been the primary subject matter of previous papers.}

Second, given that gender differences in ABC have indeed previously been documented, the attempt to estimate effects relative to specific counterfactuals (home care, center-based care) becomes a more important aspect of the paper's potential contribution. With this in mind, I think that the authors must really reconcile with Kline and Walters (2016) as well as Feller et al. (2016), who do the same thing (but in different ways) in the context of the Head Start Impact Study. Are they taking a similar approach? If not, does taking the approach of, for example, Kline and Walters (2016), matter for the conclusions?  \textbf{We use matching as a baseline in order to estimate the effect of ABC/CARE relative to different counterfactuals. In Appendix E, we present results from an instrumental variable approach relying on potential shifters of enrollment like presence of relatives or month of birth. The results reported in the appendix are larger than the intent-to-treat estimates, but much less precise. We are more limited in instruments given the small sample and its homogeneity relative to a study like HSIS. With a larger sample, they can also rely on normality, which we do not do. They both find that Head Start has larger gains compared to a home environment. Neither Kline and Walters (2016) nor Feller et al. (2016) present results by gender, so we cannot compare our results exactly. However, one important note is that a lot of the control-group subjects who enrolled in other center-based care actually enrolled in other Head Start programs. Even for those who did not, the standards in the early 2000s for preschools are much higher than those in the 1970s. The difference between ABC/CARE and the alternative center-based programs should be much larger than the difference between Head Start and the alternatives that the HSIS control-group selected into. In addition to not dividing by gender, this could explain the more decisive findings. We have included reference to these papers, and other earlier work (e.g., Heckman, 1992; Heckman, Hohmann, Smith, and Khoo, 2000)  in the introduction and a few sentences addressing this and more explicitly referencing Appendix E.}

Approach aside, the authors seem to be doing a similar dissection of counterfactual care options in their companion paper (Garcia et al. 2017). Is the innovation of the current paper simply that you're doing it by gender?  Why is this important? \textbf{The two papers are quite distinct. This paper is meant to report and summarize the myriad of treatment effects and their sources and to consider the impact of the mode of alternative childcare on estimated treatment effects. We present treatment effects by gender using multiple methods. The companion paper takes these estimates and focuses on the methodology of cost-benefit analysis. That paper also presents results by gender. We have added a few sentences in the introduction to clarify this point.}
\end{description}

\textbf{Minor comments}
\begin{enumerate}
\item I would recommend being clearer about what is meant by early education ``quality'' in this paper. Is it simply the cost of the program or in resources (``structural quality'')?  Is it something about interactions between caregivers and children (``process quality'')? I don't think that any process quality measures are available for the ABC or CARE interventions, but discussions of quality in early intervention have evolved, and the text should reflect this. \textbf{We added more explanation about the quality of ABC/CARE and the alternatives throughout, but especially in the data section. The vocabulary of process and structural quality is useful and we incorporated this citing several papers that study the relationship between different aspects of the two. You are correct that there are no measures of process quality in ABC/CARE, let alone for the control-group subjects who attended alternative care. We expanded more on the aspects of quality that we do know about to argue that the quality in ABC/CARE was high, especially compared to the other programs during that time.}
\item Figure 1 is troubling, in that it suggests that there is a lack of balance in observables across the control and treatment groups despite randomization. I think it would be helpful to see more discussion of the validity of randomized variation among non-attriters in the main text. (Relatedly, I don't think that dropouts post-randomization are not a problem, as seems to be implied in footnote 9.)  \textbf{That figure showed father's presence over time even after randomization. The pattern reflects a more widely documented trend that parents stay together more when the child is a son rather than a daughter. At randomization, the experimental groups were balanced in this variable and other variables related to disadvantage. Unfortunately, the exact randomization protocol is not documented, i.e., we do not know exactly what variables were used to match subjects and how this match occurred. To clarify the baseline characteristics, we replaced Figure 1 with Table 3. This shows the male/female and treatment/control differences at baseline. We also included more in-text explanation. Finally, our new analysis of the counterfactual scenarios relies on displaying differences in baseline characteristics by gender. The fact that girls are more disadvantaged than boys at baseline helps explain the differences in treatment effects and the differences in alternative options for the control group.}
\item Likewise, it would be helpful to see differences in observable characteristics between control children who attended and did not attend alternative childcare. \textbf{This is reported in Table A.4. We expanded the explanation of it in-text in order to speak to this concern. The main difference is that for control-group girls, working mothers always place them in alternative care. For control-group boys, working mothers do not always do this, most likely related to the fact that more fathers are present for boys than for girls.}
\item Presenting estimates by gender and family background, as is done in section 5, doesn't seem advisable given the very small sample sizes. \textbf{We have removed this analysis. }
\item Needing clarification:
\begin{enumerate}
		\item 1st full para., p. 2:  what do ``differentially promotes'' and ``differentially enhances'' mean exactly?  The language seems to imply that both sexes are positively affected by the intervention on all dimensions stated, but this does not appear to be the case (particularly with the step-down p-values) in Tables 4 and 5. \textbf{We changed the entire introduction so that the results are more clearly summarized.}
		\item Last full paragraph, p. 3:  if ``all achievement measures favor males in the control group,'' why isn't the proportion favoring males in the control group 1.0 in Table 1? \textbf{This was a typo in the text (not the table) that we have corrected.}
		\item P. 6:  It is not clear how the home visitation component can be safely ignored. Was there additional randomization of home visitation within the initial treatment group? \textbf{In ABC, the home visiting that occurred between 5 and 8 was randomized separately. No effect was found. In CARE, this 5-8 component was not randomized with all subjects who received center-based care also receiving this school-age component. We extrapolate that the findings from ABC extend to CARE as minimal changes were made to the school-age intervention. In sum, randomization of this component in ABC allows us to rule out that the age 5-8 intervention has an effect. We expanded the in-text reference related to this issue.}
		\item P. 9:  ``Dropouts are evenly balanced across treatments and controls?''  In terms of numbers or observable characteristics? \textbf{They are evenly balanced in terms of numbers. We clarify this in the text. We find that the estimates are robust to correcting for this attrition, as reported in the appendix.}
		\item P. 16:  how exactly does column (2) adjust for ``the differences in attrition''? \textbf{We adjust for attrition using IPW. This is documented in the appendix. We no longer present these tables in the main text.}
		\item Continuing paragraph, top of p. 17:  college graduation estimates are referenced but not given in the table. \textbf{This was a typo (it should have said that high school graduation increases). We removed this table.}
		\item I would be clear in the discussion on pp. 16-17 that you are using the bootstrapped p-values, not the step-down p-values. \textbf{We no longer present these results.}
		\item Pp. 21-22:  How is it that the benefit/cost ratio of ABC/CARE is so much larger for males than for females? This seems contradictory to the following statement that ``females benefit more from the program than males.''  Is that not all outcomes are created equal (in terms of social value)?  This gets back to my comments about the importance of magnitudes. \textbf{We provide more detail in response to this above, but the outcomes for which men are more affected are costlier to society. We have clarified this throughout the paper.}
		\item P. 26:  Another seeming contradiction: estimated treatment effects do not ``appear similar across genders comparing treatment to staying at home full time''; at least it doesn't appear that way in Figures 3 and 4. \textbf{We have deleted this sentence and adjusted the description in Section 5 to more accurately summarize the treatment effects discussed in Section 4.}
\end{enumerate}
\end{enumerate}

\end{document}
