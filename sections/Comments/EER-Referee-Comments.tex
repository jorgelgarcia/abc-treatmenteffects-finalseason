\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}


\linespread{1.5}

\begin{document}

\title{Collated Referee Reports}
\maketitle

\section*{Reviewer \#2}

This is an interesting paper with potentially important findings regarding the longer-term effects of an innovative early childhood intervention. While based on a relatively small sample, randomized treatment assignment (program entry) permits credible causal inference regarding the program’s effectiveness. While the paper makes a valuable contribution to the literature, the paper has some shortcomings and I see significant scope for further improvements.
\begin{enumerate}
\item The findings in the paper apply to the population of eligible households who signed up to participate in the experiment. Are there systematic differences between eligible households who signed up and did not sign up? It would be useful to give the reader a sense of whether the participating households are representative of the eligible population. \textbf{This is an important point that unfortunately lacks formal documentation. However, after speaking with some of the researchers who implemented the program, they relayed the following: All providers of health care and social services (referral agencies) in the area of the ABC/CARE study were informed of the programs. They referred mothers whom they considered disadvantaged. Eligibility was corroborated before randomization by the researchers. Our conversations with the program staff indicate that the encouragement from the referral agencies was such that most referred mothers attended and agreed to participate in the initial randomization. We included this information in-text in the data section to clarify this point (pg.\ 9). As we highlight on pg.\ 10, none of the eligible families dropped out before randomization.}


\item Strictly speaking, only the pooled control-treatment outcome comparisons exploit the randomized treatment assignment. Assuming no other selection issues related to nonrandom dropout, I consider those estimates to be the most credible. Several other main findings in this study instead rely on strong conditional independence assumptions for identification. They involve a comparison of treatment group outcomes with outcomes for two different control groups: those where the child stayed at home and those where the child entered a lower-quality childcare center. For example, among the major findings is that ``Low-quality childcare arrangements are detrimental for boys'' and ``Home care is beneficial for boys compared to low- quality center childcare''. While not always clearly discussed in the paper, these conclusions are presumably based on taking the difference between columns 6 and 4 in Table 4, representing treatment effects that control for differences in observed characteristics. An obvious challenge to establishing these causal effects is that the childcare choice among control group members is endogenous. As the authors acknowledge (for example on page 11), those who opt for alternative care are less economically disadvantaged at baseline compared to children who stay at home. So the reliability of these findings in the paper depends on the extent to which the adjusted differences in outcomes reflect selection on unobservables. One would imagine, for example, that parent(s) of more difficult or demanding boys may be more inclined to send them to childcare instead of keeping them at home. So boys in childcare may differ systematically from boys staying at home. How confident can we be that the included controls adequately control for selection into childcare? How do mothers and households who keep boys at home compare to those who choose childcare, and how does this compare for girls? There is no discussion in the paper of any potential role of selection on unobservables. \textbf{Table C.1 shows tests for differences in observed characteristics between the groups. Ask Jorge.}
\item Related to the previous point, it is unclear whether one could attribute a difference in outcomes solely to a child attending a lower-quality childcare center. Presumably the ``treatment'' also involves changes in other inputs as the decision to send a child to childcare involves monetary costs (while ABC/CARE and home care presumably are free), and may coincide with increased maternal employment. So what is estimated here is the effect of using lower-quality childcare center combined with changes in parental income and time inputs into child development, which could be compensatory or complimentary. Are the negative effects for boys due to lower quality childcare, or do they capture income effects?
 \textbf{Yes it is true that ABC/CARE is free (we clarify this now on pg.\  6) and home care is most likely free. Unfortunately, we do not have the breadth of data and sample to be able to disentangle income effects from direct effects of the program. It is true, as we show in Table C.1, that the mothers of the control-group girls who stay at home do not work work whereas 14\% of the control-group boys who stay at home have a mother who works. This is consistent with the fact that more boys than girls have a father present. This could be one mechanism through which the decision is made and could have implications for quality of home care. Unfortunately, even for the cases in which the father is present, we have no measures on the quality of the home care. Even the concept that we have on the quality of the alternative center-based care come from auxiliary historical documents (e.g., state and federal standards), rather than self-report or direct observation. We added this in-text (pg.\ 12).}
 
 Does the choice perhaps reflect the absence of good alternative informal childcare by the parent(s), grandparents and friends, relative to those who opt for home care? 
 \textbf{We attempted to use the presence of relatives as an instrument for selection into alternative center-based care. This is in Appendix E.1 (pg.\ 130). There was an extensive neighborhood survey done when the ABC subjects (not CARE, unfortunately) were entering kindergarten. This included a more expansive enumeration of family in the area and allowed us to isolate which subjects had a grandparent in the area. In addition to this measure, we also used the survey information (available in ABC and CARE) on people who lived in the household to try to capture opportunity for home care. Using different combinations of these weaker instruments and a more obviously exogenous one (being born in the fall, which would allow for easy enrollment into center-based care if following the academic year). We present various specifications in the appendix and the results compared to the intent-to-treat estimates. The IV estimates are much larger, but less precise. We added this information to footnote 8 (pg.\ 4).}

What exactly counts as ``home care''? Does it include informal childcare arrangements? These issues deserve more discussion in the paper.\textbf{Researchers administered a survey to the control-group parents asking about childcare arrangements made during each month between birth and age 5. If the answer was either staying at home or in the care of a relative, neighbor, or friend, then that is coded as home care. If the answer involved some center-based program, then the respondent also provided the name, which further confirms that the care option was indeed center-based. We have added this clarification to the data section (pg.\ 10).}

 Do you have access to data on the time mothers spent with their children, and on time spent with other family, friends and siblings? \textbf{Unfortunately, these data are not available. [Jorge, is this something that should be clarified in-text?]}
 
 Perhaps more importantly, is there any evidence on gender differences in what constitutes ``staying at home'' or ``lower-quality childcare''? \textbf{Ask Jorge.}

\item Related to the previous comment, there is little discussion in the paper of the effect of the intervention on parental income. As the estimated effects look very large, they should be discussed in more detail. Does labor income include zero income values for those with non- working parents? Presumably the large effect then captures changes in maternal employment, thus explaining why the parental income effects are so much bigger relative to the alternative of the child staying at home as compared to alternative center childcare. So one of the channels through which ABC/CARE affects child outcomes is through allowing increased maternal employment? How does this relate to estimated effects of maternal employment uncovered in the literature? \textbf{Jorge, can we discuss how to redo the description of the results?}

\item Similar to the treatment of childcare choice among control group members, in your analysis you treat the presence of the father as exogenous, while it seems more like an endogenous outcome to me. \textbf{We previously had a figure showing the presence of the father by experimental group and gender over time. We have replaced this with Table 3 on pg.\ 9 to more formally compare the baseline differences. That table highlights that father's presence is exogenous at baseline. Although, as you say, it is definitely possible that randomization into the program can affect father's presence, we always use father's presence at baseline in the analysis. We now clarify this on pg.\ 26.}

\item Nonrandom attrition. On page 9 you discuss that dropout is related to the health of the child and to mobility of families. Both seem highly related to potential outcomes, so this seems to generate a classic case of attrition-induced selection bias. How can we be confident that controlling for observables is sufficient? The estimates in Tables 4 and 5 clearly show that adjusting for covariates has meaningful impacts on treatment effect estimates, but they may still reflect differences in unobservables. Dropping 22 subjects out of a total sample of 121 is obviously not trivial, so it seems to me that the reliability of your approach for controlling for nonrandom attrition deserves more discussion in the main body of the paper. \textbf{Ask Jorge.}

\item Most of the analysis in the paper focuses on the direction rather than the magnitude of treatment effects, and all outcomes are treated as equally important. While I understand your motivation for doing so, clearly some outcomes matter more than others. In my view it would be useful to add a brief discussion of weighting, or relative importance of these outcomes in your benefit (rates of return) analysis. Furthermore, it appears from Tables 4 and 5 that the magnitudes of several estimated effects are very large (almost unrealistically so?), which at a minimum deserves more discussion in the paper. Relatedly, the results in Tables 4 and 5 are limited to average effects, while it may be useful to focus on extreme negative (and perhaps positive) outcomes. \textbf{Jorge, can we discuss how to redo the description of the results?}
\item It was not clear from the paper whether the authors investigated whether treatment effects vary with the presence of a grandparent or sibling, an analysis which could provide additional insights. \textbf{Ask Jorge.}
\end{enumerate}

\textbf{Additional comments}
\begin{enumerate}
\item Page 1. It would be useful to add a sentence briefly summarizing earlier findings about differential gender benefits of early-life interventions (among studies that report these). \textbf{We added a sentence summarizing these differences to the third paragraph in the introduction (pg.\ 1).}
\item Page 2. Please clarify here that what is meant with ``high-quality childcare'' is childcare provided by the ABC/CARE program, and ``low quality childcare'' is any alternative childcare arrangement used by control group members. It seems more appropriate to call these ``lower-quality childcare'' - can one really say these were low-quality? \textbf{We added more explanation in the introduction about the quality of ABC/CARE and the alternative options. We changed ``low-quality'' to ``lower-quality'' throughout the paper to capture that there was heterogeneity in the quality of the alternative preschool. However, the documentation that we provide in the appendix supports that even the alternative centers that had educative components, rather than being essentially child supervision, were of lower quality than what was offered in ABC/CARE (pg.\ 29 of the appendix). We also added a more detailed discussion on the quality of ABC/CARE (pg.\ 8) and the alternative options (pg.\ 12).}
\item Page 2. The statement ``staying at home is a better option for them [boys], especially if the family environment is relatively advantaged (e.g. the father is present)'' appears at odds with the findings reported later in the paper. I presume you meant when the father is absent? \textbf{We removed this example because it is an oversimplification and confusing, as you pointed out.}
\item Page 3. How do the findings of the earlier studies listed in footnote 8 compare to those in this paper? \textbf{We edited this footnote (now footnote 5 on pg.\ 2) to include some sentences on those findings relative to ours. The only paper of those listed that divide by gender is Campbell et al. (2014), which focuses on health results. Our findings are consistent with theirs.}
\item Page 4. The use of a 10\% significance level is unconventional in empirical economic research. Given the small size of your sample it may be reasonable, and perhaps is a convention in analyses based on combining functions, but in my view deserves a brief explanation. \textbf{We added an explanation that the sample size is very small to footnote 28 on pg.\ 18. We also changed the presentation of the results in the introduction such that the $p$-values are printed directly.}
\item Page 15. Explain what is meant with ``accounts for model pretesting''. Does this include the formation of the outcome ``blocks''? \textbf{Ask Jorge.}
\item Page 15. Does the test based on the 10\% significance level of treatment effects on outcomes assume independence across outcomes within and across blocks? \textbf{Ask Jorge.}
\item Page 17. You list a finding of increased college graduation for females, but in table 5 this result is missing and you state that you could not estimate the treatment effect for that outcome for women. \textbf{This was a typo. It should have read that it increased high school graduation. We corrected it (pg.\ 18). }
\item Page 20. ``Male results are stronger than female results''. Here and elsewhere in the paper the use of ``results'' is often confusing – do you mean outcomes or treatment effects? \textbf{We clarified this here (outcomes, pg.\ 21) and used more precise language throughout related to this concern.}
\item Pages 20-22. The statement on page 20 that benefits from ABC/CARE are largely driven by its effects on males' seem inconsistent with the statement on page 22 that ``females benefit more from the program than do males''. Is this apparent contradiction due to the difference between direction and magnitude of treatment effects? \textbf{This is a confusion between the dominance of females in the treatment effects versus the dominance of males in the cost/benefit analysis. That is, the treatment effects that are higher for males result in a higher monetary return on the investment. However, females have higher treatment effects in more outcomes (including some outcomes that cannot be monetized). We clarified this distinction throughout the paper in addition to the sentences you highlighted (pg.\ 23).}
\item Page 22. It appears that the results for the ``proportions equal 10\%'' test based on the pooled control group are missing in the paper? \textbf{This is Figure 2b, but it was confusing how it was referenced before. We have corrected this so that it is clear (pg.\ 24).}
\end{enumerate}

\clearpage

% REVIEWER 3
\section*{Reviewer \#3}

This manuscript considers how a host of treatment outcomes differ between disadvantaged boys and girls who were subjects of two high-quality, random-assignment child care interventions. The manuscript finds that the number of significant socially beneficial treatment effects was higher for girls than boys and that the gender differences principally stem from a smaller number of significant treatment effects for boys when the relevant comparison is home care. The manuscript makes a methodological contribution through its use and statistical analysis of combining functions to count and statistically compare the numbers of significant socially beneficial treatment effects. As a methodological exercise, the manuscript is impressive. However, although the manuscript applies these methods to an important child care experiment, its substantive contribution is less clear. 

First, comparisons of the counts of significant effects may not be especially valuable in this context. There is little consideration of the magnitudes of effects.  \textbf{We changed the summary of results in the introduction in order to highlight the magnitude of the treatment effects rather than the direction/significance. Table 1 now shows standardized treatment effects by gender. These results are consistent with and nicely complement the other analysis that focuses more on direction/significance or relative magnitude (comparing male results to female results).} 

Also, many of the outcomes are highly-gendered adult behaviors, such as employment and arrests, where we might not have expectations of comparable effects. Even if child care had similar effects on boys' and girls' early cognitive, emotional and behavioral outcomes, these might not translate into comparable adult outcomes. \textbf{This is a very important point. We argue that comparing the standardized treatment effects newly presented in Table 1 addresses this. This comparison nets out the control groups of each gender, thereby comparing the marginal effect on treatment relative to the baseline by gender. Ask Jorge.}

Second, the manuscript does not offer theories or explanations of how effects might have occurred in different domains; it focuses instead on the summary measures. \textbf{Ask Jorge.}

The main area where it does dig deeper---gender differences in the benefits of the child care intervention relative to either home care or alternative care---doesn't lead to a convincing result, because the manuscript doesn't establish the comparability or representativeness of the comparison groups. \textbf{Ask Jorge.}

The manuscript makes numerous statements about the inferiority of alternative child care for boys, but it hasn't made a strong case. \textbf{Ask Jorge.}

\subsection*{Gender Differences}

The manuscript convincingly documents that there are many differences in outcomes from high-quality child care between boys and girls. The text documents treatment effects for many adult outcomes and shows that women have better treatment outcomes for education and employment, while men have better treatment outcomes for drug use, blood pressure, and hypertension. Some of the gender differences in health outcomes had previously been reported by Campbell et al. (2014) and other outcomes have been reported before.

The manuscript glosses over differences in the patterns of results. For example, it summarizes the results in Table 6 by writing, ``The general pattern is that male results are stronger than female results in the control group. The pattern is generally reversed in the treatment group.'' Well, yes, but it's still the case that men's treatment effects were better than women's treatment effects for many outcomes (age 5 IQ, college graduation, labor income, and all four health measures) and indistinguishable for a few others. The manuscript formalizes this approach with its combining functions and statistically confirms that there are more significant positive treatment effects for girls than boys. However, these analyses continue to show that there are many positive treatment effects for boys. \textbf{Jorge, can we discuss how to redo the description of the results?}

The manuscript finds differences across many domains. But it's not clear that this is helpful. For example, how do we compare that girls had significantly better home scores at age 1.5 while boys didn't but boys had better labor incomes at 30 while girls didn't. The analysis seems worthwhile within domains of closely related measures but not across domains. More discussion and analysis of Figure 4 (and similar comparisons) would be a better way to go. \textbf{Jorge, can we discuss how to redo the description of the results?}

One piece of evidence that the counts may not be that valuable come from the reports of benefit-cost ratios that the authors calculated in their companion paper which indicate that the value of the benefits for boys is approximately four times that of girls. \textbf{The counts are valuable as one aggregate measure to understand the treatment effects. Weighing those treatment effects by the social cost is, of course, the most policy-relevant aggregate measure to report. However, presenting the counts with reference to the cost-benefit results highlights an earlier concern of yours that the context of the outcome matters. For example, ABC/CARE reduced females' criminal activity more than that of males'. However, after weighing these avoided crimes by their social cost, the weighted effect is much larger for men than for women. This is due to the nature of the crimes differing, with men committing more violent crimes. Ask Jorge.}

\subsection*{Alternative Child Care}

The focus of the manuscript turns to the type of control. The numbers of significantly positive treatment effects for girls are mostly similar regardless of the type of control situation, but, there are more differences in the counts for boys when the control is alternative child care rather than home care. Again, however, there are exceptions in the patterns. The treatment for boys is stronger for the home care comparison group for health but stronger for the alternative care group for cognitive skills, parenting, education/employment/income. There is no substantive discussion about why these different results should occur. 

The argument about the inferiority of alternative care seems to stem mainly from the higher count of positive treatment effects for the alternative care control than the home care control. However, these counts are similar to the counts for girls under each of the control situations. So this doesn't seem to provide strong evidence of gender differences in the harms associated with alternative care. Rather it looks like there is something unique about the home care that the boys received. \textbf{Ask Jorge.}

\subsection*{Selection into Home Care and Alternative Care}

Alternative care was selected by the parents and not randomly assigned. The manuscript uses matching to address the selection issues. However, it provides very little information (none in the body of the manuscript) about how much the resulting matched samples look like the treatment sample or each other. The manuscript is drawing conclusions about the impacts of alternative care but it hasn't shown that the matched alternative care sample for boys looks like either the home care or treatment samples. \textbf{Ask Jorge.}

\subsection*{Generalizability}

The children in this analysis come from extremely disadvantaged backgrounds. The mothers had an average IQ of 84; their average age at baseline was just under 20; and fathers were absent from three-quarters of the homes. Lack of maternal relatives (potential other caregivers) entered into the selection criteria. The initial characteristics of the children should be discussed more in the body of the manuscript for readers (especially those outside the U.S.) who are not familiar with the interventions. \textbf{We added a Table 3 (pg.\ 9) with more baseline information on the subjects as suggested. This helps better characterize the disadvantage of the subjects, especially the young age of the mothers. Jorge, should we cite the Brookings paper here to help ``generalizability''?}
 
A particular concern is that with such a modest initial sample and with the gender and control condition cuts that were made to the sample, the authors are trying to generalize from some extremely small cells. This is especially true of the home care cells. If Table A.3 is a guide, the boys' home care group is not only very small (9 children) but has a relatively high income, a high proportion of fathers present, older mothers, and more siblings. This again raises concerns that the differences in the treatment effects reflect something unusual in the boys home care sample. \textbf{Ask Jorge.}
 
 \subsection*{Minor Points}
 \begin{itemize}
\item P. 17, manuscript reports that treatment increases girls' college completion by 13 percentage points, but the corresponding figures are dropped from Table 5. \textbf{This was a typo (it should have said that high school completion increased by 13 percentage points). We have corrected this (pg.\ 18).}
\item Table A.5, is ``Mother Works'' a simple dummy variable? I can't determine how you arrived at the percentages listed in the table if it is. \textbf{Most of the mothers in the sample did not work, either because they were idle or they were in school. This is why the percentages in the table are so low. Ask Jorge.}
 \end{itemize}
 
 \clearpage

% REVIEWER 4
\section*{Reviewer \#4}

\subsection*{Summary}

This paper estimates the pooled impacts of two ``model'' randomized early childhood interventions---the Carolina Abecedarian Project (ABC) and the Carolina Approach to Responsive Education (CARE)---separately by gender. Because there are so many outcomes---indeed, nearly as many outcomes as participants (126 vs. 156)---inference focuses on the proportion of positive (and separately, proportion of statistically significant) treatment effects within outcome categories (IQ, education, etc.). In addition to the basic treatment-control comparison, which is based on the randomization of access to (and participation in) the intervention, the authors present comparisons of outcomes in the treatment group to those of subsets of the control group defined by exposure to center-based care under age five, adjusting for selection on observables (only) through matching. Thus, they attempt to assess the impacts of the ``high quality'' ABC/CARE intervention relative to two counterfactuals: home care and the ``low quality'' center-based care available to the control group.

\subsection*{Comments}

Impact evaluations of early childhood programs depend on the counterfactual; in turn, the policy relevance of findings from a particular intervention depend on whether that counterfactual still stands. The fraction of children today in formal childcare or early education settings is much higher than it was in the late 1970s and early 1980s, when the ABC and CARE interventions were carried out. I therefore really like the fact that the authors are trying to understand the importance of the counterfactual to their findings. That the importance may vary by gender is also interesting, and I think novel. I also applaud the authors for producing a very readable and generally clear paper; the graphical representations of the impacts are particularly helpful. \textbf{We really appreciate the point that analyzing the counterfactual environment more closely helps relate these results to the modern context. We added a sentence with this justification to the introduction (pg.\ 3).}

However, I have three major concerns about the paper as it currently stands. I will elaborate on each of these concerns in the remainder of this report, then offer a few more minor comments.

\begin{description}
\item[Major concern 1]  Participation in center-based care in the control group is not randomized. As the paper is currently written, it seems like the treatment-control/home care and treatment-control/center care inferences are as credible as the treatment-full control group inferences. These inferences are not created equally. The treatment-full control group inference is based on randomization; sample sizes are small, but absent selective attrition, randomization should address both selection on observables and selection on unobservables. By contrast, the treatment-control/home care and treatment-control/center care comparisons only adjust for selection on observables. I think that this needs to be made very clear early on in the paper (well before page 14, where it is first mentioned in the current draft), and appropriate caveats on conclusions drawn from these inferences given throughout the text.  \textbf{Clarified this in the introduction. Ask Jorge.}

\item[Major concern 2] There is too much focus on the sign and statistical significance of effects, and too little on magnitudes. In part, this is an artifact of the statistics (and corresponding inference) that the authors have chosen to highlight:  proportions of positive effects within categories. Given that the interest is in gender differences in treatment effects, shouldn't magnitudes matter as well?  I think that there is an easy solution to this:  instead of focusing on proportions, why not focus on standardized treatment effects within categories, as in the Kling, Liebman, and Katz (2007) evaluation of MTO or the Finkelstein, et al. (2012) evaluation of the Oregon Health Insurance Experiment?  Alternatively, monetization of the effects (e.g., to calculate cost-benefit ratios) would provide an omnibus magnitude, but it looks like you've already done this in another paper. \textbf{We followed this comment by changing the presentation of the summary of results in the introduction (pg.\ 5). We used a similar approach as the cited papers to present standardized treatment effects. We agree that this is clearer than the previous presentation which relied on relative magnitude. It also helps contextualize the results reported later in the paper that still rely on relative magnitude. We have also clarified summarizing the results in this paper in relation to the companion paper on cost-benefit analysis (this clarification is done throughout but a few examples include pg.\ 4 and pg.\ 23). The very short summary is that ABC/CARE positively and significantly affected more results for women than for men. However, when weighing the treatment effects by the social cost, ABC/CARE had a higher return for men than for women. This is partially because the types of outcomes that show larger treatment effects for men than women, such as health, are very socially costly. There is another issue that there are many results that are not able to be monetized. Family outcomes such as marriage or number of children are good examples of this. It is possible that ABC/CARE positively affects females in non-market ways that are not well encapsulated in either of these papers. All of this is better explained in-text as a result of the feedback we received.}

\item[Major concern 3:]  There is inadequate reconciliation with existing literature. There is (to me) a glaring lack of reconciliation with several key papers. First, and most importantly, Anderson (2008) estimates the impacts of a number of model early interventions---including ABC---correcting for multiple inference. This paper is not even cited, despite the fact that it is well known in this literature (cited 590 times in Google Scholar at the time this report was written). The authors really must cite this paper, and describe what they do differently from it; if gender differences in ABC have already been explored, what is the contribution? Do the authors arrive at different conclusions?  If so, why? \textbf{We included this citation (pg.\ 1) and added a footnote (2) explaining why we innovate on that paper. One thing that is important to note is that Anderson (2008) was published before the age-30 and -34 data collections were available. These later data collections are really important to capture more complete life cycle outcomes, especially health, crime, and employment. These findings complicate the gender differences reported in Anderson (2008). We also included this paper in Table C.1 (pg.\ 60 of the appendix) , which summarizes previous literature in more depth. Finally, we have expanded references to previous literature more generally both in the number of citations and the description given of those findings relative to ours. Gender differences of ABC/CARE have not been the primary subject matter of previous papers.}

Second, given that gender differences in ABC have indeed previously been documented, the attempt to estimate effects relative to specific counterfactuals (home care, center-based care) becomes a more important aspect of the paper's potential contribution. With this in mind, I think that the authors must really reconcile with Kline and Walters (2016) as well as Feller et al. (2016), who do the same thing (but in different ways) in the context of the Head Start Impact Study. Are they taking a similar approach? If not, does taking the approach of, for example, Kline and Walters (2016), matter for the conclusions?  \textbf{We use matching as a baseline in order to estimate the effect of ABC/CARE relative to different counterfactuals. In Appendix E (pg. \ 130 of the appendix), we present results from an instrumental variable approach relying on potential shifters of enrollment like presence of relatives or month of birth. The results reported in the appendix are larger than the intent-to-treat estimates, but much less precise. We are more limited in instruments given the small sample and its homogeneity relative to a study like HSIS. They both find that Head Start has larger gains compared to a home environment. Neither Kline and Walters (2016) nor Feller et al. (2016) present results by gender, so we cannot compare our results exactly. However, one important note is that a lot of the control-group subjects who enrolled in other center-based care actually enrolled in other Head Start programs. Even for those who did not, the standards in the early 2000s for preschools are much higher than those in the 1970s. The difference between ABC/CARE and the alternative center-based programs should be much larger than the difference between Head Start and the alternatives that the HSIS control-group selected into. In addition to not dividing by gender, this could explain the more decisive findings. We have included reference to these papers in the introduction and a few sentences addressing this and more explicitly referencing Appendix E (pg.\ 4).}

Approach aside, the authors seem to be doing a similar dissection of counterfactual care options in their companion paper (Garcia et al. 2017). Is the innovation of the current paper simply that you're doing it by gender?  Why is this important?   \textbf{This paper is meant to detail the methodology of dissecting the counterfactual care options and documenting the treatment effects. The companion paper takes this as given and focuses on the methodology of cost-benefit analysis. That paper also presents results by gender. We have added a few sentences in the introduction to clarify this point (pg.\ 4-5).}
\end{description}

\textbf{Minor comments}
\begin{enumerate}
\item I would recommend being clearer about what is meant by early education ``quality'' in this paper. Is it simply the cost of the program or in resources (``structural quality'')?  Is it something about interactions between caregivers and children (``process quality'')? I don't think that any process quality measures are available for the ABC or CARE interventions, but discussions of quality in early intervention have evolved, and the text should reflect this. \textbf{We added more explanation about the quality of ABC/CARE and the alternatives throughout, but especially in the data section (pg.\ 8, 12). The vocabulary of process and structural quality is useful and we incorporated this citing several papers that study the relationship between different aspects of the two. You are correct that there are no measures of process quality in ABC/CARE, let alone for the control-group subjects who attended alternative care. We expanded more on the aspects of quality that we do know about to argue that the quality in ABC/CARE was high, especially compared to the other programs during that time.}
\item Figure 1 is troubling, in that it suggests that there is a lack of balance in observables across the control and treatment groups despite randomization. I think it would be helpful to see more discussion of the validity of randomized variation among non-attriters in the main text. (Relatedly, I don't think that dropouts post-randomization are not a problem, as seems to be implied in footnote 9.)  \textbf{That figure showed father's presence over time even after randomization. The pattern reflects a more widely documented trend that parents stay together more when the child is a son rather than a daughter. At randomization, the experimental groups were balanced in this variable and other variables related to disadvantage. Unfortunately, the exact randomization protocol is not documented, i.e., we do not know exactly what variables were used to match subjects and how this match occurred. To clarify the baseline characteristics, we replaced Figure 1 with Table 3. This shows the male/female and treatment/control differences at baseline. We also included more in-text explanation (pg.\ 8).}
\item Likewise, it would be helpful to see differences in observable characteristics between control children who attended and did not attend alternative childcare. \textbf{This is reported in Table A.4 (pg.\ 27 of the appendix). We expanded the explanation of it in text in order to speak to this concern (pg.\ 12). The main difference is that for control-group girls, working mothers always place them in alternative care. For control-group boys, working mothers do not always do this, most likely related to the fact that more fathers are present for boys than for girls.}
\item Presenting estimates by gender and family background, as is done in section 5, doesn't seem advisable given the very small sample sizes. \textbf{Although the sample size is very small, we think that it offers some suggestions about moderating effects of family background. We have qualified the discussion of those results to be more suggestive (pg.\ 28-29). }
\item Needing clarification:
\begin{enumerate}
		\item 1st full para., p. 2:  what do ``differentially promotes'' and ``differentially enhances'' mean exactly?  The language seems to imply that both sexes are positively affected by the intervention on all dimensions stated, but this does not appear to be the case (particularly with the step-down p-values) in Tables 4 and 5. \textbf{We changed the entire introduction so that the results are more clearly summarized.}
		\item Last full paragraph, p. 3:  if ``all achievement measures favor males in the control group,'' why isn't the proportion favoring males in the control group 1.0 in Table 1? \textbf{We completely redid the results shown in the introduction. The control-group males do very well in the achievement tests relative to the control-group females. This is not the case for the treatment group in which the females do much better than their male counterparts. This is consistent with the new presentation of results in Table 1, which shows the standardized treatment effects averaged over the outcome category.}
		\item P. 6:  It is not clear how the home visitation component can be safely ignored. Was there additional randomization of home visitation within the initial treatment group? \textbf{In ABC, the home visiting that occurred between 5 and 8 was randomized separately. No effect was found. In CARE, this 5-8 component was not randomized with all subjects who received center-based care also receiving this school-age component. We extrapolate that the findings from ABC extend to CARE as minimal changes were made to the school-age intervention. In sum, randomization of this component in ABC allows us to rule out that the age 5-8 intervention has an effect. We expanded the in-text reference related to this issue (pg.\ 6).}
		\item P. 9:  ``Dropouts are evenly balanced across treatments and controls?''  In terms of numbers or observable characteristics? \textbf{They are evenly balanced in terms of numbers. We clarify this in-text (pg.\ 10). We find that the estimates are robust to correcting for this attrition, as reported in the appendix (pg.\ 50 of the appendix).}
		\item P. 16:  how exactly does column (2) adjust for ``the differences in attrition''? \textbf{We adjust for attrition using IPW. This is documented in the appendix (pg.\ 50 of the appendix). We added clarification in the main text (pg.\ 17).}
		\item Continuing paragraph, top of p. 17:  college graduation estimates are referenced but not given in the table. \textbf{This was a typo (it should have said that high school graduation increases). This has been corrected.}
		\item I would be clear in the discussion on pp. 16-17 that you are using the bootstrapped p-values, not the step-down p-values. \textbf{We have added this clarification.} 
		\item Pp. 21-22:  How is it that the benefit/cost ratio of ABC/CARE is so much larger for males than for females? This seems contradictory to the following statement that ``females benefit more from the program than males.''  Is that not all outcomes are created equal (in terms of social value)?  This gets back to my comments about the importance of magnitudes. \textbf{We provide more detail in response to this above, but the outcomes for which men are more affected are costlier to society. We have clarified this throughout the paper (e.g., pg.\ 23) and added additional sentences to the introduction to address this concern (pg.\ 4).}
		\item P. 26:  Another seeming contradiction: estimated treatment effects do not ``appear similar across genders comparing treatment to staying at home full time''; at least it doesn't appear that way in Figures 3 and 4. \textbf{To be discussed with Jorge.}
\end{enumerate}
\end{enumerate}

\end{document}
