\documentclass[12pt]{article}

\usepackage{booktabs}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{threeparttable}

\newcommand{\mr}{\multirow}
\newcommand{\mc}{\multicolumn}

%\linespread{2}

\begin{document}

\doublespacing

\title{Collated Referee Reports}
\maketitle

% REVIEWER 2
\section*{Reviewer \#2}

This is an interesting paper with potentially important findings regarding the longer-term effects of an innovative early childhood intervention. While based on a relatively small sample, randomized treatment assignment (program entry) permits credible causal inference regarding the program’s effectiveness. While the paper makes a valuable contribution to the literature, the paper has some shortcomings and I see significant scope for further improvements.
\begin{enumerate}
\item The findings in the paper apply to the population of eligible households who signed up to participate in the experiment. Are there systematic differences between eligible households who signed up and did not sign up? It would be useful to give the reader a sense of whether the participating households are representative of the eligible population. \textbf{This is an important point that unfortunately lacks formal documentation. However, after speaking with some of the researchers who implemented the program, they relayed the following: All providers of health care and social services (referral agencies) in the area of the ABC/CARE study were informed of the programs. They referred mothers whom they considered disadvantaged. Eligibility was corroborated before randomization by the researchers. Our conversations with the program staff indicate that the encouragement from the referral agencies was such that most referred mothers attended and agreed to participate in the initial randomization. We included this information in-text in the data section to clarify this point (pg.\ 9). As we highlight on pg.\ 10, none of the eligible families dropped out before randomization.}


\item Strictly speaking, only the pooled control-treatment outcome comparisons exploit the randomized treatment assignment. Assuming no other selection issues related to nonrandom dropout, I consider those estimates to be the most credible. \textbf{This is a distinction that was not highlighted enough in the submitted draft. We have clarified language throughout distinguishing between the approaches and have added more explanation of the differences in assumptions needed for the evaluation in relation to the counterfactual scenarios (an example is pg.\ 3-4). We also have added clarification of the results presented that account for attrition using IPW (pg.\ 18). The full discussion of the IPW approach that we take is on pg.\ 50 of the appendix. } 

Several other main findings in this study instead rely on strong conditional independence assumptions for identification. They involve a comparison of treatment group outcomes with outcomes for two different control groups: those where the child stayed at home and those where the child entered a lower-quality childcare center. For example, among the major findings is that ``Low-quality childcare arrangements are detrimental for boys'' and ``Home care is beneficial for boys compared to low- quality center childcare''. While not always clearly discussed in the paper, these conclusions are presumably based on taking the difference between columns 6 and 4 in Table 4, representing treatment effects that control for differences in observed characteristics. \textbf{We added explanation on the top of pg.\ 19 to clarify the computation behind these statements. We also deleted or qualified statements like the ones you highlighted throughout to remind the reader that those comparisons rest on stronger assumptions than the LATE-like estimates. Examples of this include pg.\ 15, 18.}

An obvious challenge to establishing these causal effects is that the childcare choice among control group members is endogenous. As the authors acknowledge (for example on page 11), those who opt for alternative care are less economically disadvantaged at baseline compared to children who stay at home. So the reliability of these findings in the paper depends on the extent to which the adjusted differences in outcomes reflect selection on unobservables. One would imagine, for example, that parent(s) of more difficult or demanding boys may be more inclined to send them to childcare instead of keeping them at home. So boys in childcare may differ systematically from boys staying at home. How confident can we be that the included controls adequately control for selection into childcare? How do mothers and households who keep boys at home compare to those who choose childcare, and how does this compare for girls? There is no discussion in the paper of any potential role of selection on unobservables. \textbf{We have expanded our description of the observed characteristics of the control-group children who selected into different childcare arrangements (pg.\ 10-12). We recognize that we may not fully account for potentially endogenous unobservables and now explicitly stated that in the paper (pg.\ 18). We do have alternative approaches in the appendix, including an instrumental variable approach and control functions (pg.\ 129 of the appendix). These, in theory, should account for unobservables more completely than our main analysis and yield similar results to what we present in the paper. However, the instruments are weak in the small and homogenous sample, making it less credible. We have clarified that we try these approaches in-text (pg.\ 16). We discuss the instrumental variables that we use in more detail in the response to your next comment.}


\item Related to the previous point, it is unclear whether one could attribute a difference in outcomes solely to a child attending a lower-quality childcare center. Presumably the ``treatment'' also involves changes in other inputs as the decision to send a child to childcare involves monetary costs (while ABC/CARE and home care presumably are free), and may coincide with increased maternal employment. So what is estimated here is the effect of using lower-quality childcare center combined with changes in parental income and time inputs into child development, which could be compensatory or complimentary. Are the negative effects for boys due to lower quality childcare, or do they capture income effects?
 \textbf{Yes it is true that ABC/CARE is free for the families (we clarify this now on pg.\  6). Unfortunately, we do not have the breadth of data and sample to be able to disentangle income effects from direct effects of the program. It is true, as we show in Table A.4 (pg.\ 27 of the appendix), that the mothers of the control-group girls who stay at home do not work whereas 14\% of the control-group boys who stay at home have a mother who works. This is consistent with the fact that more boys than girls have a father present, both in the data and as a documented pattern (e.g., Dahl and Moretti, 2008). This could be one mechanism through which the decision is made and could have implications for quality of home care. Unfortunately, even for the cases in which the father is present, we have no measures on the specific quality of the home care. Even the concept that we have on the quality of the alternative center-based care come from auxiliary historical documents (e.g., state and federal standards), rather than self-report or direct observation. We added this in-text (pg.\ 12).}
 
 Does the choice perhaps reflect the absence of good alternative informal childcare by the parent(s), grandparents and friends, relative to those who opt for home care? 
 \textbf{We attempted to use the presence of relatives as an instrument for selection into alternative center-based care. This is in Appendix E.1 (pg.\ 129 of the appendix). There was an extensive neighborhood survey done when the ABC subjects (not CARE, unfortunately) were entering kindergarten. This included a more expansive enumeration of family in the area and allowed us to isolate which subjects had a grandparent in the area. In addition to this measure, we also used the survey information (available in ABC and CARE) on people who lived in the household to try to capture opportunity for home care. Using different combinations of these weaker instruments and a more plausibly exogenous one (being born in the fall, which would allow for easy enrollment into center-based care if following the academic year). We present various specifications in the appendix. The IV results are pretty comparable to the main results but larger in magnitude and less precise. We added this information to footnote 8 (pg.\ 4).}

What exactly counts as ``home care''? Does it include informal childcare arrangements? These issues deserve more discussion in the paper. \textbf{Researchers administered a survey to the control-group parents asking about childcare arrangements made during each month between birth and age 5. If the answer was either staying at home or in the care of a relative, neighbor, or friend, then that is coded as home care. If the answer involved some center-based program, then the respondent also provided the name, which further confirms that the care option was indeed center-based. We have added this clarification to the data section (pg.\ 10).}

 Do you have access to data on the time mothers spent with their children, and on time spent with other family, friends and siblings? \textbf{Unfortunately, we cannot study the differences in time use due to lack of data. There are no time diaries available. We note this in-text (footnote 15 on pg.\ 13).}
 
 Perhaps more importantly, is there any evidence on gender differences in what constitutes ``staying at home'' or ``lower-quality childcare''? \textbf{We are not able to precisely compare the quality of the center-based alternatives at the individual level and our knowledge of the quality of the home care is not precisely known. The main difference that we can measure is the larger amount of fathers present for the control-group boys who stay at home (pg.\ 12).}

\item Related to the previous comment, there is little discussion in the paper of the effect of the intervention on parental income. As the estimated effects look very large, they should be discussed in more detail. Does labor income include zero income values for those with non- working parents? \textbf{Yes, parental labor income is 0 for non-working parents. We clarify this in-text (footnote 30 on pg.\ 19).} 

Presumably the large effect then captures changes in maternal employment, thus explaining why the parental income effects are so much bigger relative to the alternative of the child staying at home as compared to alternative center childcare. So one of the channels through which ABC/CARE affects child outcomes is through allowing increased maternal employment? How does this relate to estimated effects of maternal employment uncovered in the literature? \textbf{In response to this comment, we added a paragraph to Section 4 explaining the treatment effects on parental income (pg.\ 19, 22). In that explanation, we reference the appendix, which has effects on maternal employment. Although the effects on parental income still show up when comparing to the group that received alternative care, the effects on maternal employment are only present compared to the group that stayed at home. We also added references to other studies in footnote 31 (pg.\ 22). Although there are a few finding that subsidized child care does not increase maternal labor supply (e.g., Havnes and Mogstad, 2011), there are several that find a positive causal effect of increasing access to child care on maternal labor supply (Bauernschuster and Schlotter, 2015; Bettendorf et al., 2015; Geyer et al., 2015; Brilli et al., 2016). Brilli et al., (2016) is particularly consistent with our results given that they find an increased effect in provinces with less availability of alternative programs. This information is in footnote 31.}

\item Similar to the treatment of childcare choice among control group members, in your analysis you treat the presence of the father as exogenous, while it seems more like an endogenous outcome to me. \textbf{We previously had a figure showing the presence of the father by experimental group and gender over time. We have replaced this with Table 3 on pg.\ 9 to more formally compare the baseline differences. That table highlights that father's presence is balanced at baseline. Although, as you say, it is definitely possible that randomization into the program can affect father's presence, we always use father's presence at baseline in the analysis. We now clarify this on pg.\ 29.}

\item Nonrandom attrition. On page 9 you discuss that dropout is related to the health of the child and to mobility of families. Both seem highly related to potential outcomes, so this seems to generate a classic case of attrition-induced selection bias. How can we be confident that controlling for observables is sufficient? The estimates in Tables 4 and 5 clearly show that adjusting for covariates has meaningful impacts on treatment effect estimates, but they may still reflect differences in unobservables. Dropping 22 subjects out of a total sample of 121 is obviously not trivial, so it seems to me that the reliability of your approach for controlling for nonrandom attrition deserves more discussion in the main body of the paper. \textbf{This is a crucial point to clarify. We provide details for each of these individuals in Table A3. We argue that most cases of non-compliance were exogenous to the program implementers or to household choices and we elaborate on how we deal with them.}

\textbf{1. Four individuals in the treatment group did not complete the treatment. They left 3, 10, 6, and 9 months after the treatment began. We treat the as though they have had treatment (because they did, at least for a few months). In later life follow ups, we fully observe outcomes for this children and include them in our computations. This would only bias our results downwards, as this children did not complete treatment. In terms of information loss for estimating treatment effects, that is not an issue for these four children.}

\textbf{2. Four individuals died: two of them in the treatment group and two of them in the control group. Given the causes of death (heart disease for two of them, SIDS for one of them, and a pedestrian accident for one of them), we interpret this as missing at random. This would be information lost at random.}

\textbf{3. Four children in the treatment group "disappeared." There is no data on them, and it is difficult to make a methodological decision with respect to them. We have no data on them and have no other choice than to assume that they are missing at random.}

\textbf{4. Three children crossed from the control to the treatment group. This crossover was suggested and enforced by the local authorities, and did not occur by household choice or by design. We decide to drop that child from our sample of analysis. This dropping could be interpreted as exogenous because was a consequence of an action of a third party (neither the household nor the program designers were responsible for this).}

\textbf{5. One children in the control group and two children dropped from the sample, in a standard attrition fashion, which we address as documented in the paper. We observe baseline data and data before age 8 for this children (i.e., they attrited but data collection for them continued).}

\textbf{6. Two children in the treatment group were diagnosed as developmentally delayed 6 and 36 moths after the treatment began. This disqualified for treatment: Children were not supposed to be developmentally delayed. This is not a concern per se. The concern would be that analogous control-group children could not be detected (because usually there is less contact of program officers with control-group children). Given the complementary features offered to the control group and the frequent data collection, implementation staff kept a close relationship with the control-group children, which lessens that concern.}

\item Most of the analysis in the paper focuses on the direction rather than the magnitude of treatment effects, and all outcomes are treated as equally important. While I understand your motivation for doing so, clearly some outcomes matter more than others. In my view it would be useful to add a brief discussion of weighting, or relative importance of these outcomes in your benefit (rates of return) analysis. \textbf{We changed the introduction to focus on standardized treatment effects, which allow for some sense of magnitude to give context to the other results (Table 1, pg.\ 5). The individual results described in Section 4.1 also focus on magnitude and we have expanded this section in the updated paper. Tables 4 and 5 (pg.\ 20-21) present a short list of outcomes that are more socially relevant (i.e., no measures) and are key inputs of the cost-benefit analysis. We have added reference to the rate of return analysis in this section (pg.\ 18) to better connect the results. We have also added more references to the cost-benefit results throughout (e.g., pg.\ 5).}

Furthermore, it appears from Tables 4 and 5 that the magnitudes of several estimated effects are very large (almost unrealistically so?), which at a minimum deserves more discussion in the paper. \textbf{We added explanation of these very large effects to address this comment (pg.\ 18-19, 22-23). Part of the explanation of the large effects relies on citing other papers that find similar results or comparing with related treatment effects to show consistency.} 

Relatedly, the results in Tables 4 and 5 are limited to average effects, while it may be useful to focus on extreme negative (and perhaps positive) outcomes. \textbf{This is most effectively done in the cost-benefit analysis given that the costs are calculated on an individual level. For example, the cost of each committed crime is summed to compute the reduced burden of crime as a result of ABC/CARE. Extreme values, such as those who commit no crimes or those who commit very serious crimes, will be accounted for in this aggregate. We added discussion of this point in the paper (pg.\ 22).}

\item It was not clear from the paper whether the authors investigated whether treatment effects vary with the presence of a grandparent or sibling, an analysis which could provide additional insights. \textbf{Thin support and incomplete data makes this analysis difficult to accomplish in a credible manner. The family structures of the subjects were complex resulting in household and family data that varies substantially between data collection points. Investigating treatment effects by the presence of the father (pg.\ 67 of the appendix) is possible given that this is captured with less measurement error. We clarify this in a footnote 36 on pg.\ 31. We do use the presence of some relatives as an instrument for selection into preschool (pg.\ 129 of the appendix), although this is a crude measurement that is only possible to use as an instrument when interacting it with more plausibly exogenous instruments, like being born in the fall.}

\end{enumerate}

\textbf{Additional comments}
\begin{enumerate}
\item Page 1. It would be useful to add a sentence briefly summarizing earlier findings about differential gender benefits of early-life interventions (among studies that report these). \textbf{We added a sentence summarizing these differences to the third paragraph in the introduction (pg.\ 1).}
\item Page 2. Please clarify here that what is meant with ``high-quality childcare'' is childcare provided by the ABC/CARE program, and ``low quality childcare'' is any alternative childcare arrangement used by control group members. It seems more appropriate to call these ``lower-quality childcare'' - can one really say these were low-quality? \textbf{We added more explanation in the introduction about the quality of ABC/CARE and the alternative options. We changed ``low-quality'' to ``lower-quality'' throughout the paper to capture that there was heterogeneity in the quality of the alternative preschool. However, the documentation that we provide in the appendix supports that even the alternative centers that had educative components, rather than being essentially child supervision, were of lower quality than what was offered in ABC/CARE (pg.\ 29 of the appendix). We also added a more detailed discussion on the quality of ABC/CARE (pg.\ 8) and the alternative options (pg.\ 9, 12).}
\item Page 2. The statement ``staying at home is a better option for them [boys], especially if the family environment is relatively advantaged (e.g. the father is present)'' appears at odds with the findings reported later in the paper. I presume you meant when the father is absent? \textbf{We removed this example because it is an oversimplification and confusing, as you pointed out.}
\item Page 3. How do the findings of the earlier studies listed in footnote 8 compare to those in this paper? \textbf{We edited this footnote (now footnote 5 on pg.\ 2) to include some sentences on those findings relative to ours. The only paper of those listed that divide by gender is Campbell et al. (2014), which focuses on health results. Our findings are consistent with theirs.}
\item Page 4. The use of a 10\% significance level is unconventional in empirical economic research. Given the small size of your sample it may be reasonable, and perhaps is a convention in analyses based on combining functions, but in my view deserves a brief explanation. \textbf{We added footnote 28 on pg.\ 19 to clarify this in the paper. We also changed the presentation of the results in the introduction such that the $p$-values are printed directly.}
\item Page 15. Explain what is meant with ``accounts for model pretesting''. Does this include the formation of the outcome ``blocks''? \textbf{We expanded the information on accounting for model pretesting (pg.\ 17). Accounting for model pretesting involves selecting the model with the most predictive control set. This is detailed in Appendix D.1 (pg.\ 71 of the appendix.}
\item Page 15. Does the test based on the 10\% significance level of treatment effects on outcomes assume independence across outcomes within and across blocks? \textbf{The combining functions do not restrict the within- or between-outcomes correlation structure. To see this, note the following. In order to compute the point estimate, we simply categorize the variables and ask what proportion are either positive or positive and significant (depending of the statistic of interest). For inference, we bootstrap our procedure. For a bootstrap sample b, we sample with replacement our entire sample, re-categorize, and compute the statistics again. The standard error of our statistic is the standard deviation of the resulting empirical bootstrap distribution. Thus, our inference procedure does not restrict the within- or between-outcomes correlation structure.}
\item Page 17. You list a finding of increased college graduation for females, but in table 5 this result is missing and you state that you could not estimate the treatment effect for that outcome for women. \textbf{This was a typo. It should have read that it increased high school graduation. We corrected it (pg.\ 18). }
\item Page 20. ``Male results are stronger than female results''. Here and elsewhere in the paper the use of ``results'' is often confusing – do you mean outcomes or treatment effects? \textbf{We clarified this here (outcomes, pg.\ 23) and used more precise language throughout related to this concern.}
\item Pages 20-22. The statement on page 20 that benefits from ABC/CARE are largely driven by its effects on males' seem inconsistent with the statement on page 22 that ``females benefit more from the program than do males''. Is this apparent contradiction due to the difference between direction and magnitude of treatment effects? \textbf{This is a confusion between the dominance of females in the treatment effects versus the dominance of males in the cost/benefit analysis. That is, the treatment effects that are higher for males result in a higher monetary return on the investment. However, females have higher treatment effects in more outcomes (including some outcomes that cannot be monetized). We clarified this distinction throughout the paper in addition to the sentences you highlighted (pg.\ 22).}
\item Page 22. It appears that the results for the ``proportions equal 10\%'' test based on the pooled control group are missing in the paper? \textbf{This is Figure 2b, but it was confusing how it was referenced before. We have corrected this so that it is clear (pg.\ 25).}
\end{enumerate}

\clearpage

% REVIEWER 3
\section*{Reviewer \#3}

This manuscript considers how a host of treatment outcomes differ between disadvantaged boys and girls who were subjects of two high-quality, random-assignment child care interventions. The manuscript finds that the number of significant socially beneficial treatment effects was higher for girls than boys and that the gender differences principally stem from a smaller number of significant treatment effects for boys when the relevant comparison is home care. The manuscript makes a methodological contribution through its use and statistical analysis of combining functions to count and statistically compare the numbers of significant socially beneficial treatment effects. As a methodological exercise, the manuscript is impressive. However, although the manuscript applies these methods to an important child care experiment, its substantive contribution is less clear. 

First, comparisons of the counts of significant effects may not be especially valuable in this context. There is little consideration of the magnitudes of effects.  \textbf{We changed the summary of results in the introduction in order to highlight the magnitude of the treatment effects rather than the direction/significance. Table 1 now shows standardized treatment effects by gender. These results are consistent with and complement the other analysis that focuses more on direction/significance or relative magnitude (comparing male results to female results). In Section 4.1, we also discuss the magnitude of individual outcomes. We reference the companion cost-benefit analysis more clearly throughout the paper, which focuses more on the magnitudes given that it weighs them by their associated social cost.} 

Also, many of the outcomes are highly-gendered adult behaviors, such as employment and arrests, where we might not have expectations of comparable effects. Even if child care had similar effects on boys' and girls' early cognitive, emotional and behavioral outcomes, these might not translate into comparable adult outcomes. \textbf{This is a very important point. We argue that comparing the standardized treatment effects newly presented in Table 1 addresses this (pg.\ 5). This comparison nets out the control groups of each gender, thereby comparing the marginal effect on treatment relative to the baseline by gender. This type of analysis is also done in Table 6 (pg.\ 24).}

Second, the manuscript does not offer theories or explanations of how effects might have occurred in different domains; it focuses instead on the summary measures. \textbf{We expanded the summary of results in Section 4.1 (pg.\ 18), which focuses exclusively on individual treatment effects for a selection of important outcomes. The updated section includes more analysis of the different domains and only mentions the summary measures to relate the observed individual treatment effects to aggregate measures. In response to this comment, these individual effects are more completely discussed.}

The main area where it does dig deeper---gender differences in the benefits of the child care intervention relative to either home care or alternative care---doesn't lead to a convincing result, because the manuscript doesn't establish the comparability or representativeness of the comparison groups. The manuscript makes numerous statements about the inferiority of alternative child care for boys, but it hasn't made a strong case. \textbf{We expanded the explanations of the control group (pg.\ 10), referencing more explicitly Table A.7 (pg.\ 26 in the appendix), which describes the baseline characteristics of the control-group children by selection into alternative care setting. We also explained in more detail the process of recruiting and randomizing the subjects (pg.\ 9-12). This helps establish that the sample reflected the children from disadvantaged families in the Chapel Hill area. Finally, the selection into home care or alternative center-based care is not randomized, as you mention. We included more explanation in the paper explicitly saying this and better explaining the assumptions of the methods we use to account for this selection (e.g., pg.\ 3,15). We aim for this expanded explanation to further support the analysis of results comparing ABC/CARE to alternative care settings by gender.}

\subsection*{Gender Differences}

The manuscript convincingly documents that there are many differences in outcomes from high-quality child care between boys and girls. The text documents treatment effects for many adult outcomes and shows that women have better treatment outcomes for education and employment, while men have better treatment outcomes for drug use, blood pressure, and hypertension. Some of the gender differences in health outcomes had previously been reported by Campbell et al. (2014) and other outcomes have been reported before.

The manuscript glosses over differences in the patterns of results. For example, it summarizes the results in Table 6 by writing, ``The general pattern is that male results are stronger than female results in the control group. The pattern is generally reversed in the treatment group.'' Well, yes, but it's still the case that men's treatment effects were better than women's treatment effects for many outcomes (age 5 IQ, college graduation, labor income, and all four health measures) and indistinguishable for a few others. The manuscript formalizes this approach with its combining functions and statistically confirms that there are more significant positive treatment effects for girls than boys. However, these analyses continue to show that there are many positive treatment effects for boys. \textbf{There are indeed many positive treatment effects for boys. Statements like the one you highlighted have been deleted or modified to be more nuanced (e.g., pg.\ 32-34). We have also expanded references to the companion cost-benefit analysis, in which the weighted treatment effects reveal that the social returns for males are higher than those for females (e.g., pg.\ 5).}

The manuscript finds differences across many domains. But it's not clear that this is helpful. For example, how do we compare that girls had significantly better home scores at age 1.5 while boys didn't but boys had better labor incomes at 30 while girls didn't. The analysis seems worthwhile within domains of closely related measures but not across domains. More discussion and analysis of Figure 4 (and similar comparisons) would be a better way to go. \textbf{We edited the description of results to focus more on relating treatment effects on closely related outcomes (e.g., pg.\ 22). In response to this comment, we have also expanded and clarified the analysis of the combining functions (pg.\ 26).}

One piece of evidence that the counts may not be that valuable come from the reports of benefit-cost ratios that the authors calculated in their companion paper which indicate that the value of the benefits for boys is approximately four times that of girls. \textbf{The counts are valuable as one aggregate measure to understand the treatment effects. Weighing those treatment effects by the social cost is, of course, the most policy-relevant aggregate measure to report. However, presenting the counts with reference to the cost-benefit results highlights an earlier concern of yours that the context of the outcome matters. For example, ABC/CARE reduced females' criminal activity more than that of males'. However, after weighing these avoided crimes by their social cost, the weighted effect is much larger for men than for women. This is due to the nature of the crimes differing, with men committing more violent crimes. We have expanded reference to the companion paper throughout the manuscript (e.g., pg.\ 5, 22).}

\subsection*{Alternative Child Care}

The focus of the manuscript turns to the type of control. The numbers of significantly positive treatment effects for girls are mostly similar regardless of the type of control situation, but, there are more differences in the counts for boys when the control is alternative child care rather than home care. Again, however, there are exceptions in the patterns. The treatment for boys is stronger for the home care comparison group for health but stronger for the alternative care group for cognitive skills, parenting, education/employment/income. There is no substantive discussion about why these different results should occur. \textbf{We have expanded the discussion of results to better relate the treatment effects to one another (pg.\ 19, 22). For example, women have large gains in employment, income, and education relative to those in the control group who stayed at home. The relationship between these three variables is clear and thus the results make substantive sense. Another example is that we now better explain the results on parental income, which are substantial. The more nuanced description of results helps clarify these points even though we cannot present formal tests of mechanisms explaining the different treatment effects.}

The argument about the inferiority of alternative care seems to stem mainly from the higher count of positive treatment effects for the alternative care control than the home care control. However, these counts are similar to the counts for girls under each of the control situations. So this doesn't seem to provide strong evidence of gender differences in the harms associated with alternative care. Rather it looks like there is something unique about the home care that the boys received. \textbf{This is an insightful point that there could be a substantive difference in the care that boys received outside of ABC/CARE. It is even possible that the gender differences in the treatment effects of ABC/CARE come from a different experience by gender of the treatment itself. Unfortunately, this particular point is outside the scope of our data and analysis and cannot be confirmed empirically. We also lack documentation hinting at either of these phenomena. We partially addressed this comment in the paper by expanding the description of the quality of ABC/CARE (pg.\ 8) and the alternatives (pg.\ 9-12). This helps support the distinction in quality apart from the ex post treatment effects. We also added the qualification that you mention (pg.\ 30) to present a potential explanation for the observed effects.}

\subsection*{Selection into Home Care and Alternative Care}

Alternative care was selected by the parents and not randomly assigned. The manuscript uses matching to address the selection issues. However, it provides very little information (none in the body of the manuscript) about how much the resulting matched samples look like the treatment sample or each other. The manuscript is drawing conclusions about the impacts of alternative care but it hasn't shown that the matched alternative care sample for boys looks like either the home care or treatment samples. \textbf{This is an important point and we have added Table D.4 to Appendix D to show the balance between the groups after matching.}

\singlespacing
\begin{table}[htbp!]
\begin{threeparttable}
\caption{Testing Matched Samples} \label{tab:testing-matched-samples}
\input{../../output/matching-baseline-test-pstest}
\begin{tablenotes}
\item \footnotesize \raggedright Note: This table tests the difference between the matched samples for both sets of matches that are done: treatment to alternative childcare and treatment to staying at home. The \% Bias is the standardized mean difference between the matched samples. The corresponding $t$-scores and $p$-values are also reported.
\end{tablenotes}
\end{threeparttable}
\end{table}
\doublespacing

\subsection*{Generalizability}

The children in this analysis come from extremely disadvantaged backgrounds. The mothers had an average IQ of 84; their average age at baseline was just under 20; and fathers were absent from three-quarters of the homes. Lack of maternal relatives (potential other caregivers) entered into the selection criteria. The initial characteristics of the children should be discussed more in the body of the manuscript for readers (especially those outside the U.S.) who are not familiar with the interventions. \textbf{We added a Table 3 (pg.\ 9) with more baseline information on the subjects as suggested. This helps better characterize the disadvantage of the subjects, especially the young age of the mothers. To discuss the representativeness of the sample of the larger US population, we calculate that 43\% of all African American children would be eligible now and that 19\% were eligible during the intervention. We include this in-text (pg.\ 6).}
 
A particular concern is that with such a modest initial sample and with the gender and control condition cuts that were made to the sample, the authors are trying to generalize from some extremely small cells. This is especially true of the home care cells. If Table A.3 is a guide, the boys' home care group is not only very small (9 children) but has a relatively high income, a high proportion of fathers present, older mothers, and more siblings. This again raises concerns that the differences in the treatment effects reflect something unusual in the boys home care sample. \textbf{The cells indeed get small after making the cuts used for our analysis. We have added footnote 13 (pg.\ 10) to highlight this issue.}
 
 \subsection*{Minor Points}
 \begin{itemize}
\item P. 17, manuscript reports that treatment increases girls' college completion by 13 percentage points, but the corresponding figures are dropped from Table 5. \textbf{This was a typo (it should have said that high school completion increased by 13 percentage points). We have corrected this.}
\item Table A.5, is ``Mother Works'' a simple dummy variable? I can't determine how you arrived at the percentages listed in the table if it is. \textbf{Yes, it is a dummy variable. Most of the mothers in the sample did not work, either because they were idle or they were in school. This is why the percentages in the table are so low.}
 \end{itemize}
 
 \clearpage

% REVIEWER 4
\section*{Reviewer \#4}

\subsection*{Summary}

This paper estimates the pooled impacts of two ``model'' randomized early childhood interventions---the Carolina Abecedarian Project (ABC) and the Carolina Approach to Responsive Education (CARE)---separately by gender. Because there are so many outcomes---indeed, nearly as many outcomes as participants (126 vs. 156)---inference focuses on the proportion of positive (and separately, proportion of statistically significant) treatment effects within outcome categories (IQ, education, etc.). In addition to the basic treatment-control comparison, which is based on the randomization of access to (and participation in) the intervention, the authors present comparisons of outcomes in the treatment group to those of subsets of the control group defined by exposure to center-based care under age five, adjusting for selection on observables (only) through matching. Thus, they attempt to assess the impacts of the ``high quality'' ABC/CARE intervention relative to two counterfactuals: home care and the ``low quality'' center-based care available to the control group.

\subsection*{Comments}

Impact evaluations of early childhood programs depend on the counterfactual; in turn, the policy relevance of findings from a particular intervention depend on whether that counterfactual still stands. The fraction of children today in formal childcare or early education settings is much higher than it was in the late 1970s and early 1980s, when the ABC and CARE interventions were carried out. I therefore really like the fact that the authors are trying to understand the importance of the counterfactual to their findings. That the importance may vary by gender is also interesting, and I think novel. I also applaud the authors for producing a very readable and generally clear paper; the graphical representations of the impacts are particularly helpful. \textbf{We really appreciate the point that analyzing the alternative childcare environment more closely helps relate these results to the modern context. We added a sentence with this justification to the introduction (pg.\ 3).}

However, I have three major concerns about the paper as it currently stands. I will elaborate on each of these concerns in the remainder of this report, then offer a few more minor comments.

\begin{description}
\item[Major concern 1]  Participation in center-based care in the control group is not randomized. As the paper is currently written, it seems like the treatment-control/home care and treatment-control/center care inferences are as credible as the treatment-full control group inferences. These inferences are not created equally. The treatment-full control group inference is based on randomization; sample sizes are small, but absent selective attrition, randomization should address both selection on observables and selection on unobservables. By contrast, the treatment-control/home care and treatment-control/center care comparisons only adjust for selection on observables. I think that this needs to be made very clear early on in the paper (well before page 14, where it is first mentioned in the current draft), and appropriate caveats on conclusions drawn from these inferences given throughout the text.  \textbf{We have expanded upon this point in the paper to ensure that the differences in the approaches are explicitly stated. We now first mention this distinction on pg.\ 3. We also have adjusted the language describing the results (especially in Section 4.1) so that the assumptions are more clearly stated. This provides more qualifications to the results to address this concern.}

\item[Major concern 2] There is too much focus on the sign and statistical significance of effects, and too little on magnitudes. In part, this is an artifact of the statistics (and corresponding inference) that the authors have chosen to highlight:  proportions of positive effects within categories. Given that the interest is in gender differences in treatment effects, shouldn't magnitudes matter as well?  I think that there is an easy solution to this:  instead of focusing on proportions, why not focus on standardized treatment effects within categories, as in the Kling, Liebman, and Katz (2007) evaluation of MTO or the Finkelstein, et al. (2012) evaluation of the Oregon Health Insurance Experiment?  Alternatively, monetization of the effects (e.g., to calculate cost-benefit ratios) would provide an omnibus magnitude, but it looks like you've already done this in another paper. \textbf{We followed this comment by changing the presentation of the summary of results in the introduction (pg.\ 5). We used a similar approach as the cited papers to present standardized treatment effects. We agree that this is clearer than the previous presentation which relied on relative magnitude. It also helps contextualize the results reported later in the paper that still rely on relative magnitude. We have also clarified summarizing the results in this paper in relation to the companion paper on cost-benefit analysis (this clarification is done throughout but a few examples include pg.\ 4 and pg.\ 23). The very short summary is that ABC/CARE positively and significantly affected more results for women than for men. However, when weighing the treatment effects by the social cost, ABC/CARE had a higher return for men than for women. This is partially because the types of outcomes that show larger treatment effects for men than women, such as health, are very socially costly. There is another issue that there are many results that are not able to be monetized. Family outcomes such as marriage or number of children are good examples of this. It is possible that ABC/CARE positively affects females in non-market ways that are not well encapsulated in either of these papers. All of this is better explained in-text as a result of the feedback we received.}

\item[Major concern 3:]  There is inadequate reconciliation with existing literature. There is (to me) a glaring lack of reconciliation with several key papers. First, and most importantly, Anderson (2008) estimates the impacts of a number of model early interventions---including ABC---correcting for multiple inference. This paper is not even cited, despite the fact that it is well known in this literature (cited 590 times in Google Scholar at the time this report was written). The authors really must cite this paper, and describe what they do differently from it; if gender differences in ABC have already been explored, what is the contribution? Do the authors arrive at different conclusions?  If so, why? \textbf{We included this citation (pg.\ 1) and added a footnote (2) explaining why we innovate on that paper. One thing that is important to note is that Anderson (2008) was published before the age-30 and -34 data collections were available. These later data collections are really important to capture more complete life cycle outcomes, especially health, crime, and employment. These findings complicate the gender differences reported in Anderson (2008). We also included this paper in Table C.1 (pg.\ 60 of the appendix) , which summarizes previous literature in more depth. Finally, we have expanded references to previous literature more generally both in the number of citations and the description given of those findings relative to ours. Gender differences of ABC/CARE have not been the primary subject matter of previous papers.}

Second, given that gender differences in ABC have indeed previously been documented, the attempt to estimate effects relative to specific counterfactuals (home care, center-based care) becomes a more important aspect of the paper's potential contribution. With this in mind, I think that the authors must really reconcile with Kline and Walters (2016) as well as Feller et al. (2016), who do the same thing (but in different ways) in the context of the Head Start Impact Study. Are they taking a similar approach? If not, does taking the approach of, for example, Kline and Walters (2016), matter for the conclusions?  \textbf{We use matching as a baseline in order to estimate the effect of ABC/CARE relative to different counterfactuals. In Appendix E (pg. \ 129 of the appendix), we present results from an instrumental variable approach relying on potential shifters of enrollment like presence of relatives or month of birth. The results reported in the appendix are larger than the intent-to-treat estimates, but much less precise. We are more limited in instruments given the small sample and its homogeneity relative to a study like HSIS. They both find that Head Start has larger gains compared to a home environment. Neither Kline and Walters (2016) nor Feller et al. (2016) present results by gender, so we cannot compare our results exactly. However, one important note is that a lot of the control-group subjects who enrolled in other center-based care actually enrolled in other Head Start programs. Even for those who did not, the standards in the early 2000s for preschools are much higher than those in the 1970s. The difference between ABC/CARE and the alternative center-based programs should be much larger than the difference between Head Start and the alternatives that the HSIS control-group selected into. In addition to not dividing by gender, this could explain the more decisive findings. We have included reference to these papers in the introduction and a few sentences addressing this and more explicitly referencing Appendix E (pg.\ 4).}

Approach aside, the authors seem to be doing a similar dissection of counterfactual care options in their companion paper (Garcia et al. 2017). Is the innovation of the current paper simply that you're doing it by gender?  Why is this important?   \textbf{This paper is meant to detail the methodology of dissecting the counterfactual care options and documenting the treatment effects. The companion paper takes this as given and focuses on the methodology of cost-benefit analysis. That paper also presents results by gender. We have added a few sentences in the introduction to clarify this point (pg.\ 4-5).}
\end{description}

\textbf{Minor comments}
\begin{enumerate}
\item I would recommend being clearer about what is meant by early education ``quality'' in this paper. Is it simply the cost of the program or in resources (``structural quality'')?  Is it something about interactions between caregivers and children (``process quality'')? I don't think that any process quality measures are available for the ABC or CARE interventions, but discussions of quality in early intervention have evolved, and the text should reflect this. \textbf{We added more explanation about the quality of ABC/CARE and the alternatives throughout, but especially in the data section (pg.\ 8-12). The vocabulary of process and structural quality is useful and we incorporated this citing several papers that study the relationship between different aspects of the two. You are correct that there are no measures of process quality in ABC/CARE, let alone for the control-group subjects who attended alternative care. We expanded more on the aspects of quality that we do know about to argue that the quality in ABC/CARE was high, especially compared to the other programs during that time.}
\item Figure 1 is troubling, in that it suggests that there is a lack of balance in observables across the control and treatment groups despite randomization. I think it would be helpful to see more discussion of the validity of randomized variation among non-attriters in the main text. (Relatedly, I don't think that dropouts post-randomization are not a problem, as seems to be implied in footnote 9.)  \textbf{That figure showed father's presence over time even after randomization. The pattern reflects a more widely documented trend that parents stay together more when the child is a son rather than a daughter. At randomization, the experimental groups were balanced in this variable and other variables related to disadvantage. Unfortunately, the exact randomization protocol is not documented, i.e., we do not know exactly what variables were used to match subjects and how this match occurred. To clarify the baseline characteristics, we replaced Figure 1 with Table 3. This shows the male/female and treatment/control differences at baseline. We also included more in-text explanation (pg.\ 9-10).}
\item Likewise, it would be helpful to see differences in observable characteristics between control children who attended and did not attend alternative childcare. \textbf{This is reported in Table A.4 (pg.\ 27 of the appendix). We expanded the explanation of it in text in order to speak to this concern (pg.\ 12). The main difference is that for control-group girls, working mothers always place them in alternative care. For control-group boys, working mothers do not always do this, most likely related to the fact that more fathers are present for boys than for girls.}
\item Presenting estimates by gender and family background, as is done in section 5, doesn't seem advisable given the very small sample sizes. \textbf{Although the sample size is very small, we think that it offers some suggestions about moderating effects of family background. We have qualified the discussion of those results to be more suggestive (pg.\ 29-30). }
\item Needing clarification:
\begin{enumerate}
		\item 1st full para., p. 2:  what do ``differentially promotes'' and ``differentially enhances'' mean exactly?  The language seems to imply that both sexes are positively affected by the intervention on all dimensions stated, but this does not appear to be the case (particularly with the step-down p-values) in Tables 4 and 5. \textbf{We changed the entire introduction so that the results are more clearly summarized.}
		\item Last full paragraph, p. 3:  if ``all achievement measures favor males in the control group,'' why isn't the proportion favoring males in the control group 1.0 in Table 1? \textbf{We completely redid the results shown in the introduction. The control-group males do very well in the achievement tests relative to the control-group females. This is not the case for the treatment group in which the females do much better than their male counterparts. This is consistent with the new presentation of results in Table 1, which shows the standardized treatment effects averaged over the outcome category.}
		\item P. 6:  It is not clear how the home visitation component can be safely ignored. Was there additional randomization of home visitation within the initial treatment group? \textbf{In ABC, the home visiting that occurred between 5 and 8 was randomized separately. No effect was found. In CARE, this 5-8 component was not randomized with all subjects who received center-based care also receiving this school-age component. We extrapolate that the findings from ABC extend to CARE as minimal changes were made to the school-age intervention. In sum, randomization of this component in ABC allows us to rule out that the age 5-8 intervention has an effect. We expanded the in-text reference related to this issue (pg.\ 6).}
		\item P. 9:  ``Dropouts are evenly balanced across treatments and controls?''  In terms of numbers or observable characteristics? \textbf{They are evenly balanced in terms of numbers. We clarify this in-text (pg.\ 10). We find that the estimates are robust to correcting for this attrition, as reported in the appendix (pg.\ 48 of the appendix).}
		\item P. 16:  how exactly does column (2) adjust for ``the differences in attrition''? \textbf{We adjust for attrition using IPW. This is documented in the appendix (pg.\ 48 of the appendix). We added clarification in the main text (pg.\ 18).}
		\item Continuing paragraph, top of p. 17:  college graduation estimates are referenced but not given in the table. \textbf{This was a typo (it should have said that high school graduation increases). This has been corrected.}
		\item I would be clear in the discussion on pp. 16-17 that you are using the bootstrapped p-values, not the step-down p-values. \textbf{We have added this clarification.} 
		\item Pp. 21-22:  How is it that the benefit/cost ratio of ABC/CARE is so much larger for males than for females? This seems contradictory to the following statement that ``females benefit more from the program than males.''  Is that not all outcomes are created equal (in terms of social value)?  This gets back to my comments about the importance of magnitudes. \textbf{We provide more detail in response to this above, but the outcomes for which men are more affected are costlier to society. We have clarified this throughout the paper (e.g., pg.\ 22) and added additional sentences to the introduction to address this concern (pg.\ 4-5).}
		\item P. 26:  Another seeming contradiction: estimated treatment effects do not ``appear similar across genders comparing treatment to staying at home full time''; at least it doesn't appear that way in Figures 3 and 4. \textbf{We have deleted this sentence and adjusted the description in Section 5 to more accurately summarize the treatment effects discussed in Section 4.}
\end{enumerate}
\end{enumerate}

\end{document}
