%Input preamble
\input{preamble}
\input{output/mainstatistics}

\usepackage[stable]{footmisc}

\newcommand*\leftright[2]{%
  \leavevmode
  \rlap{#1}%
  \hspace{0.5\linewidth}%
  #2}

\newcommand{\orth}{\ensuremath{\perp\!\!\!\perp}}%
\newcommand{\indep}{\orth}%
\newcommand{\notorth}{\ensuremath{\perp\!\!\!\!\!\!\diagup\!\!\!\!\!\!\perp}}%
\newcommand{\notindep}{\notorth}

\externaldocument{abc_comprehensivecba_appendix-pub}
\externaldocument{abc_comprehensivecba_appendix-priv}
\pagenumbering{roman}

\begin{document}


\doublespacing
\setcounter{section}{3}
\section{Summarizing Multiple Treatment Effects} \label{section:methodology}

ABC/CARE has rich longitudinal data on multiple outcomes over multiple periods of the life cycle. Summarizing these effects in an interpretable way is challenging.\footnote{Appendix~\ref{appendix:results} presents step-down $p$-values for the blocks of outcomes that are used in our benefit/cost analysis which we summarize in this section (\citealp{Lehman_Romano_2005_AnnStat} and \citealp{Romano_Shaikh_2006_AnnStat}). We follow the algorithm in \citet{Romano_Wolf_2016_pval_SaPL}.} Simpler, more digestible summary measures are useful for understanding our main findings. This section discusses our approach to summarizing vectors of treatment effects using combining functions that count the proportion of treatment effects by different categories of outcomes.

Consider a block of $N_l$ outcomes indexed by set $Q_l = \{1,\dots,N_l\}$. Let $j \in Q_l$ be a particular outcome within block $l$. Associated with it is a mean treatment effect
\begin{equation}
\Delta_{j,a} : = \mathbb{E} \left[ Y^1_{j,a} - Y^0_{j,a} | \bm{B} \in \mathcal{B}_0 \right], j \in Q_l.
\end{equation}

We assume that outcomes can be ordered so that $\Delta_{j,t} >0$ is beneficial.\footnote{All but 5\% of the outcomes we study can be ranked in this fashion. See Appendix~\ref{appendix:results} for a discussion.} We summarize the estimated effects of the program on outcomes within the block by the number of positive counts within block $l$:
\begin{equation}
C_l = \sum^{N_l}_{j=1} 1 (\hat{\Delta}_{j,a} >0).
\end{equation}
The proportion of beneficial outcomes in block $l$ is $C_l / N_l$.\footnote{In our empirical application we consider all the outcomes as a block, and then different blocks grouped according to common categories---e.g., skills, health, crime.}

Let $\mathcal{L}$ be the set of blocks. Under the null hypothesis of no treatment effects for all $j \in Q_l, l \in \mathcal{L}$, and assuming the validity of asymptotic approximations, $C_l / N_l$ should be centered around $1/2$.

An alternative to formalize this is the following. Suppose that the treatment effect $\Delta_{j,a}$ has a null cumulative distribution associated to it. Denote this distribution by $\mathbb{F}_{j,a} \left( \cdot \right)$. Assume that $\mathbb{F}_{j,a} \left( 0 \right) = 1/2$. Therefore, $\Pr \left( \Delta_{j,a} > 0 \right) = 1 - \Pr \left( \Delta_{j,a} \leq 0 \right) = 1 - \mathbb{F}_{j,a} \left( 0 \right) = 1/2$. This states that under the null hypothesis a beneficial outcome is as likely as a non-beneficial outcome and enables us to show that $C_{l}/N_{l}$ is centered around $1/2$. That is, $\mathbb{E} \left[ C_{l}/N_{l} \right] = 1/2$. To see this, note that $\mathbb{E}\left[ 1 ( \Delta_{j,a} >0)  \right] = \Pr \left( \Delta_{j,a} \leq 0 \right) \times 0  + \Pr \left( \Delta_{j,a} > 0 \right)  \times 1 = 1/2$ and therefore $\mathbb{E} \left[ C_{l}  \right] = \mathbb{E} \left[ \sum^{N_l}_{j=1} 1 (\Delta_{j,a} >0) \right] = \sum^{N_l}_{j=1} \mathbb{E}\left[ 1 ( \Delta_{j,a} >0)  \right] = N_{l}/2$. Thus, $\mathbb{E} \left[ C_{l}/N_{l} \right] = 1/2$.

We bootstrap to obtain $p$-values for the null for each block and over all blocks. We also count the beneficial treatment effects that are statistically significant in the sets of outcomes across each of the groups indexed by the set $Q_l$. Using a 10\% significance level, on average 10\% of all outcomes should be ``significant'' at the 10\% level even if there is no treatment effect of the program, using a similar justification as before. We provide evidence against both null hypotheses.\footnote{We present $p$-values for these hypotheses and a number of combining functions by outcome categories in Appendix~\ref{appendix:results}.} Combining counts across all blocks enables us to avoid (i) arbitrarily picking outcomes that have statistically significant effects---``cherry picking''; or (ii) arbitrarily selecting blocks of outcomes to correct the $p$-values when accounting for multiple hypothesis testing.

%References
\pagebreak
\singlespace
\bibliographystyle{chicago}
\bibliography{heckman}

\end{document}


