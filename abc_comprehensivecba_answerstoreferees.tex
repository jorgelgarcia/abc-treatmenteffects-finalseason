%Input preamble
\input{preambleappendix}
\input{output/mainstatistics}

\usepackage[stable]{footmisc}

\newcommand*\leftright[2]{%
  \leavevmode
  \rlap{#1}%
  \hspace{0.5\linewidth}%
  #2}

\newcommand{\orth}{\ensuremath{\perp\!\!\!\perp}}%
\newcommand{\indep}{\orth}%
\newcommand{\notorth}{\ensuremath{\perp\!\!\!\!\!\!\diagup\!\!\!\!\!\!\perp}}%
\newcommand{\notindep}{\notorth}

\externaldocument{abc_comprehensivecba_appendix-pub}
\externaldocument{abc_comprehensivecba_revised}
\doublespacing

\begin{document}

\singlespacing
\begin{titlepage}
\newgeometry{top=.8in, bottom=.8in, left=.8in, right=.8in}

\title{\Large \textbf{Responses to the Editor and the Referees \\ Quantifying the Life-cycle \\ Benefits of an Influential Early Childhood Program}.}

\author{
Jorge Luis Garc\'{i}a\\
John E. Walker  Department of Economics\\
Clemson University \\ 
Social Science Research Institute \\ 
Duke University \\  \and
James J. Heckman \\
American Bar Foundation \\
Department of Economics\\
The University of Chicago \and
Duncan Ermini Leaf \\
Leonard D. Schaeffer Center \\  for Health Policy and Economics\\
University of Southern California \and
Mar\'{i}a Jos\'{e} Prados \\
Dornsife Center for \\ Economic and Social Research\\
University of Southern California}
\date{First Draft: February 4 , 2018\\ This Draft: \today}

\maketitle
\thispagestyle{empty}
\restoregeometry
\end{titlepage}

\doublespacing

\noindent We thank you all for the thoughtful comments which have led to substantial improvement in the paper. Itemized responses to each of the questions are next.

\noindent \textbf{Editor. Most certainly, the next version should make it reasonably easy to get on top of it all, even for an outsider like me. The JPE owes this to its readers, in particular future graduate students.}

\noindent \textit{Response.} We rewrote the introduction and the methodological sections, and reorganized the remainder of the sections. We use labor income as a workhorse example to illustrate our forecast method. We describe it generally in the introduction, and then get to the precise details in the main methodological section, in which we also provide a list of steps to follow to replicate this procedure. The forecasting for the rest of the outcomes follows a very similar logic which we detail in the Appendix.

\noindent \textbf{Editor. The key idea of the synthetic cohort should be fleshed out much more clearly in the introduction. The econometric theory portion looks like it is written by authors that are different from those that wrote the rest: nothing wrong with dividing up work, of course, but as a result, the paper feels rather disjoint.} 

\noindent \textit{Response.} The forecasting is fleshed out and illustrated in Section~\ref{section:cbamethodology}. The econometric portion has now been compressed and reorganized, so that the basic testable implications can be mathematically expressed. The rest has been left out.

\noindent \textbf{Editor. There really needs to be an appropriate literature discussion. Readers typically look for it in the introduction or in an extra section following it. I know that Jim in particular has been on the theme that ``early childhood education has remarkable returns'' for decades. There surely must be a substantial body of work by now on this, and perhaps not only by him. So, what is in short the state of the art? How does the paper at hand advance beyond the state of the art, what is truly new and substantial here? How does it relate to what has been done before?}

\noindent \textit{Response.} The paper is relatively long so we decided to intersperse the literature review in the introduction. The first paragraph of the paper actually states what the concrete contribution of our paper is. While you are right that there has been much work on identifying and estimating the gains from early childhood education, there is much less work on long term outcomes and, especially, life-cycle benefits. Our paper is the first to provide a methodology to forecast life-cycle benefits to estimate rates of return. In fact, by doing so it provides a template to evaluate social programs that are not only early childhood education programs. The appropriate comparisons and relevant literature are cited in the introduction. A whole section is devoted to comparing our method with ``back-of-the-envelope'' calculations that current papers in the literature employ (Section~\ref{section:bcaestimates}). We think that this gives a clear idea of what the contribution of our paper is.

\noindent \textbf{Editor. I am not really sure that the econometric theory portion (most of Section~\ref{section:cbamethodology}, thus) with all its abstract assumptions is all that helpful: parts of it are sloppy (see e.g. main comment 4), parts of it are unclear (see e.g. main comment 4 and several minor comments), and parts of it seem to hide rather than illuminate the crucial parts of the analysis (see in particular my main comment 5 below). This should all be much more coherent. Perhaps, for the JPE, one can afford to off-shelve some of the detailed, but ultimately tangential econometric theory formulation to the technical appendix: it sometimes feels like something that got formulated, after the intuition of the general principles were understood (and those would be good to formulate) rather than the other way around. I am not sure that the formalism will be of much help to any reader, at a first pass. I shall admit, I may have been missing the crucial bit, which you might strongly feel should be part of the main text. But perhaps even then there is a solution of drastically reducing it all to that, while moving the full-fledged version to the technical appendix.}

\noindent \textit{Response.}  We are now only keeping the basic framework and are much more precise about it. Having labor income as a ``workhorse example'' allows us to get rid of one of the subindices and sets that we were carrying around---see Equation~\eqref{eq:outcome}. We reduced the number of assumptions to what is absolutely basic to derive the testable implications. The testable implications are very relevant in explaining the intuition of the forecasting as well as how would one take our method to practice in other samples. The whole procedure is now explained in only a few equations.

\noindent \textbf{Editor. pg.\ 15 seems to describe a key component of your analysis. You seek to compare, say, whether labor income is different between treated and non- treated, and since you cannot observe that for the people in your sample, you use a synthetic sample for prediction. Fine. But then the key surely is to get the difference between these two groups correctly, i.e., that the two synthetic groups of the auxiliary sample differ by ideally exactly as much as they would if we were to follow the original two groups. pg.\ 15 talks much about predicting future incomes, but we don't care much about the level itself: we care much more about the difference between these two groups. There is little said to assure the reader that one gets the right answer for that difference.}

\noindent \textit{Response.} That is correct, one could get by with an accurate prediction of the treatment-control difference. We rely on the stronger conditions of predicting in levels for both the treatment and the control because this provides us with additional testable implications---Equations~\eqref{eq:suff1} and~\eqref{eq:suff2}---for which our method performs very well. However, we also discuss the minimal conditions required to accurately forecast life-cycle mean differences.

\noindent \textbf{The background variables will be the same for the treated and untreated, for example. So how, exactly, does the difference in treatment show up in the synthetic groups?  Just the development of labor income until the observable age? That might be fine, but then clearly say so. Something else?}

\noindent \textit{Response.} It shows up because there are two \text{different} types of predictors: (i) $\bm{B}_k$ background variables that are not affected by treatment; and (ii) $\bm{X}_{k,a}^d$ which could be affected by treatment (what you call outcomes up to age a). The key assumption for obtaining our forecasts is actually that $\bm{X}_{k,a}^d$ generates the treatment effect that the program could have on $\bm{Y}_{k,a}^d$ through the invariant production functions. Any treatment-control difference in the outcomes of interest arises from a treatment-control difference in $\bm{X}_{k,a}$ (as dictated by the function $\bm{\phi}$). These points are clearly discussed in the list of steps in Section~\ref{section:cbamethodology}.

\noindent \textbf{This needs to be a lot clearer and a lot more convincing. You may be resolving this eventually in (3). It is unclear there, however, whether you want all the characteristics of the synthetic group to be the same or just for the one specific j, which you are seeking to forecast in (1). To me, it makes more sense that they are all the
same (if possible: is it? Comment on that!).}

\noindent \textit{Response.} We now thoroughly comment on this point in Section~\ref{section:cbamethodology}, where we detail the construction of the synthetic cohorts. As you point out, it makes more sense to construct one synthetic control group and one synthetic treatment group for doing the analysis across all of the outcomes. That is what we do.

\noindent \textbf{Editor. Connected to that: I found assumption A-1 on pg.\ 18 mystifying. It may actually be unfortunate that you ``suppress individual i subscripts'' to ``avoid notational clutter'', as you state on p. 16. I thought that the explanation on pg.\ 15 and (3) meant, that you take each individual of your actual sample and ``match him/her'' up with someone in the auxiliary sample, who has the exact same vector of characteristics Y until age a* (which then raises a bunch of questions: what, if there are many in the artificial data that do the trick? What, if there are none?). So, you then would have an auxiliary sample, that looks like your experimental sample, but where you can observe everything until the end of their lives. If that is what you do, then A-1 is not an assumption: it is a definition of the auxiliary sample.} 

\noindent \textit{Response.} We have rewritten Section~\ref{section:cbamethodology}. We apologize for the confusion in our main analysis. Our procedure is listed there. We have removed old Assumption A-1 in the last version of the paper because it was not even necessary. We now note that: we do not match individual to individual across experimental and non-experimental samples. Instead, we construct synthetic treatment and control groups and estimate structural relationships. What matters is the structural relationships that we are able to identify and estimate in the non-experimental samples, but not the outcomes themselves. For this, Assumption A-1 was confusing and we have restated all our assumptions in terms of these structural relationships.

\noindent \textbf{And if that is not the definition, then exactly what is the definition? In any case, assumption A-2 on p.21 states some support condition. It would seem to me that this is a necessary condition to even construct the auxiliary sample, as defined by ``assumption'' A-1. Perhaps you mean something else, but this should all be crystal clear. Moreover, the selection of variables is really key. Suppose you include cohort information in the regressors in (1): then, assumption A-2 would be impossible to satisfy. There is too much crucial information here, swept under the rug of apparently clean formalism.}

\noindent \textit{Response.} The selection of variables is in fact key, and we now have generated two subsections to discuss this and explain how we put it in practice. These are in Section~\ref{section:cbamethodology}.

\noindent \textbf{Editor. A key concern that I do not see discussed early on and with great care is that ``different times are different''. Suppose, say, that Y contains labor income, measured in year-2000 dollars. Suppose I wanted to use your methodology to also say something about great-great-grandkids, and therefore tried to find a matching sample of people, where I have data for their next four generations. I probably would have to go back more than 100 years. But then someone with the labor income of a contemporary lower middle class person would be considered filthy rich back then! They surely wouldn't be comparable! The issue may be less pronounced here, since the difference in birth year is perhaps just 20 or 30 years (how much, actually?), but still. You might be able to finesse this by just looking at income growth rates (since, once again, we are ultimately only interested in the difference between the treated and the non-treated groups). But still, one might need to worry about ``macro developments'' here. Crime rates may have changed. Female labor force participation, divorce rates, unemployment rates: they all changed. Perhaps, the identifying assumption here is that these affected the treated and non-treated groups the same, so that these macro effects disappear, once differencing or so. But shouldn't that be clearly spelled out and clearly argued? You ``hide'' all that with ``Condition C-1'', but as I just described with my great-great- grandkids example, this can be a pretty ridiculous condition for certain lists of outcomes. The selection of outcomes (e.g.: level of income or growth of income or income relative to the average U.S. income?) is really key! Don't hide that behind too much formalism, discuss this clearly and upfront. At this point, it is hard to be convinced that what you do is legit.}

\noindent \textit{Response.} Your concern boils down to a ``cohort effects'' concern. As noted previously, we expressed this in an admittedly obscure assumption. Note that actually all we need is for the structural relationships to display a ``no cohort effects'' property:' What we require is for the mapping between predictors and outcomes to be constant across children, parents, and grand-children, once we condition on background variables. We elaborate on this in Remark~\ref{remark:cohort} after stating Assumption~\ref{ass:summary}. What is valuable here is that this assumption leads to testable implications which we test and in which our samples perform very well as discussed are in Tables~\ref{table:invariance} and~\ref{table:invarianceerrors}.

\noindent \textbf{Editor. Is it really true that you can get by with (6)? If you want to match individual-by-individual (as described in my main comment 4 above), might we want to condition also on outcomes up to age a*? Perhaps I am misunderstanding that condition, since you also state something about X potentially containing lagged variables. You weren't all that clear on this before (see p. 19, top), and this now comes back to haunt me in understanding what it is you do. This needs clarification.}

\noindent \textit{Response.} We understand the source of the confusion. We now clarify in the text and in this response. In Equation~\eqref{eq:outcome} we define what the relationship between the outcomes of interest $Y_{k,a}^d$ and two \text{different} types of predictors: (i) $\bm{B}_k$ background variables that are not affected by treatment; and (ii) $\bm{X}_{k,a}^d$ which could be affected by treatment (what you call outcomes up to age a). The key assumption for obtaining our forecasts is that the treatment effects are generated by changes in $\bm{X}_{k,a}^d$ through a policy-invariant production function. Recall: we do not want to match individual-to-individual. Instead, we want to create comparable samples to treatment and control in the auxiliary samples. These points are now clearly discussed in the list of steps in Section~\ref{section:cbamethodology}.

\noindent \textbf{Editor. Cut figure 2: TMI. This is technical appendix material. Key results ``in print'' only, please.}

\noindent \textit{Response.} We find this figure to be helpful in communicating the robustness of our results, but we understand that the first draft contained way too much information. We moved this figure to the results section and expanded much more on it to discuss our results.

\noindent \textbf{Editor. P.7, ``when we omit crime ... still ... substantial returns''. State how much.}

\noindent \textit{Response.} This sentence has actually been edited out.

\noindent \textbf{Editor. P.9. Given that you make advertisement for these programs, it surely is important to understand well what these programs do, without overloading the reader with information. On pg.\ 9 you say, ``Both have two phases, the first of which lasts from birth until age 5. ... The second phase of the study consists of child academic support through home visits from ages 5 through 8. The first phase of CARE, from birth until age 5, has an additional treatment arm of home visits designed to improve home environments.'' You point to appendix A and to \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED} for more information, but I feel, more ought to be said here about the substance of the program. Among the items of interest: one would like to know what ``portion'' is particularly costly, how much it costs and why.}

\noindent \textit{Response.} Section~\ref{section:background} now describes the main ingredients and Section~\ref{section:programscosts} expands on the cost of each of the annual components of the program. We do not think that it is helpful to elaborate further on this in the main text. But we elaborate in detail in Table~\ref{tab:totalcosts} in Appendix~\ref{app:programcosts} on the costs. As it is usual in these programs, teaching is the most expensive input. Note from Appendix~\ref{app:programcosts} that we went back to the primary sources (even invoices) to be able to compute these costs.

\begin{table}[H]
\centering
\begin{threeparttable}
\caption{Yearly Program Costs, ABC/CARE}
\footnotesize
\input{output/programcosts}
\begin{tablenotes}
\footnotesize
\item Note: This table summarizes the yearly costs for ABC/CARE. They are based on primary-source documentation describing ABC. We assume that the costs for ABC and CARE were the same based on conversations with programs' staff \citep{projectcare2014interviews,abc2014-2015interviews}. 
\end{tablenotes}
\end{threeparttable}
\end{table}

\noindent \textbf{Editor. pg.\ 10, ``Randomization for ABC/CARE was conducted on child pairs matched on family characteristics. Siblings and twins were jointly randomized into either treatment or control groups. Randomization pairing was based on the childhood risk index, maternal education, maternal age, and gender of the subject.'' I don't know what that means. Perhaps it is good that I am an outsider here. Was this randomization done by the programs themselves? I.e., did they sort children into pairs, so that both had similar family backgrounds, and then flipped a coin on who got admitted? What does ``joint randomization'' mean? Does it mean, either all siblings got in or they didn't? If this is true for siblings, why is it important to then mention twins in particular? Aren't twins siblings? I understand that siblings aren't twins, but somehow, that sentence threw me off. Etc.. Please make sure this is all crystal clear, even to outsiders like me.}

\noindent \textit{Response.} This part of the main text contained a lot of jargon and we decided to leave it out of the text to avoid confusion. For all practical matters, the importance is that admission into the program was randomized. The randomization was done by the program officials themselves. The paired randomization process as you described it is exactly how they carried out the randomization. Siblings (either when they were twins or when they were not) were paired and randomized as a unit and put together either in treatment or control status. The steps and a diagram describing the randomization protocol in detail are in Appendix~\ref{appendix:background}.

\noindent \textbf{Editor. pg.\ 11, ``Toward this end, we define three indicator variables: W = 1 indicates that the parents referred to the program participate in the randomization protocol, W = 0 indicates otherwise.'' That seems to introduce a new element not described previously, and is hard to understand as stated. So, parents got referred to these programs, see p.9. Their ``eligibility was determined by a score on a childhood risk index.'' So, does W=0 indicate getting excluded by that score? Hopefully not, but that is how it reads. The next paragraph on p. 9 simply mentions the randomization, which you capture with R. I therefore do not know what the W stands for. Ah, this seems to get clarified in the next paragraph ... but it really is confusing as stated here. You mean to say, ``W-1 indicates that the parents referred to the program participate choose to participate ...''. Since you argue in the next paragraph that all parents do, why not drop W altogether? Don't waste notation. It is coming back on p. 19, and there too it does not seem to be of much help. Perhaps I am missing something important here, but if so, tell the reader (i.e. that silly novice graduate student reading this paper).}

\noindent \textit{Response.} The definitions of $W, D, R$ are now provided in two consecutive paragraphs at the beginning of Section~\ref{section:cbamethodology}. We do think that it is important to define them separately. $W$ is offer to participate in randomization, $R$ denotes randomization into or out of the program, and $D$ denotes compliance. It is \textit{not} a feature of all programs that $W = 1$ and $D = R$. When interpreting the external validity of our estimates, this is a powerful fact. Once invited, everyone agrees to participate and complies. Thus, our inferences are valid for everyone in the population who was given an offer to begin with. We can locate those people by asking who satisfies $\bm{B} \in \mathcal{B}_0$ (i.e.,\ who is eligible).

\noindent \textbf{Editor. Related, in that same paragraph, you note that R takes one of two values, i.e. R = 1 or R = 0. I then don't understand what you mean by ``D indicates attending the program, i.e., D = R implies compliance with the initial randomization protocol.'' I may have an idea what you mean: I just don't understand it from a mathematical and notational perspective. What values can D take? Are you saying, that there are two cases implying compliance with the initial randomization protocol, namely R=1 and D=1 as well as R=0 and D=0 (so that R=D in both cases)? It confuses me.}

\noindent \textit{Response.} This has been rephrased. $R$ takes $1$ if the child is randomized to treatment and $0$ if she is randomized to control. $D$ is $1$ if the child complies to the treatment status (i.e.,\ the parents comply to what the randomization protocol indicates). $R$ and $D$ are \textit{ex-ante} different: The former is a not a decision and the latter is.

\noindent \textbf{Editor. pg.\ 11: The first sentence of the paragraph ``Individuals ...'' should need one or several extra words at the end to make it proper English.}

\noindent \textit{Response.} We have clarified that $\mathcal{B}_0$ is the set of risk-index scores that determines program eligibility. Eligibility and the index are discussed in Section~\ref{section:background}. The index is spelled out on footnote, and then summarized in detail in Appendix~\ref{appendix:background}.

\noindent \textbf{Editor. pg.\ 12, top. ``j'' usually means an index: could there be a better symbol instead ... ah, actually, you mean this to be an index! It is just written in a confusing way ... in particular, J does not ``index the outcomes'' (that could be a large index set!), but rather, indexes the component of the outcome. What is d? How does it relate to D or R (or something else) before? What is k,e,n? Strangely, e and n are defined at the bottom of pg.\ 16, but not here. Why not give a number of components j rather than talking about the set J? Shouldn't you tell the reader more about the list of outcomes which make up the vector Y? After all, later on, you seek to construct a synthetic cohort with similar outcomes ... so knowing what they are will be crucial latest then. This paragraph needs a dedicated rewrite.}

\noindent \textit{Response.} We agree and actually came to the conclusion that the $j$ indexing was unnecessary. $j$ indexed one of many outcomes, and we are now using a vector of outcomes to summarize our method. The generalization to many outcomes is obvious and thus we dropped this indexing.

\noindent \textbf{Editor. pg.\ 13: As a poor graduate student reading your paper, I can't figure out what to do with table 1. Is this meant to summarize something that is elsewhere in the paper: perhaps a technical appendix? I gather that you are trying to construct life-cycle costs and benefits. The first column gives a list of items, that are rather cryptic: if it was just them, it would be better to use two paragraphs and explain them. For example, why are ``Health Costs'' listed twice? What does ``Victimization Inflation'' mean? I understand the next column, i.e. age. But the information in the remaining columns is, at best, a reference to something clarified elsewhere. It gives me at best a vague guide at how to attempt and reconstruct your numbers. It says that I should ``impute national victims-arrests ratio(s)'' and a lot of other stuff. Recommendation: I feel this table should be in the technical appendix. In the main body of the text instead provide an in-text list of the ``components'', i.e. the left-most column. Explain them briefly, where needed. Also, explain briefly the main idea or main hurdle or main innovation in calculating that component, if needed. If they are similar to your main ``intuitive'' labor income example, then say so. For each component, point to a precise location in the technical appendix, where you explain with sufficient clarity, exactly what you do, so that a graduate student can replicate your numbers exactly.}

\noindent \textit{Response.} We have done so. Table 1 was not effective, and, as you suggest, we base everything on our labor income example. Instead of providing tedious tables, we spelled out a recipe to replicate our procedure. An analogous recipe for replicating our inference procedures is in Appendix~\ref{appendix:methodology}.

\noindent \textbf{Editor. pg.\ 14: what is a* ? If that is a number, why not state it? Something else?} 

\noindent \textit{Response.} As our labor income example makes clear, $a^*$ is a point where the researcher observes both a realized value in the experimental sample and a forecast model (output of the methodology). In our case, $a^* = 30$. But it could take many values across applications, and that's why we state it abstractly. We want to provide the steps to replicate our methodology in other settings.

\noindent \textbf{Editor. pg.\ 14, last sentence of paragraph ``We have data ...'' was probably meant to say ``which requires us to ...'' (or something else).}

\noindent \textit{Response.} Correct. This section has changed completely. 

\noindent \textbf{Editor. P.15:you have not told the reader much about B0. See also my comment 8 above.}

\noindent \textit{Response.} The same response applies to that of your previous comment.

\noindent \textbf{Editor. pg.\ 15, middle: what is ``mediation analyses''? If this is a well-known term in the literature, please supply a key reference, else explain.}

\noindent \textit{Response.} Yes it is., but we have clarified it in the introduction. One standard reference relevant to this literature is \citet{Heckman_Pinto_etal_2013_PerryFactor}. We have provided that.

\noindent \textbf{Editor.  ``the two stages can be compressed''. Cool. But we don't care whether this can be done: we care only whether you actually do this. Do you? And if so, exactly how? Details should be provided in the technical appendix.}

\noindent \textit{Response.} We more concisely state why would this be important and do present results using this alternative. Instead of following the steps in Section~\ref{section:cbamethodology}, an alternative is simply to study the average profiles of treatment-groups-alikes and control-group-alikes (and take the respective mean difference between these two groups). That is what we call non-parametric matching. It is a useful check because it compresses our procedure to a simple exercise, but it relies on the same key assumptions (and that's why spelling out our method is relevant). We believe that this is a method that some readers will be familiar with, and will find appealing given the robustness of our results to using it. We discuss it succinctly in the text but in greater detail in the Appendix.

\noindent \textbf{Editor. pg.\ 16, ``There is close agreement of the constructed profiles within the age group of the experimental sample.'' See my main comment 3: if the constructed profile is obtained per matching the profile within the age group of the experimental sample, isn't this then a tautological statement? The same holds for the next paragraph. I.e., what, precisely, is used for construction, and what is the independent verification here? This is very unclear.}

\noindent \textit{Response.} The explanation that we gave before failed to communicate why the fact that the constructed profiles match is important. To explain this, we refer to the recipe that we provide in Section~\ref{section:cbamethodology}. The first matching obtains samples that resemble our treatment and control groups at baseline. This is how we construct synthetic cohorts. We later use matching on baseline variable and on $\bm{X}_{d,a}^d$ to identify and estimate structural relationships and form a forecast. The reason why Figure~\ref{figure:controltests} is compelling is because in the auxiliary sample there is no treatment at all (everyone who satisfies $\bm{B} \in \mathcal{B}_0$ is observationally equivalent to a control-group child). Thus, our forecast for the average profile for the control group should be the same as the average profile for people who satisfy $\bm{B} \in \mathcal{B}_0$ in the auxiliary sample. We now state this more clearly in Section~\ref{section:cbamethodology}.

\noindent \textbf{Editor. On pg.\ 20 and just above Assumption A-1, Y now suddenly has five subscripts, when it only had three before, and the common subscripts are in a different order. I find that confusing. You then get to equation (3), and now there are four subscripts. This is not a compromise: this is even more confusing.}

\noindent \textit{Response.} We now only keep subscripts for what is relevant to our methodology: treatment status, experimental and non-experimental samples, and age. The rest is gone, and was in fact convoluted.

\noindent \textbf{Editor.  pg.\ 24: Assumption A-4 feels a bit odd. The notation is general enough that both d and k could be components of x. If one had a phi, which did not depend on it, then one could construct a new one, which did, switching between the ``old'' values, in dependence on d and k, and proceed with that. Is Theorem 1 then still valid? Perhaps something else is meant.}

\noindent \textit{Response.} Let us clarify this because it is at the heart of our methodology. What we mean is that outcomes in both the experimental and non-experimental samples can be summarized by $\bm{x}$ and $\bm{b}$. That is, the realization of an outcome of interest is generated by realizations of $\bm{x}$ and $\bm{b}$. That is why it is crucial for us to document that treatment is in fact operating on $\bm{x}$ and that $\bm{\phi} \left( \cdot, \bm{b} \right)$ is a non-trivial function of $\bm{x}$, which we document in Section~\ref{section:cbamethodology}. If $\bm{x}$ and $\bm{b}$ summarize membership to either the experimental or the non-experimental sample and treatment status, then there is no $\bm{\phi}_{k,j}^d$ for $d=0,1$ and $k = e,n$ but one and only one \textit{invariant} $\phi$.

\noindent \textbf{Editor. pg.\ 27: the notes to table 2 contain a model. That really should be part of the main text or appendix (or technical appendix): it feels odd to explain it there.}

\noindent \textit{Response.} This table has been placed on the Appendix.

\noindent \textbf{Editor. Is, say, pg.\ 29 a verbal description of what you described more formally above? Something else? How do the two relate? And what do you do, exactly? For example, the paragraph ``Our methodology...'' on pg.\ 29 needs a more precise fleshing out in the technical appendix, and you should point to that in the main text.}

\noindent \textit{Response.} As we clarify in the text now, forecasting the outcomes other than labor income rely on similar assumptions and some additional steps. We provide brief details in Section~\ref{section:cbapractice} for each of these outcomes and then refer to the reader to each of the relevant appendices (there is one appendix for each outcome, including labor income).

\section*{Comments of Reviewer 1}

\noindent \textbf{Referee 1. First, the title is misleading. The ABC/CARE projects do not in any way represent ``prototypical" child care. The title is misleading and might suggest that one could expect comparable benefits from almost any form of child care. This was center-based child care that offered low staff to child ratios, active monitoring, used a curriculum, etc. The title should be revised to be more accurate. Similarly, the program should be referred to more accurately as a child development center form of childcare throughout the paper and its features briefly reiterated in the discussion.}

\noindent \textit{Response.} Based on this comment, we have retitled our paper replacing the word prototypical with influential. We maintain that the program is influential, but as you say it may not be prototypical. In footnote 6, as well as Table A.33, we provide a list of programs around the world that have replicated ABC/CARE. We explicitly acknowledge in the introduction that ``ABC/CARE was offered as a child development form of childcare,'' and that ``it is a prototype of what early childhood education should be (e.g., high staff to child ratios, active monitoring of children, and relaxation of time constraints to single mothers starting form birth) and not necessarily what early childhood is nationwide.''

\noindent \textbf{Referee 1. Second, this paper unduly relies on citation of the authors' own unpublished analyses and sometimes the unpublished work of others. This is not necessary in most cases. The authors fail to cite in the appropriate locations the peer-reviewed publication(s) that make(s) the same point about many foundational issues, such as the study's original design and prior seminal findings. For example, the fact that the children in the control condition were not prevented from attending center-based childcare in the community appears in major prior articles and the benefits of this intermediate, non-randomized treatment ``substitute" has been effectively documented (notably, \citet{Burchinal_etal_1989_CD_Daycare-Pre-K-Dev}). Why would the authors cite an unpublished source of their own (specifically, \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED}, unpublished) for this fact? Actually, the \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED} is cited so often that one wonders how much it overlaps with this paper and what is needed from that not readily available paper to understand this current paper? This strongly detracts from the current paper.}

\noindent \textit{Response.} This point is very well taken and we made an effort to: (i) cite \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED} only when necessary (it is now \citet{Garcia_Heckman_Ziff_2018_EER} and it is forthcoming). Before, it was cited over 10 times. Now, it is cited in the introduction once to state the difference between that paper and this paper per the editor's request. We concretely point to some results and references from that paper that are useful here; and (ii) rely on sources that are primary to the facts that we intend to document or refer to. Examples of these appear mostly when we discuss the content of the program in Section~\ref{section:background}. We refer to:

\begin{enumerate}
\item \citet{Burchinal_etal_1989_CD_Daycare-Pre-K-Dev} and other contemporaneous sources when discussing the take-up of alternative childcare arrangements by the control group. 
\item \citet{Sparling_1974_Synth_Edu_Infant_SPEECH, Ramey_Collier_etal_1976_CarolinaAbecedarianProject, Ramey_etal_1985_Project-CARE_TiECSE, Wasik_Ramey_etal_1990_CD, Ramey-etal_2012-ABC} when documenting the content of the ABC/CARE program. 
\item \citet{Wasik_Ramey_etal_1990_CD} when documenting the slight differences between ABC and CARE.
\end{enumerate}

\noindent About the frequency in which \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED} is cited, we now keep a minimum and explained the difference between that paper and this paper explicitly. We do want it to be to known that \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED} is our companion paper. These two papers are the first to use administrative data on crime. Previous studies have relied on self-reported crime outcomes and have claimed (somewhat not surprisingly) no effects. We elaborate on this in Appendix~\ref{appendix:crime}, which is devoted to criminal outcomes.

\noindent Perhaps this is too much detail for our paper but note that \citet{Anderson_2008_JASA}---a often-cited study in this literature---provides estimates of factors for the Carolina Abecedarian Project (ABC) that combine many outcomes into a condensed summary measure. However, the data he uses do not include important health, survey, and administrative data collected from the ABC sample after age 21, resulting in different results than what we report. The most glaring example of this is crime outcomes, whose treatment effects are not significant until after age 21 in ABC. We also note that previous literature do not separate the effects by gender and, as a consequence, do not find precise treatment effects on education and labor income. As we report in Table 1, the treatment effects are substantial when considering effects by gender. Previous studies presenting treatment effects of ABC and CARE include \citet{Ramey_etal_1985_Project-CARE_TiECSE,Clarke_Campbell_1998_ABC_Comparison_ECRQ,Campbell_Pungello_etal_2001_DP,Campbell_Ramey_etal_2002_ADS,Campbell_Wasik_etal_2008_ECRQ,Campbell_Conti_etal_2014_EarlyChildhoodInvestments}. Only \citet{Campbell_Conti_etal_2014_EarlyChildhoodInvestments} divide the treatment effects by gender. However, they do so only focusing on the health effects, finding that men have many more positive effects especially in cardiovascular and metabolic conditions. This is consistent with the results that we report in our paper.

\noindent \textbf{Similarly, specific previously published findings about effects of the early educational intervention at age 30 and 21 should be cited more directly in the introduction and at intermittent places later so that readers can more fully appreciate the context of this new economic forecasting analysis. To the extent that the current authors notice subtle differences or include additional data can be mentioned, when needed, but not to the exclusion of providing readers more details about these studies and previous findings.}

\noindent \textit{Response.} We have added the information in the previous answer as a means to clarify for the reader the source of the differences between our results and the results in previous papers.

\noindent \textbf{Referee 1. Closely related is that earlier reports sometimes appear at odds with the assumptions and perhaps the data incorporated into this new, expansive economic analysis. A prime example is that there were no significant effects on earnings or crime at age 30 of the original treatment, at least as previously analyzed. This should not be ignored -and if differences occur, the authors should offer reasons for these discrepancies.}

\noindent \textit{Response.} The source of the difference in outcomes was previously noted in our response. It arises from our access to richer data at later stages of the life cycle. We speculate that the other assumptions that we make have to do with the fact that we assume that (i) once treatment is offered, all of the families agree to participate of the program; (ii) once randomized into treatment, there is full compliance. 

\noindent We believe that the work that we have done to document the randomization protocol and the sample of participants is novel in its thorough detail. Previous sources have disqualified the validity of the randomization protocol without knowledge of the causes behind why different individuals attrit from the sample as the data collection process evolved \citep[e.g.][]{Whitehurst_2014_Senate_Testimony}. While presenting all this would provide too much detail for our main text, Appendix~\ref{appendix:background} explain exactly why these assumptions hold. Instead of assuming that the sample is invalid, we went back to the original program designers and files and found out that attrition is actually not a serious concern for the reasons that we state in Appendix~\ref{appendix:background}. For ABC, for which validity has been questioned, we argue that our assumptions are sound because most cases of non-compliance were unrelated actions to the program implementers or to household decisions. We elaborate on how we deal with attrition and missing data in Appendix~\ref{appendix:background}  and summarize next:

\begin{enumerate}

\item Four children in the treatment group did not complete the treatment. They left 3, 10, 6, and 9 months after the treatment began. We treat them as though they have had treatment (because they did, at least for a few months). In later life follow ups, we fully observe outcomes for these children and include them in our computations. This would only bias our results downwards, as these children did not complete treatment.

\item Four children died: two of them in the treatment group and two of them in the control group. Given the causes of death (heart disease for two of them, SIDS for one of them, and a pedestrian accident for one of them), we interpret this as missing at random.

\item Four children in the treatment group "disappeared." There is no data on them, and it is difficult to make a methodological decision with respect to them. We have no data on them and have no other choice than to assume that they are missing at random.

\item Three children crossed from the control to the treatment group. This crossover was suggested and enforced by the local authorities, and did not occur by household choice or by design. We decide to drop these children from our sample of analysis. This drop out could be interpreted as exogenous because it was a consequence of a third party action (neither the household nor the program designers were responsible for this).

\item One child in the control group and two children in the treatment group dropped from the sample. We address this problem in the Appendix. We observe baseline data and data before age 8 for these children (i.e., they attrited but data collection for them continued).

\item Two children in the treatment group were diagnosed as developmentally delayed 6 and 36 months after the treatment began. This disqualified them for treatment: The original design assumed that children were not supposed to be developmentally delayed. This is not a concern per se. The concern would be that analogous control-group children could not be detected (because usually there is less contact of program officers with control-group children). Given the complementary features offered to the control group and the frequent data collection, implementation staff kept a close relationship with the control-group children, which lessens that concern.

\end{enumerate}

\noindent \textbf{Referee 1. Finally, the paper lacks a much-needed section on limits and a contextual interpretation of these two studies. The projects occurred in a small university town that had high income, high education families and a school system deemed excellent by almost all parameters. Further, the proportion of minority and low-income families was very low, as noted in many prior publications about these studies. More importantly for a lifetime analysis, most of these study participants remained nearby and the Research Triangle Park has many job opportunities, at all levels, thus increasing employment opportunities - probably for both groups of study participants. Thus, although many of these findings may generalize, they need to be contextualized for cohort and geography. Another issue is that the gender differences that favor males in one way, but females in another way warrant greater discussion. These cannot be disaggregated from complex U.S. issues around race and gender, expectations, racism, opportunities, etc. A thoughtful mention of this will much improve the contribution of this important paper.}

\noindent \textit{Response.} Our summary and conclusions section, Section~\ref{section:conclusion}, is now devoted to briefly summarizing and qualifying  its findings to assess and acknowledge these important caveats.

\section*{Comments of Reviewer 3}

\noindent \textbf{Referee 3. The goal of the paper is to perform a comprehensive evaluation of an early childhood program (ACB/CARE). The evaluation is comprehensive in several ways: (i) It includes a wide range of outcomes; (ii) It forecasts and monetizes the effects on these outcomes over the life-cycle, to estimate rates of returns and compare benefits to costs; and (iii) It tries to account for both the sampling error in the experimental and auxiliary samples and the forecast error due to the interpolation and extrapolation. If I understand correctly, i) is already done in a separate paper \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED}. What's new in this paper is ii) and iii), both of which are challenging tasks but potentially quite useful for program evaluation.}

\noindent \textit{Response.} That is exactly right. In our companion paper, \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED} (now \citet{Garcia_Heckman_Ziff_2018_EER} forthcoming), we provide a ``more traditional'' analysis of treatment effects on multiple outcomes, focusing on gender differences and providing some novelties in terms of, for example, use of administrative crime data at age 30. Our paper intends to map these treatment effects into life-cycle measures of social efficiency.

\noindent \textbf{Referee 3. The paper is extraordinarily long, in total 350 pgs.\ including appendices. There are numerous long footnotes. I never refereed anything like this paper. I spent several days on the manuscript and I still don't understand what exactly is being done.}

\noindent \textit{Response.} We cannot provide a direct solution to the fact that the paper is very long because there is a lot empirical analysis to document given the nature of the paper. However, we have tried to make the paper much more concrete, in part using a lot of the feedback that you, the other referee, and the editor provided. In summary: (i) we briefly introduced the issue and illustrated with labor income, which is the workhorse example in what remains of the paper; (ii) provided a background and data section; and (iii) and then headed directly to the forecast of the paper. We provide a recipe of the exact steps that we follow, in the hope that the reader can understand exactly what is being done. In that case, the Appendix could become simply a means for consulting details, instead of explicit content that the reader needs to understand (which we agree neither is practical nor realistic). We hope that readers with different interests are able to consult different sections of the appendix.

\noindent \textbf{Referee 3. The body of the paper is far from self-contained; it is necessary to read the many appendices (and footnotes) to understand what the authors actually do, how the various procedures perform, etc. Indeed, most of the substance is in the appendices. The body of the paper actually reads a bit like a very long introduction/summary of what the authors do and what they found.}

\noindent Responde. After reformatting the paper, we are actually documenting in the main text all of the ingredients needed to form the labor income forecast: (i) a motivation of the issue and a summary of the main ingredients and results in the introduction; (ii) a brief summary of the program and data in Section~\ref{section:background}, the theoretical components and, importantly, a list disguising each step in Section~\ref{section:cbamethodology}, and so on. The paper should be self-contained in terms of forecasting labor income. For the remaining of the outcomes, the relevant appendices are cited.

\noindent \textbf{Referee 3.  I think it would be useful to drop the long introduction and get quickly to the core of the paper: How to forecast (and aggregate) the life-cycle costs and benefits.}

\noindent \textit{Response.} That is what we now do. We summarize our approach in the introduction and illustrate it using labor income. The reader, after finishing the introduction, should now have a clear idea of what the methodology is. The rest of the paper documents the crucial details and the remaining details are in the Appendix.

\noindent \textbf{Referee 3. Appendix~\ref{appendix:methodology} is important, and much of it is necessary to understand what you actually do, and the pros and cons of alternative approaches.}

\noindent \textit{Response.} We moved the crucial ingredients of Appendix~\ref{appendix:methodology} into the text. In particular, after listing each of the components in our forecasting procedure in Section~\ref{section:cbamethodology}, we proceed to document and test the relevant steps associated with each step. For example, we provide relevant details on the construction of the synthetic cohorts, document the treatment effects on the intermediate inputs that we use to forecast, and provide the tests of invariance. These elements were previously relegated to Appendix~\ref{appendix:methodology}, while being crucial.

\noindent \textbf{Referee 3. You don't really offer a new approach to monetize the outcomes. Perhaps this part of the paper can be summarized in a short subsection with a table. The details on how you monetize given your setting may be discussed in an appendix.}

\noindent \textit{Response.} We have relegated this, and particularly Table 1 of the previous version, to Appendix~\ref{appendix:methodology}.

\noindent \textbf{Throughout the paper, the authors ``test and do not reject" some testable implications of the key assumptions. Failure to reject is then taken as support of the assumptions. This raises two questions:}  

\noindent \textbf{If the paper is supposed to be a template, what should the researcher do if she rejects a given assumption, such as exogeneity or structural invariance? This seems like a likely event given the strong assumptions. Is it possible to make progress under alternative or weaker assumptions?}

\noindent \textit{Response.} Yes. It is possible to proceed under weaker assumptions. It is actually the case that the only object to forecast is the mean difference between the treatment and control. This weaker condition is provided in Equation~\eqref{eq:nec}. We do note, however, that the stronger the assumption the sharper the testable implication that the researcher is able to obtain. Mean independence allows us to derive the implications in Equations~\eqref{eq:suff1} and~\eqref{eq:suff2} and provide the tests in Figures~\ref{fig:labor-income-profiles} and~\ref{figure:controltests}. This would not be possible if Equation~\eqref{eq:nec} were the only implication. We have tried to be cautious about the important point that failure to reject is not tantamount to the truth of the null - it is just consistent with it.

\noindent \textbf{In the body of the paper, the authors consistently argue that they test and do not reject the assumptions they make. Looking at the appendices, this seems to be true in many but not all cases. Also, in some of the cases it is true, the sampling error is significant and one cannot say much about the testable implications. The authors should be clear about this.}

\noindent \textit{Response.} This is a good point. We want to offer our methodology as a template for the evaluation of other programs. A major part of Section~\ref{section:cbamethodology} is actually now devoted to justifying the use of $\bm{\phi}$ as a means of forecasting. The justification relies on the testable implications encapsulated in Equations~\eqref{eq:suff1} and~\eqref{eq:suff2}. As you point out in your report, a lot of relevant material used to justify this was left in the Appendix in the previous version of the paper. In this paper, we discuss the tests of these implications in Tables~\ref{table:invariance} and~\ref{table:invarianceerrors}. We also elaborate the magnitudes and the standard errors of the tests. In short and related to your question: The tests are not as precise as in Panel (a), but, as before, the coefficients associated with the relevant indicator are relatively low if compared with the average of the variable (average labor income in the experimental and non-experimental sample for males and females is $40,007$ and $24,584$ and  $32,717$ and $24,098$, respectively). Similar statements would hold for the complementary tests in Appendix~\ref{appendix:methodology}.

\noindent \textbf{Referee 3. I don't understand how the paper deals with substitution bias. Perhaps it was discussed in one of the appendices (or in \citet{Garcia_Heckman_Ziff_2017_Gender-Diff_UNPUBLISHED}) but I missed it. Please clarify what assumptions and data allow you to address this issue.}

\noindent \textit{Response.} Thanks for asking for this clarification, which was missing in the previous draft. We now sidestep this issue by focusing the vast bulk of our analysis on treatment relative to next best. Substitution bias is more auxiliary to our study because our main interest is to compare treatment to control, so we discuss it as a complementary but not a main result in Appendix~\ref{appendix:cbaresultscont} in the revised version. We acknowledge that dealing with substitution bias relies on further assumptions, which may congest the main messages of the paper.

\noindent \textbf{Referee 3. How do you choose predictor variables? It needs to be able to predict a treatment effect, and so the predictor variable should be affected by treatment. I might be wrong but it doesn't look like you are using the subsample of predictors that are affected by treatment? Why not? Why does it make sense to include predictor variables not affected by treatment?}

\noindent \textit{Response.} As detailed in Section~\ref{section:cbamethodology}, there are predictors not affected by treatment, $\bm{B}_k$, and predictors affected by treatment, $\bm{X}_{k,a}^d$. The former allow us to gain precision when identifying and estimating $\bm{\phi}$ in the auxiliary samples. We choose them to be the set of variables that are available across the two samples available at baseline in the experimental sample. The latter are the most important ones, as our whole methodology relies on them as ``mediators'' of treatment. That is precisely what is embedded in Assumption~\ref{ass:summary}. As detailed in Section~\ref{section:cbamethodology}, a variable is a predictor variable: (i) if it is available in the experimental and the non-experimental data; (ii) the support in the non- experimental data contains the support in the experimental data; (iii) mediates or causes labor income; and (iv) is affected by treatment. Section~\ref{section:cbamethodology} documents that these hold for the intermediate inputs that we use.

\noindent \textbf{Referee 3. What, if any, restrictions are there on the joint distribution of the predicted outcomes in a given period? Are, say, high earners also more likely to be healthy? What are the cross-equation restrictions in the forecasts?}

\noindent \textit{Response.} This is an excellent point that we cannot implement in our data. We explain the reason in Section~\ref{section:following} and reproduce the explanation here. As both a referee and various commentators of our paper usefully pointed out, our identification and estimation does not impose cross-sectional restrictions. That is, it does not identify and estimate the $\bm{\phi_{a}} \left( \bm{x}, \bm{b} \right)$ for all of our outcomes. This is a consequence of a data restriction: We use different datasets to identify and estimate the  $\bm{\phi_{a}} \left( \bm{x}, \bm{b} \right)$ for each outcome (i.e., labor income, health, crime). Thus, the predictor variables that we are able to use differ across outcomes and we cannot perform this estimation. This implies an efficiency loss because it impedes us from imposing cross-sectional restrictions across outcomes.

\noindent \textbf{Referee 3. Please clarify why one needs a randomized experiment if one is willing to make the assumptions you invoke (such as exogeneity of the predictor variables and structural invariance)? Why not just go to observational data where we can observe long-run outcomes and have a larger set of covariates to do the matching. What economic model or assumptions would invalidate such a matching procedure (which motivates why you look at social experiments), yet still be consistent with the assumptions you invoke? The paper should be clear about this.}

\noindent \textit{Response.} The new exposition clarifies this. By assuming that treatment is mediated by $\bm{X}_{k,a}^d$ the treatment-control differences in any outcomes of interest will result from the treatment-control difference in $\bm{X}_{k,a}^d$ (as dictated by the structural function $\phi$). One could think of doing this non-parametrically and that is exactly what we discuss in Section~\ref{section:sens}. We need the experiment to determine which regressors generate the treatment effects.

\noindent \textbf{Referee 3. The importance of essential heterogeneity is a key insight of other work by Heckman and coauthors. Please discuss your assumptions and approaches in light of this evidence. Does the presence of essential heterogeneity in a wide range of settings tell us something of the applicability of the methods you propose in this paper?}

\noindent \textit{Response.} We appreciate this point, but, again, we are limited by the sample at hand. To address essential heterogeneity in this paper, we would need to allow for heterogeneous responses to treatment. In our small-sample experiment, doing this leads to very unstable estimates. We approximate a complex reality by providing an estimate of the average treatment effect of the program, and statistics related to it, for the population for which $\bm{B} \in \mathcal{B}_0$, assuming a homogeneity.






%References
\singlespace
\bibliographystyle{chicago}
\bibliography{heckman}

\end{document} 
