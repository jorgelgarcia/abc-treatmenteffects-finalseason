%Input preamble
\input{preamble}
\input{output/mainstatistics}

\usepackage[stable]{footmisc}

\newcommand*\leftright[2]{%
  \leavevmode
  \rlap{#1}%
  \hspace{0.5\linewidth}%
  #2}

\newcommand{\orth}{\ensuremath{\perp\!\!\!\perp}}%
\newcommand{\indep}{\orth}%
\newcommand{\notorth}{\ensuremath{\perp\!\!\!\!\!\!\diagup\!\!\!\!\!\!\perp}}%
\newcommand{\notindep}{\notorth}

\externaldocument{abc_comprehensivecba}
\externaldocument{abc_comprehensivecba_appendix}
\pagenumbering{roman}

\begin{document}


\doublespacing

\subsection{Data Combination Estimator in the GMM Framework} \label{appendix:gmm}

\noindent Our analysis is based on a causal model for treatment ($d=1$) and control ($d=0$) outcomes for measure $j$ at age $a$ in sample $k \in \{e,n\}$ where $e$ denotes membership in the experimental sample and $n$ denotes membership in the auxiliary sample:\\

\begin{equation}\label{eq:outcome}
Y^d_{k,j,a} = \phi^d_{k,j,a} (\bm{X}^d_{k,a}, \bm{B}_k) + \varepsilon^d_{k,j,a}, \quad k \in \{n,e\}, \quad j \in \mathcal{J}_a, \quad d \in \{0, 1\}. 
\end{equation}

\noindent $\phi^d_{k,j,a}\left( \cdot, \cdot \right)$ is an invariant structural production relationship mapping inputs $\bm{X}^d_{k,a}, \bm{B}_k$ into output $Y^d_{k,j,a}$ holding error term $\varepsilon^d_{k,j,a}$ fixed.\\

\noindent Note that Assumption ~\ref{ass:exog} (Exogeneity) implies no serial correlation in $ \varepsilon^d_{k,j,a}$.\\

\noindent \textbf{[JJH: Not if we transform the estimates. Did you estimate with random walk component? This does not require absence of serial correlation?] [JLG: Sending a separate document discussing these estimates.]}\\


\noindent We show in the main text that $\phi^d_{n,j,a} (\cdot, \cdot)$ is an unbiased predictor of $Y_{e,j,a}^d$. This holds for any age, although we are specifically interested in $a > a^*$, given that we do not observe $Y_{e,j,a}^d$ after $a^*$.\\

\noindent We frame the estimation of $\phi^d_{n,j,a} (\cdot, \cdot)$ in the generalized method of moments (GMM) framework. This helps us illustrate how our prediction theory in the main text provides theoretical conditions for the combination of multiple datasets.\\

\noindent First, note that Assumption ~\ref{ass:exog} (Exogeneity) implies the following holds in the \textit{experimental sample}: 

\begin{eqnarray}
\mathbb{E} \left[ Y_{e,j,a}^d | \bm{X}_{e,a}^d, \bm{B}_{e} \right] =  \phi^d_{e,j,a}\left( \bm{X}_{e,a}^d, \bm{B}_{e} \right). \label{eq:main}
\end{eqnarray}

\noindent By Assumption~\ref{ass:contain} (Support Conditions), the support of the auxiliary sample contains the support of the experimental sample. Thus, Equation~\eqref{eq:main} is valid for any $\bm{X}^d_{k,a}$, $\bm{B}_{k}$, and $\bm{Y}_{k,a}$, with $k \in \{ e, n\}$. We then can write: 

\begin{eqnarray}
\mathbb{E} \left[ Y_{n,j,a}^d | \bm{X}_{n,a}^d, \bm{B}_{n} \right] =  \phi^d_{e,j,a}\left( \bm{X}_{n,a}^d, \bm{B}_{n} \right).
\end{eqnarray}

\noindent This relates the moment $\mathbb{E} \left[ Y_{n,j,a}^d | \bm{X}_{n,a}^d, \bm{B}_{n} \right]$ in the auxiliary sample to the function  $\phi^d_{e,j,a}\left( \cdot, \cdot \right)$ in the experimental sample.\\

\noindent By Assumption~\ref{ass:summary} (Invariance), we can write this as: 

\begin{eqnarray}\label{eq:momentlink}
\mathbb{E} \left[ Y_{n,j,a}^d | \bm{X}_{n,a}^d, \bm{B}_{n} \right] &=&  \phi^d_{e,j,a}\left( \bm{X}_{n,a}^d, \bm{B}_{n} \right) \nonumber \\ 
 &=&  \phi^d_{n,j,a}\left( \bm{X}_{n,a}^d, \bm{B}_{n} \right) \nonumber \\
 &=&  \phi_{j,a}\left( \bm{X}_{n,a}^d, \bm{B}_{n} \right). \label{eq:mainpred}
\end{eqnarray}

\noindent Equation~\eqref{eq:momentlink} directly states the relationship between the moment observed in the auxiliary sample, the left-hand side, and the function that we use to construct the predictions. Our objective is to estimate the parameters, $\bm{\theta}_{j,a}$, characterizing this function.\\ 

\noindent The key moment condition implied by Assumption~\ref{ass:exog} (Exogeneity) is 

\begin{equation}
\mathbb{E} \left[ \bm{m}_{j,a} \left( \bm{X}_{n,a}^d, \bm{B}_{n}; \bm{\theta}_{j,a} \right) \right] = 0, \label{eq:moment}
\end{equation}

\noindent where $\bm{m}_{j,a} \left( \bm{X}_{n,a}^d, \bm{B}_{n} ; \bm{\theta}_{j,a} \right) := {\bm{X_{n,a}^d}}^{'} \left( Y_{n,j,a}^d -   \phi^d_{j,a} \left( \bm{X}_{n,a}^d, \bm{B}_{n} \right) \right)$ for $a \in [0, \ldots A]$.\\

\noindent This allows us to discuss our data combination estimator as a generalized method of moments estimator.\\

\noindent First, suppose that we are interested in estimating $\phi_{j,a} \left( \cdot \right)$ for a single outcome $j \in \mathcal{J}_{a}$ (e.g. labor income), but across all ages of interest. For the time being, assume that we do not place specific weights on the different moments implied by \eqref{eq:moment} (we come back to this issue below) and that there are two age periods after age $a^*$. In our auxiliary sample, the following moments identify $\bm{\theta}_{j,a^*+1}, \bm{\theta}_{j,a^*+2}$: 

\begin{equation}
\mathbb{E}
\begin{bmatrix}
\bm{m}_{j,a^*+1} \left( \bm{X}_{n,a^*+1}^d, \bm{B}_{n}; \bm{\theta}_{j,a^*+1} \right) \\ \bm{m}_{j,a^*+2} \left( \bm{X}_{n,a^*+2}^d, \bm{B}_{n}; \bm{\theta}_{j,a^*+2} \right) 
\end{bmatrix}
= \bm{0} \label{eq:smoment}
\end{equation}\\

\noindent An estimation approach leading to consistent estimates is to minimize

\begin{equation}
q : = 
{\begin{bmatrix}
\bm{\bar{m}}_{j,a^*+1} \left( \bm{X}_{n,a^*+1}^d, \bm{B}_{n}; \bm{\theta}_{j,a^*+1} \right) \\ \bm{\bar{m}}_{j,a^*+2} \left( \bm{X}_{n,a^*+2}^d, \bm{B}_{n}; \bm{\theta}_{j,a^*+2} \right) 
\end{bmatrix}}^{'}
\begin{bmatrix}
\bm{\bar{m}}_{j,a^*+1} \left( \bm{X}_{n,a^*+1}^d, \bm{B}_{n}; \bm{\theta}_{j,a^*+1} \right) \\ \bm{\bar{m}}_{j,a^*+2} \left( \bm{X}_{n,a^*+2}^d, \bm{B}_{n}; \bm{\theta}_{j,a^*+2} \right) 
\end{bmatrix}, 
\end{equation}\\

\noindent where $\bar{u}$ denotes the empirical counterpart of $u$.\\

\noindent \textbf{[JJH: stack across all ages.] [JLG: This is coming after.}\\


\noindent \textbf{[JJH: we are trying to predict in $n$ sample] [JJH: How do we initialize the $n$? We are using $n$ to predict.] [JLG: Correct. See 1. below. There, I state how do we initialize in the auxiliary sample. The auxiliary sample always contains the outcomes observed at $a^*$. The footnote states what happens when we do not.]}\\

\noindent \textbf{[JJH: let's cut the chase ---you never say how you forecast $n$. The answer to the previous question should get to this.]}\\

\noindent \textbf{[JJH: How do we join the $e$ sample with the $n$ sample.] [JLG: The two samples meet in the joint moment condition in \eqref{eq:MOMENT}. A few steps come before.]}\\

\noindent Two important questions are:

\begin{enumerate}
\item The moment in \eqref{eq:smoment} are satisfied in the auxiliary sample, \textbf{how do we \textit{initialize} the computation of their empirical counterparts in the auxiliary sample?} \\ 
\noindent In the auxiliary sample, there are two cases.\\

\begin{enumerate}
\item We observe $Y_{n,j,a}$ at $a = a^*$. We are able to evaluate the empirical counterpart of $\bm{\bar{m}}_{j,a^*+1} \left( \bm{X}_{n,a^*+1}^d, \bm{B}_{n} \right) $, when $ \bm{X}_{n,a^*+1}^d$ contains a lagged value of $Y_{n,j,a}$ at $a^*+1$. The same is true for $a^*+1 < a < A$. Thus, we do not need to use predictions of $Y_{n,j,a}$ in the auxiliary sample. We evaluate $\bm{\bar{m}}_{j,a} \left( \bm{X}_{n,a}^d, \bm{B}_{n} \right)$ at  the realization of $\bm{X}_{n,a}^d$, when forming the empirical moments.\\

\noindent This is the case for all of the outcomes, except for health.\\

\item We do not observe $Y_{n,j,a}$ at $a = a^*$. This happens for some health outcomes. At $a^*$, we do not observe health outcomes as cancer or heart disease. We observe biomarkers.  We use these biomarkers to predict the health outcomes at $a^*$. Once a prediction is available, we can a step analogous to step $2.$ below to compute the empirical counterpart of $\bm{\bar{m}}_{j,a} \left( \bm{X}_{n,a}^d, \bm{B}_{n} \right)$. We form a prediction of the health outcome at $a^*$ and then we go forward as in (a), replacing the observed outcome at $a = a^*$ with the prediction.\\

\noindent The prediction of the health outcomes at age $a^*$, is based on probabilist models that are identified through standard moment conditions (see Appendix~\ref{appendix:health}). For further reference, we define this additional set of moments as: 

\begin{equation}
\mathbb{E} \left[ \mathbf{h} \left(  \bm{X}_{n,a^*}^d, \bm{B}_{n}; \bm{\theta}_{h}  \right) \right] = \mathbf{0}.
\end{equation}
\end{enumerate}

\item \textbf{How do we use the estimates of $\bm{\theta}_{j,a^*+1}, \bm{\theta}_{j,a^*+2}$ to construct the predictions in the experimental sample?}\\ 
\noindent Based on the estimates of $\bm{\theta}_{j,a^*+1}, \bm{\theta}_{j,a^*+2}$, we can recover estimates of the functions that we use to predict: $\hat{\phi}_{j,a^*+1}, \hat{\phi}_{j,a^*2}$. We use these functions in the experimental sample to construct the predictions of interest: $\hat{Y}_{e,j,a^*+1}$ and $\hat{Y}_{e,j,a^*+2}$. In a two-period setting, we would do the following: 

\begin{enumerate}
\item Evaluate $\hat{\phi}_{j,a^*+1} \left( \cdot \right)$ at  $\bm{X}_{e,a^*+1}^d, \bm{B}_{e}$ and obtain the the prediction $\hat{Y}_{e,j,a^*+1}$. In our empirical analysis, $\bm{X}_{e,a^*+1}^d$ contains a one-period lagged value of $Y_{e,j,a^*+1}$. It is possible to construct the prediction at $a^*+1$ because we observe $Y_{e,j,a^*}$.

\item $\hat{\phi}_{j,a^*+2} \left( \cdot \right)$ at  $\bm{X}_{e,a^*+2}^d, \bm{B}_{e}$ and obtain the the prediction $\hat{Y}_{e,j,a^*+2}$. In our empirical application, $\bm{X}_{e,a^*+2}^d$ contains a one-period lagged value of $Y_{e,j,a^*+2}$. It is possible to construct the prediction at $a^*+2$ because we use $\hat{Y}_{e,j,a^*+1}$ (as an estimate of $Y_{e,j,a^*+1}$) to evaluate $\hat{\phi}_{j,a^*+2}$ at  $\bm{X}_{e,a^*+2}^d, \bm{B}_{e}$.
\end{enumerate}
\end{enumerate}

\noindent \noindent The estimator discussed so far, however, misses three important aspects: 

\begin{enumerate}[(i)] 
\item Note that Assumption~\ref{ass:exog} (Exogeneity) applies both to the auxiliary and to the experimental samples. Together with Assumption~\ref{ass:summary} (Invariance), this implies that the moment condition in \eqref{eq:smoment} is valid in both samples. We can use these additional moment condition in our estimation procedure.
\item We can set-up an estimator that jointly consider the moments of all outcomes $j \in \mathcal{J}_{a}$ for $a \in [a^*+1, \ldots, A]$.
\item We can minimize a weighted loss function, that weighs the moment in \eqref{eq:moment} for each outcome and at each age. It is of specific interest for us to weight the variance of the moments in \eqref{eq:moment} because, in order to satisfy Assumption~\ref{ass:contain} (Support Conditions), we pool different auxiliary data sources, as we explain in the main text.
\end{enumerate}

\noindent Taking these aspects into consideration, the joint moment condition for identifying the parameters associated all of our outcomes, $\bm{\theta}$ is 




\begin{eqnarray}
\mathbb{E} \left[ \bm{m} \left( \cdot ; \bm{\theta} \right) \right] &:=&
\begin{bmatrix}
 \mathbf{h} \left(  \bm{X}_{n,a^*}^d, \bm{B}_{n}; \bm{\theta}_{h}  \right) \\  \mathbf{h} \left(  \bm{X}_{e,a^*}^d, \bm{B}_{e}; \bm{\theta}_{h}  \right) \\
\bm{m}_{e,j',a^*+1} \left( \bm{X}_{e,a^*+1}^d, \bm{B}_{e}; \bm{\theta}_{j',a^*+1} \right) \\ \vdots \\  \bm{m}_{e,j',A} \left( \bm{X}_{e,A}^d, \bm{B}_{e}; \bm{\theta}_{j',A} \right) \\
\bm{m}_{n,j',a^*+1} \left( \bm{X}_{n,a^*+1}^d, \bm{B}_{n}; \bm{\theta}_{j',a^*+1} \right) \\ \vdots \\  \bm{m}_{n,j',A} \left( \bm{X}_{n,A}^d, \bm{B}_{e}; \bm{\theta}_{j',A} \right) \\
\bm{m}_{e,j'',a^*+1} \left( \bm{X}_{e,a^*+1}^d, \bm{B}_{e}; \bm{\theta}_{j'',a^*+1} \right) \\ \vdots \\  \bm{m}_{e,j'',A} \left( \bm{X}_{e,A}^d, \bm{B}_{e}; \bm{\theta}_{j'',A} \right) \\
\bm{m}_{n,j'',a^*+1} \left( \bm{X}_{n,a^*+1}^d, \bm{B}_{n}; \bm{\theta}_{j'',a^*+1} \right) \\ \vdots \\  \bm{m}_{n,j'',A} \left( \bm{X}_{n,A}^d, \bm{B}_{e}; \bm{\theta}_{j'',A} \right) 
 \label{eq:loss}
\end{bmatrix}  \\ \nonumber
&=& \bm{0}, \label{eq:MOMENT}
\end{eqnarray}

\noindent where we use the subindex used so far to distinguish the moments in the auxiliary sample with the moments in the experimental sample. In our analysis, $\bm{X}_{k,a^*+1}^d$ contains a lagged and possibly unobserved values of $Y_{k,j,a^*+1}$. To compute the empirical counterparts of $\bm{m}_{k,j,a^*+1}$ for $k \in \{e, n\}$, we use the steps listed as 1. and 2. above.\\

\noindent Let $\bm{W}$ be a positive definite matrix. A consistent estimation approach for $\bm{\theta}$ is to minimize 

\begin{equation}
Q :=  {\bm{\bar{m}} \left( \cdot ; \bm{\theta} \right) }^{'} \bm{W} ^{-1} {\bm{\bar{m}} \left( \cdot ; \bm{\theta} \right)}. \label{eq:wloss}
\end{equation}

\noindent We use the CNLSY to construct the moments from ages 22 to 29 and then use the PSID and the NLSY79 as a single, joint sample to construct the moments afterwards (except for health, where we use various other datasets, as we explain in Appendix~\ref{appendix:health}).\\

\noindent The loss function in \eqref{eq:wloss} weighs the moments coming from different datasets. $\bm{W}$ is not restricted to be diagonal so that these moments are allowed to correlate. Iterated, feasible procedures to obtain an estimate of $\bm{W}$ jointly with the parameters of interest guarantee efficiency and are straightforward to implement \citep{Hansen_1982_Econometrica,Amemiya_1985_advanced}.\footnote{\citet{Altonji_Segal_1996_JoBaES} show that GMM presents downwards bias in absolute value in small-sample size setting, which could be a concern in our setting.} 

%References
\singlespace
\bibliographystyle{chicago}
\bibliography{heckman}

\end{document}


